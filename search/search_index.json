{"config":{"lang":["ja"],"separator":"[\\s\\-\uff0c\u3002]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"AWS Certified Data Analytics Tutorial","text":"<p>Started at May. 2021 By Jacob Xi </p>"},{"location":"#about-this-tutorial","title":"About this tutorial","text":"<p>This books is my 6th tech books published recently and my 1st English version tutorial book. And this book is my favorite and hard-working book so far. The weather is getting hotter and hotter\u2600\ufe0f, thank you so much team colleagues' and friends' support and instruction. # Have to Keigo Higashino\ud83d\udcda is my favorite Japanese author\uff0c \u201cThe Miracles of the Namiya General Store\u201d is one of my loving book</p> <p> </p>"},{"location":"#description","title":"Description","text":"<p>The AWS Certified Data Analytics Specialty Exam is one of the most challenging certification exams you can take from Amazon. Passing it tells employers in no uncertain terms that your knowledge of big data systems is wide and deep.</p> <p>The world of data analytics on AWS includes a dizzying array of technologies and services. Just a sampling of the topics I cover in-depth are:</p> <ul> <li>Streaming massive data with AWS Kinesis</li> <li>Queuing messages with Simple Queue Service (SQS)</li> <li>Wrangling the explosion data from the Internet of Things (IOT)</li> <li>Transitioning from small to big data with the AWS Database Migration Service (DMS)</li> <li>Storing massive data lakes with the Simple Storage Service (S3)</li> <li>Optimizing transactional queries with DynamoDB</li> <li>TRying your big data systems together with AWS Lambda</li> <li>Making unstructured data query-able with AWS Glue, Glue ETL, Glue DataBrew, Glue Studio, and Lake Formation</li> <li>Processing data at unlimited scale with Elastic MapReduce, including Apache Spark, Hive, HBase, Presto, Zeppelin, Splunk, and Flume</li> <li>Applying neural networks at massive scale with Deep Learning, MXNet, and Tensorflow</li> <li>Applying advanced machine learning algorithms at scale with Amazon SageMaker</li> <li>Analyzing streaming data in real-time with Kinesis Analytics</li> <li>Searching and analyzing petabyte-scale data with Amazon Elasticsearch Service</li> <li>Querying S3 data lakes with Amazon Athena</li> <li>Hosting massive-scale data warehouses with Redshift and Redshift Spectrum</li> <li>Integrating smaller data with your big data, using the Relational Database Service (RDS) and Aurora</li> <li>Visualizing your data interactively with Quicksight</li> <li>Keeping your data secure with encryption, KMS, HSM, IAM, Cognito, STS, and more</li> </ul> <p> </p>"},{"location":"#previous-on-my-technolog-book","title":"Previous on my Technolog book","text":"<p>\u624b\u6478\u624b Jenkins \u6218\u672f\u6559\u7a0b (\u5927\u5e08\u7248\uff09</p> <p>\u624b\u6478\u624b Elasticsearch7 \u6280\u672f\u4e0e\u5b9e\u6218\u6559\u7a0b</p> <p>\u624b\u6478\u624b Redis \u6280\u672f\u4e0e\u5b9e\u6218\u6559\u7a0b</p> <p>\u624b\u6478\u624b Chef &amp; Ansible \u6280\u672f\u4e0e\u5b9e\u6218\u6559\u7a0b</p> <p>\u624b\u6478\u624b \u5206\u5e03\u5f0f\u4e0e\u6d41\u5f0f\u7cfb\u7edf (In progress)</p> <p>Azure 103&amp;900 Tutorial (In progress)</p> <p>\u624b\u6478\u624b Linux Performance &amp; \u9762\u8bd5\u5b9e\u6218\u6559\u7a0b</p> <p>\u624b\u6478\u624b Databases \u5168\u6559\u7a0b</p>"},{"location":"#salut-cest-moi","title":"Salut! C'est Moi","text":"<p>The man is not old as long as he is seeking something, A man is not old until regrets take the place of dreams.</p> <p>Hello, this is me, Jacob. Currently, I'm working as DevOps and Cloud Engineer in SAP, and I'm the certified AWS Solution Architect and Certified Azure Administrator, Kubernetes Specialist, Jenkins CI/CD and ElasticStack enthusiast. </p> <p>I was working as Backend Engineer in New York City and achieved my CS master degree in SIT, America. Believe it or not, I'll keep writing, more and more books will come out at such dramatic and unprecedented 2021. </p> <p>If you have anything want to talk to me directly, you can reach out for via email xichao2015@outlook.com\u3002</p> <p>Salute, c'est moi, Jacob. Actuellement, je travaille en tant qu'ing\u00e9nieur DevOps et Cloud dans SAP, et je suis architecte de solution AWS certifi\u00e9 et administrateur Azure certifi\u00e9, sp\u00e9cialiste Kubernetes et passionn\u00e9 de CI/CD.</p> <p>Je travaillais en tant qu'ing\u00e9nieur backend \u00e0 New York et j'ai obtenu mon master CS \u00e0 SIT, en Am\u00e9rique. Croyez-le ou non, je continuerai \u00e0 \u00e9crire, de plus en plus de livres sortiront cette ann\u00e9e.</p>"},{"location":"#tutorial-content","title":"Tutorial content","text":"<ul> <li>Section1:   Intro<ul> <li>AWS Certified Big Data Specialty 2020 - In Depth &amp; Hands On!</li> </ul> </li> <li>Section2:   Collection<ul> <li>L1 Collections - Kinesis DataStream Overview</li> <li>L2 [Exercise] Kinesis Firehose (PurchaseLogs/OrderLogs)</li> <li>L3 [Exercise] Kinesis Data Streams</li> <li>L4 SQS vs. Kinesis Data Stream</li> <li>L5 IoT Overview and DeepDive</li> <li>L6 Data Collection Others</li> <li>L7 MSK Managed Streaming for Apache Kafka (Amazon MSK)</li> </ul> </li> <li>Section3:   Storage<ul> <li>L1 Storage S3</li> <li>L2 DynamoDB</li> <li>L3 Hands on S3</li> <li>L4 ElastiCache Overview</li> </ul> </li> <li>Section4:   Processing<ul> <li>L1 AWS Lambda </li> <li>L2 [Exercise] AWS Lambda</li> <li>L3 AWS Glue &amp; Lake Formation</li> <li>L4 EMR Elastic MapReduce</li> <li>L5 Elastic MapReduce Exercise</li> <li>L6 AWS Data Pipeline</li> <li>L7 Deep Learning</li> </ul> </li> <li>Section5:   Analysis<ul> <li>L1 Kinesis Analytics</li> <li>L2 Kinesis Analytics Exercise</li> <li>L3 Amazon Elasticsearch Service</li> <li>L4 Amazon Elasticsearch Service Exercise</li> <li>L5 Amazon Athena</li> <li>L6 [Exercise] AWS Glue and Athena</li> <li>L7 AWS Redshift</li> <li>L8 [Exercise] Redshift Spectrum</li> </ul> </li> <li>Section6:   Visualization<ul> <li>L1 Visualization </li> <li>L2 Amazon Quicksight Exercise</li> </ul> </li> <li>Section7:   Security<ul> <li>L1 Security - Encryption</li> <li>L2 AWS Services Security Deep Dive</li> <li>L3 Account and Identity Federation</li> <li>L4 Polices, CloudTrail &amp; VPCe</li> </ul> </li> <li>Section8:   WrapUp<ul> <li>L1 AWS Bigdata Integration</li> <li>L2 AWS Big Data Instances</li> </ul> </li> <li>Section9:   Machine Learning<ul> <li>AWS Machine Learning \uff08Amazon ML Service/Amazon SageMaker)</li> </ul> </li> <li>Section10:  Quizs<ul> <li>Quiz1 Collection</li> <li>Quiz2 Storage</li> <li>Quiz3 AWS Lambda</li> <li>Quiz4 AWS Glue</li> <li>Quiz5 EMR and the Hadoop Ecosystem</li> <li>Quiz6 Kinesis Analytics</li> <li>Quiz7 Amazon ES</li> <li>Quiz8 Amazon Athena</li> <li>Quiz9 Amazon Redshift</li> <li>Quiz10 Amazon Quicksight</li> <li>Quiz11 Security</li> <li>Quiz12 Amazon Machine Learning and Sagemaker</li> <li>AWS Certified Data Analytics Specialty Practice Exam</li> </ul> </li> </ul>"},{"location":"#to-be-continue","title":"To be continue","text":"<p>I will put more effort do finish \"Azure 103&amp;900 Tutorial book\" and \"Distributed Message System Book\" this month hopefully. And starting working on \"AWS Solution Arcitect\" and \"Istio\", please waiting for it.\ud83d\ude42</p> <p> </p>"},{"location":"chap1/1intro/","title":"AWS Certified Big Data Specialty 2020 - In Depth &amp; Hands On!","text":""},{"location":"chap1/1intro/#service-will-learn","title":"Service Will Learn","text":""},{"location":"chap1/1intro/#introducing-our-hands-on-case-study-cadabracom","title":"Introducing our Hands-On Case Study: <code>Cadabra.com</code>","text":""},{"location":"chap1/1intro/#requirement-1-order-history-app","title":"Requirement 1: Order history app","text":"<ol> <li>site's mobile app to do this will simulate order data being generated on an easy to instance and publish that data </li> <li>Data using Kinesis data streams into an AWS lambda function which in turn will populate an order database in dynamoDB that our app can read from.</li> </ol>"},{"location":"chap1/1intro/#requirement-2-product-recommendations","title":"Requirement 2: Product recommendations","text":"<p>Automated product recommendations to our customers online which involves training a machine learning:</p> <ol> <li>Model based on aggregate customer purchasing data to build this we'll publish our order data through Kinesis firehose into a data lake hosted in Amazon S3</li> <li>spin up an Amazon Elastic map reduce cluster to produce recommendations model using Apache Spark.</li> </ol>"},{"location":"chap1/1intro/#requirement-3-transaction-rate-alarm","title":"Requirement 3: Transaction rate alarm","text":"<p>Next we'll create an operational system that alerts us if an unexpected rate of orders comes in all of a sudden. This might indicate some sort of attack that someone needs to deal with immediately.</p> <ul> <li>And so it must work in real time to build this will use Kinesis data streams and Kinesis data analytics to monitor our incoming orders </li> <li>Use a lambda function to fire off alarms using Amazon SNS or cell phone when something unusual happens.</li> </ul>"},{"location":"chap1/1intro/#requirement-4-near-real-time-log-analysis","title":"Requirement 4: Near-real-time log analysis","text":"<p>We also want to be able to analyze server log data in near real time for operational purposes for this requirement.</p> <ul> <li>We'll use Kinesis firehose to pump Apache log data directly into the Amazon Elastic search service </li> </ul>"},{"location":"chap1/1intro/#requirement-5-data-warehousing-visualization","title":"Requirement 5: Data warehousing &amp; visualization","text":""},{"location":"chap1/1intro/#final-put-it-together","title":"Final: Put it together","text":""},{"location":"chap10/qz10_quicksight/","title":"Quiz10 Amazon Quicksight","text":""},{"location":"chap10/qz10_quicksight/#question-1","title":"Question 1","text":"<p>Your manager has asked you to prepare a visual on QuickSight to see trends in how money was spent on entertainment in the office in the past 12 months. What visual will you use? </p> <ul> <li>Pivot table </li> <li>Line chart </li> <li>Story </li> <li>Pie chart </li> </ul> <p>Line charts are appropriate for viewing trends in data over time. </p>"},{"location":"chap10/qz10_quicksight/#question-2","title":"Question 2","text":"<p>You wish to publish a visual you've created illustrating trends of work coming into your company, for  your employees to view. wnicn tool in utuickbignt woula be appropriate? </p> <ul> <li>Dashboard </li> <li>Stories </li> <li>Pie chart </li> <li>Auto-graph </li> </ul> <p>A dashboard is a way to publish a screen of data to a larger audience. </p>"},{"location":"chap10/qz10_quicksight/#question-3","title":"Question 3","text":"<p>You want to build a visualization from the data-set you have imported, but you are unsure what visual to select for the best view. What can you do? </p> <ul> <li>Use a pie chart </li> <li>Use a pivot table </li> <li>Use an area line chart </li> <li>Select auto-graph </li> </ul> <p>Auto-graph will automatically try to select the most appropriate visualization type for the data you have selected. </p>"},{"location":"chap10/qz10_quicksight/#question-4","title":"Question 4","text":"<p>The source data you wish to analyze is not in a clean format. What can you do to ensure your visual in QuickSight looks good, with a minimum of effort? </p> <ul> <li>Select edit / preview data before loading it into analysis, and edit it as needed. </li> <li>Use auto-graph </li> <li>Convert it with Data Pipeline </li> <li>Use pivot tables </li> </ul>"},{"location":"chap10/qz10_quicksight/#question-5","title":"Question 5","text":"<p>How can you point QuickSight to fetch from your database stored on the EC2 instance in your VPC ? </p> <ul> <li>Add Amazon QuickSight IP range to the allowed IPs of the hosted DB </li> <li>Not possible with locally hosted Database </li> <li>Migrate to RDS first and then add the data set from there. </li> <li>Use Auto-graph </li> </ul>"},{"location":"chap10/qz11_security/","title":"Quiz11 Security","text":""},{"location":"chap10/qz11_security/#question-1","title":"Question 1","text":"<p>Server side encryption means that the data is sent encrypted to the server first </p> <ul> <li>true </li> <li>false </li> </ul>"},{"location":"chap10/qz11_security/#question-2","title":"Question 2","text":"<p>In server side encryption, only the encryption happens on the server. Where does the decryption happen? </p> <ul> <li>The Server </li> <li>The Client </li> </ul>"},{"location":"chap10/qz11_security/#question-3","title":"Question 3","text":"<p>We need to gain access to a Role in another AWS account. How is it done? </p> <ul> <li>We should ask for them to create a user for us </li> <li>We should ask for them to send us access keys </li> <li>We should use the STS service to gain temporary credentials </li> </ul>"},{"location":"chap10/qz11_security/#question-4","title":"Question 4","text":"<p>You have a mobile application and would like to give your users access to their own personal space in Amazon S3. How do you achieve that? </p> <ul> <li>Generate IAM user credentials for each of your application's users </li> <li>Use Cognito Identity Federation </li> <li>Use SAML Identity Federation </li> <li>Use a Bucket Policy to make your bucket public </li> </ul>"},{"location":"chap10/qz11_security/#question-5","title":"Question 5","text":"<p>You need an encryption service that supports asymmetric encryption schemes. Which service could you use? </p> <ul> <li>CloudHSM </li> <li>KMS </li> <li>Lambda </li> </ul>"},{"location":"chap10/qz11_security/#question-6","title":"Question 6","text":"<p>We'd like to encrypt 100MB of data client side before uploading it to S3. We should use </p> <ul> <li>KMS <code>Encrypt</code> call </li> <li>Enveloppe Encryption </li> <li>SSE-S3 </li> <li>SSE-KMS </li> </ul>"},{"location":"chap10/qz11_security/#question-7","title":"Question 7","text":"<p>You would like to ensure data is encrypted client side before being  sent to Kinesis. What should you use? </p> <ul> <li>The client side encryption option of the AWS SDK </li> <li>The client side encryption option of KPL library</li> <li>The client side encryption option of the KCL library </li> <li>You must create custom code </li> </ul>"},{"location":"chap10/qz11_security/#question-8","title":"Question 8","text":"<p>Which technology allows you to access the AWS service from your private subnets without the need to have an outgoing internet connection? </p> <ul> <li>AWS Direct Connect </li> <li>VPC Endpoints </li> <li>Internet Gateways</li> <li>NAT Instances </li> </ul>"},{"location":"chap10/qz11_security/#question-9","title":"Question 9","text":"<p>What do you need to attach to an IoT rule's engine action to ensure it's capable of sending data directly into Kinesis? </p> <ul> <li>An IAM user </li> <li>An IoT policy </li> <li>An IAM group </li> <li>An IAM role </li> </ul>"},{"location":"chap10/qz11_security/#question-10","title":"Question 10","text":"<p>Which of the following statement is wrong? </p> <ul> <li>DynamoDB Streams cannot be encrypted </li> <li>DynamoDB security is done through IAM </li> <li>Users must be created within DynamoDB </li> <li>DynamoDB supports only table creation, not database creation </li> </ul> <p>The entire security in DynamoDB is managed through IAM, we don't need to create users within DynamoDB (unlike RDS) </p>"},{"location":"chap10/qz11_security/#question-11","title":"Question 11","text":"<p>Which of the following services is accessed through a VPC Endpoint of type Interface ? </p> <ul> <li>Kinesis </li> <li>DynamoDB </li> <li>S3 </li> </ul> <p>DynamoDB, S3: That's a gateway endpoint </p> <p>Kinesis: VPC endpoint</p>"},{"location":"chap10/qz11_security/#question-12","title":"Question 12","text":"<p>What security mechanism does not exist for RDS? </p> <ul> <li>KMS at rest encryption </li> <li>Cloud HSM at rest encryption </li> <li>SSL encryption </li> <li>Transparent Data Encryption </li> </ul>"},{"location":"chap10/qz11_security/#question-13","title":"Question 13","text":"<p>You would like to deploy a Lambda function to privately access your RDS database. Under the default options, your Lambda function cannot reach your RDS database due to a network issue. How can you resolve it? </p> <ul> <li>Encrypt the database password with KMS </li> <li>Deploy your Lambda function in your VPC </li> <li>Increase the Lambda timeout </li> <li>Attach a VPC endpoint to RDS </li> </ul>"},{"location":"chap10/qz11_security/#question-14","title":"Question 14","text":"<p>Which statement about EMR security is incorrect? </p> <ul> <li>You can SSH into your cluster nodes </li> <li>EMRFS supports S3 encryption </li> <li>Apache Ranger is packaged within EMR </li> <li>EMR supports LUKS encryption </li> <li>EMR supports Kerberos </li> <li>There are two security groups assigned between your different cluster nodes </li> </ul> <p>If you choose to use Ranger, it must be installed externally from your EMR cluster. Recommended read: https://aws.amazon.com/blogs/big-data/best-practices-for-securing-amazon-emr/ </p>"},{"location":"chap10/qz11_security/#question-15","title":"Question 15","text":"<p>Which of the following login is not supported by Kibana? </p> <ul> <li>Using an IAM user </li> <li>Using Cognito </li> <li>Using an email / password combination </li> </ul>"},{"location":"chap10/qz11_security/#question-16","title":"Question 16","text":"<p>Which at rest encryption is not supported by Redshift? </p> <ul> <li>KMS </li> <li>CloudHSM </li> <li>External HSM </li> <li>LUKS </li> </ul> <p>LUKS is for EMR</p>"},{"location":"chap10/qz11_security/#question-17","title":"Question 17","text":"<p>Your users are federated using the web identity provider amazon.com. What does the following policy do? </p> <p></p> <ul> <li>Allow AWS IAM users to upload and download objects from a bucket that is named after their username </li> <li>Allow users federated through amazon.com to upload and download objects from a bucket that is named after their username</li> </ul>"},{"location":"chap10/qz11_security/#question-18","title":"Question 18","text":"<p>Someone has deleted your Redshift cluster and you would like to find out who or what it was. How can  you do it? </p> <ul> <li>Use Redshift access logs </li> <li>use 53 access Logs </li> <li>Use CloudTrail </li> <li>Use IAM </li> </ul>"},{"location":"chap10/qz12_ML/","title":"Quiz12 Amazon Machine Learning and Sagemaker","text":""},{"location":"chap10/qz12_ML/#question-1","title":"Question 1:","text":"<p>What limit, if any, is there to the size of your training dataset in Amazon Machine Learning by default? </p> <ul> <li>1TB </li> <li>100GB </li> <li>50GB </li> <li>No limit </li> </ul> <p>By default, Amazon ML is limited to 100GB of training data. You can file a support ticket to get this increased, but Amazon ML cannot handle terabyte-scale data. </p>"},{"location":"chap10/qz12_ML/#question-2","title":"Question 2:","text":"<p>Is there a limit to the size of the dataset that you can use for training models with Amazon SageMaker? If so, what is the limit? </p> <ul> <li>100GB </li> <li>No fixed limit </li> <li>1TB </li> <li>50GB </li> </ul> <p>There are no fixed limits to the size of the dataset you can use for training models with Amazon SageMaker. </p>"},{"location":"chap10/qz12_ML/#question-3","title":"Question 3:","text":"<p>The audit team of an organization needs a history of Amazon SageMaker API calls made on their account for security analysis and operational troubleshooting purposes. Which of the following service helps in this regard? </p> <ul> <li>CloudTrail </li> <li>Cloud Watch </li> <li>CloudFormation </li> <li>SageMaker Logs </li> </ul> <p>SageMaker outputs its results to both CloudTrail and Cloud Watch, but CloudTrail is specifically designed for auditing purposes. </p>"},{"location":"chap10/qz12_ML/#question-4","title":"Question 4:","text":"<p>Which of the following is a new Amazon SageMaker capability that enables machine learning models to train once and run anywhere in the cloud and at the edge? </p> <ul> <li>SageMaker Neo </li> <li>SageMaker Search </li> <li>Batch Transform </li> <li>Jupyter Notebooks </li> </ul>"},{"location":"chap10/qz12_ML/#question-5","title":"Question 5:","text":"<p>A Python developer is planning to develop a machine learning model to predict real estate prices using a Jupyter notebook and train and deploy this model in a high available and scalable manner. The developer wishes to avoid worrying about provisioning sufficient capacity for this model. Which of the following services is best suited for this? </p> <ul> <li>Apache Spark </li> <li>Amazon Machine Learning </li> <li>Amazon EMR </li> <li>Amazon SageMaker</li> </ul> <p>SageMaker is the only scalable solution that is both fully managed and uses Jupyter notebooks. </p>"},{"location":"chap10/qz1_coll/","title":"Quiz1 Collection","text":""},{"location":"chap10/qz1_coll/#question-1","title":"Question 1","text":"<p>You are accumulating data from IoT devices and you must send data within 10 seconds to Amazon ElasticSearch service. That data should also be consumed by other services when needed. Which service do you recommend using? </p> <ul> <li>Kinesis Data Streams <ul> <li>Steams (click streams, IoT devices and metrics, logs)</li> <li>Great for real-time big data</li> </ul> </li> <li>Kinesis Data Firehose </li> <li>SQS </li> <li>Database Migration Service </li> </ul>"},{"location":"chap10/qz1_coll/#question-2","title":"Question 2","text":"<p>You need a managed service that can deliver data to Amazon S3 and scale automatically for you. You want to be billed only for the actual usage of the service and be able to handle peak loads. Which service do you recommend? </p> <ul> <li>Kinesis Data Streams <ul> <li>Auto Scaling is not a native feature of Kinesis Data Streams</li> </ul> </li> <li>Kinesis Data Firehose <ul> <li>Load data into Redshift Amazon S3 / ElasticSearch / Splunk</li> <li>Automatic scaling</li> <li>Pay for the amount of data going through Firehose</li> </ul> </li> <li>SQS </li> <li>Kinesis Analytics </li> </ul>"},{"location":"chap10/qz1_coll/#question-3","title":"Question 3","text":"<p>You are sending a lot of 100B data records and would like to ensure you can use Kinesis to receive your data. What should you use to ensure optimal throughput, that has asynchronous features ? </p> <ul> <li>Kinesis SDK </li> <li>Kinesis Producer Library <ul> <li>Synchronous or Asynchronous API (better performance for async)</li> <li>Batching (both turned on by default) \u2014 increase throughput, decrease cost</li> </ul> </li> <li>Kinesis Client Library </li> <li>Kinesis Connector Library </li> <li>Kinesis Agent </li> </ul> <p>(Through batching (collection and aggregation), we can achieve maximum throughput using the KPL. KPL is also supporting an asynchronous API </p>"},{"location":"chap10/qz1_coll/#question-4","title":"Question 4","text":"<p>You would like to collect log files in mass from your Linux servers running on premise. You need a retry mechanism embedded and monitoring through CloudWatch. Logs should end up in Kinesis. What will help you accomplish this? </p> <ul> <li>Kinesis SDK </li> <li>Kinesis Producer Library </li> <li>Kinesis Agent <ul> <li>Monitor Log files and sends them to Kinesis Data Streams</li> <li>Emits metrics to CloudWatch for monitoring</li> </ul> </li> <li>Direct Connect </li> </ul>"},{"location":"chap10/qz1_coll/#question-5","title":"Question 5","text":"<p>You would like to perform batch compression before sending data to Kinesis, in order to maximize the throughput. What should you use? </p> <ul> <li>Kinesis SDK </li> <li>Kinesis Producer Library Compression Feature </li> <li>Kinesis Producer Library + Implement Compression Yourself <ul> <li>Kinesis Producer Library (KPL): Compression must be implemented by the user </li> </ul> </li> </ul>"},{"location":"chap10/qz1_coll/#question-6","title":"Question 6","text":"<p>You have 10 consumers applications consuming concurrently from one shard, in classic mode by issuing Getrecords() commands. what is the the average latency for consuming these records for each application? </p> <ul> <li>70 ms </li> <li>200 ms </li> <li>1 sec </li> <li>2 sec <ul> <li>Maximum of 5 GetRecords API calls per shard per second</li> <li>10 / 5 * 2 = 2</li> </ul> </li> </ul> <p>You can issue up to 5 GetRecords API calls per second, so it'll take 2 seconds for each consuming application betore they can issue their next call </p>"},{"location":"chap10/qz1_coll/#question-7","title":"Question 7","text":"<p>You have 10 consumers applications consuming concurrently from one shard, in enhanced fan out mode. What is the average latency for consuming these records for each application? </p> <ul> <li>70 ms <ul> <li>That means 20 consumers will get 40MB/s per shard aggregated </li> <li>Reduce latency (~70 ms)</li> </ul> </li> <li>200 ms </li> <li>1 sec </li> <li>2 sec </li> </ul> <p>here, no matter how many consumers you have, in enhanced fan out mode, each consumer will receive 2MB per second of throughput and have an average latency of 70ms. </p>"},{"location":"chap10/qz1_coll/#question-8","title":"Question 8","text":"<p>You would like to have data delivered in near real time to Amazon ElasticSearch, and the data delivery to be managed by AWS. What should you use? </p> <ul> <li>Kinesis Client Library (KCL) </li> <li>Kinesis Connector Library </li> <li>Kinesis Firehose <ul> <li>Near Real Time (60 seconds latency minimum for non full batches)</li> <li>Fully Managed Service, no administration</li> </ul> </li> </ul>"},{"location":"chap10/qz1_coll/#question-9","title":"Question 9","text":"<p>You are consuming from a Kinesis stream with 10 shards that receives on average 8 MB/s of data from various producers using the KPL. You are therefore using the KCL to consume these records, and observe through the CloudWatch metrics that the throughput is 2 MB/s, and therefore your application is lagging. What's the most likely root cause for this issue? </p> <ul> <li>You need to split shards some more </li> <li>There's a hot partition </li> <li>Cloudwatch is displaying the average throughput metric, not the aggregate one </li> <li>Your DynamoDB table is under-provisioned <ul> <li>Leverages DynamoDB for coordination and checkpointing (one row per shard) <ul> <li>Make sure you provision enough WCU / RCU</li> <li>Or use On-Demand for DynamoDB</li> <li>Otherwise DynamoDB may slow down KCL</li> </ul> </li> </ul> </li> </ul> <p>Because it's under provisioned, checkpointing does not happen fast enough and results in a lower throughput for your KCL based application. Make sure to increase the RCU / WCU </p>"},{"location":"chap10/qz1_coll/#question-10","title":"Question 10","text":"<p>You would like to increase me capacity of your Kinesis streams. What should you do? </p> <ul> <li>Split Shards <ul> <li>Can be used to increase the Stream capacity ( 1 MB/s data in per shard)</li> </ul> </li> <li>Merge Shards </li> <li>Turn on Auto Scaling <ul> <li>Auto Scaling is not a native feature of Kinesis data streams</li> </ul> </li> </ul>"},{"location":"chap10/qz1_coll/#question-11","title":"Question 11","text":"<p>Which of the following statement is wrong? </p> <ul> <li>Spark Streaming can write to Kinesis Data Streams </li> <li>Spark Streaming can read from Kinesis Data Firehose </li> <li>Spark Streaming can read from Kinesis Data Streams </li> </ul>"},{"location":"chap10/qz1_coll/#question-12","title":"Question 12","text":"<p>Which of tho follnwing Kinesis Data Firehose does not write?</p> <ul> <li>S3 </li> <li>Redshift </li> <li>DynamoDB </li> <li>ElasticSearch </li> <li>Splunk <ul> <li>Load data into Redshift Amazon S3 / ElasticSearch / Splunk </li> </ul> </li> </ul>"},{"location":"chap10/qz1_coll/#question-13","title":"Question 13","text":"<p>You are looking to decouple jobs and ensure data is deleted after being processes. Which technology would you choose? </p> <ul> <li>Kinesis Data Streams </li> <li>Kinesis Data Firehose </li> <li>SQS <ul> <li>Process the message within the visibility timeout</li> <li>Delete the message using the message ID &amp; receipt handle</li> </ul> </li> </ul> <p>That means that basically when you have SQS your consumers will poll messages and you consumers will process these messages and then delete them from the SQS Queue</p>"},{"location":"chap10/qz1_coll/#question-14","title":"Question 14","text":"<p>You are collecting data from loT devices at scale and would like to forward that data into Kinesis Data Firehose. How should you proceed? </p> <ul> <li>Send that data into an loT topic and define a rule action </li> <li>Use enhanced fanout for the loT topic and send that data into Kinesis Data Streams </li> <li>Create an SNS topic, send the IoT data there and use AWS Lambda </li> <li>Send that data into an loT topic and use device shadow </li> </ul>"},{"location":"chap10/qz1_coll/#question-15","title":"Question 15","text":"<p>Which protocol is not supported by the IoT Device Gateway? </p> <ul> <li>MQTT </li> <li>Websockets </li> <li>HTTP 1.1 </li> <li>FTP </li> </ul>"},{"location":"chap10/qz1_coll/#question-16","title":"Question 16","text":"<p>You would like to control the target temperature of your room using an IoT thing thermostat. How can you change its state for target temperature even in the case it's temporarily offline? </p> <ul> <li>Send a message to the loT broker every 10 seconds until it is acknowledged by the loT thing </li> <li>Use a rules actions that triggers when the device comes back online </li> <li>Change the state of the device shadow </li> <li>Change its metadata in the thing registry </li> </ul> <p>That's precisely the purposes of the device shadow, which gets synchronized with the device when it comes back online </p>"},{"location":"chap10/qz1_coll/#question-17","title":"Question 17","text":"<p>You are looking to continuously replicate a MySQL database that's on premise to Aurora. Which service will allow you to do so securely? </p> <ul> <li>AWS Direct Connect </li> <li>Database Migration Services </li> <li>AWS Lambda </li> <li>Kinesis Data Streams </li> </ul> <p>DMC is fully secure </p>"},{"location":"chap10/qz1_coll/#question-18","title":"Question 18","text":"<p>You have setup Direct Connect on one location to ensure your traffic into AWS is going over a private network. You would like to setup a failover connection, that must be as reliable and as redundant as possible, as you cannot afford to be down for too long. What backup connection do you recommend? </p> <ul> <li>Another Direct Connect setup </li> <li>Site to Site VPN</li> <li>Client Side VPN </li> <li>Snowball Connection </li> </ul> <p>although this is not as private another Direct Connect setup, it is definitely more reliable as it leverage the public web. it is the correct answer</p>"},{"location":"chap10/qz1_coll/#question-19","title":"Question 19","text":"<p>You would like to transfer data in AWS in less than two days from now. What should you use? </p> <ul> <li>Setup Direct Connect  </li> <li>Use the Public Internet </li> <li>Use AWS Snowball </li> <li>Use AWS Snowmobile </li> </ul>"},{"location":"chap10/qz2_storage/","title":"Quiz2 Storage","text":""},{"location":"chap10/qz2_storage/#question-1","title":"Question 1","text":"<p>Your big data application is taking a lot of files from your local on-premise NFS storage and inserting them into S3. As part of the data integrity verification process, the application downloads the files right after they've been uploaded. What will happen?</p> <p>S3 is eventually consistent only for DELETE or overwrite PUT</p> <ul> <li>The application will receive a 404 as S3 is eventually consistent </li> <li>The application will receive a 200 as S3 for new PUT is strongly consistent </li> </ul>"},{"location":"chap10/qz2_storage/#question-2","title":"Question 2","text":"<p>You are gathering various files from providers and plan on analyzing them once every month using Athena, which must return the query results immediately. You do not want to run a high risk of losing files and want to minimise costs. Which storage type do you recommend?</p> <ul> <li>S3 General Purpose </li> <li>S3 Infrequent Access </li> <li>S3 One Zone Infrequent Access </li> <li>S3 Glacier </li> </ul>"},{"location":"chap10/qz2_storage/#question-3","title":"Question 3","text":"<p>As part of your compliance as a bank, you must archive all logs created by all applications and ensure they cannot be modified or deleted for at least 7 years. Which solution should you use?</p> <ul> <li>S3 General Purpose with a Bucket Policy </li> <li>Glacier with a Vault Lock Policy </li> <li>Glacier with a Vault Access Policy </li> <li>S3 Infrequent Access with a Bucket Policy </li> </ul>"},{"location":"chap10/qz2_storage/#question-4","title":"Question 4","text":"<p>You are generating thumbnails in S3 from images. Images are in the <code>images/</code> directory while thumbnails in the <code>thumbnails/</code> directory. After running some analytics, you realized that images are rarely read and you could optimise your costs by moving them to another S3 storage tiers. What do you recommend that requires the least amount of changes?</p> <ul> <li>Create two different buckets for images and thumbnails </li> <li>Change the default storage class for the bucket to S3 Infrequent Access </li> <li>Create a Lifecycle Rule for the entire bucket </li> <li>Create a Lifecycle Rule for the images/ prefix </li> </ul>"},{"location":"chap10/qz2_storage/#question-5","title":"Question 5","text":"<p>In order to perform fast big data analytics, it has been recommended by your analysts in Japan to continuously copy data from your S3 bucket in us-east-1. How do you recommend doing this at a minimal cost?</p> <ul> <li>Enable Cross Region Replication</li> <li>Create an EC2 instance in us-east-1 and run <code>s3 sync</code> with a cron job </li> <li>Create an EC2 instance in Japan and run <code>s3 sync</code> with a cron job </li> <li>Use CloudFront </li> </ul>"},{"location":"chap10/qz2_storage/#question-6","title":"Question 6","text":"<p>Your big data application is taking a lot of files from your local on-premise NFS storage and inserting them into S3. As part of the data integrity verification process, you would like to ensure the files have been properly uploaded at minimal cost. How do you proceed?</p> <ul> <li>Download the files back onto your machine and compare the MD5 hash </li> <li>Compute the local ETag for each file and compare them with AWS S3's ETag </li> <li>Download the files back onto your machine and compare the SHA-256 hash </li> </ul>"},{"location":"chap10/qz2_storage/#question-7","title":"Question 7","text":"<p>Your application plans to have 15,000 reads and writes per second to S3 from thousands of device ids. Which naming convention do you recommend?</p> <p>you get about 3k reads per second per prefix, so using the device-id will help having many prefixes and parallelize your writes</p> <ul> <li><code>&lt;device-id&gt;/yyyy-mm-dd/....</code> </li> <li><code>yyyy-mm-dd/&lt;device-id&gt;/....</code> </li> <li><code>mm-dd-yyyy/&lt;device-id&gt;/....</code> </li> <li><code>dd-mm-yyyy/&lt;device-id&gt;/....</code></li> </ul>"},{"location":"chap10/qz2_storage/#question-8","title":"Question 8","text":"<p>You are looking to have your files encrypted in S3 and do not want to manage the encryption yourself. You would like to have control over the encryption keys and ensure they're securely stored in AWS. What encryption do you recommend?</p> <ul> <li>SSE-C </li> <li>SSE-KMS </li> <li>SSE-S3 </li> <li>Client Side Encryption </li> <li>TLS encryption </li> </ul>"},{"location":"chap10/qz2_storage/#question-9","title":"Question 9","text":"<p>Your website is deployed and sources its images from an S3 bucket. Everything works fine on the internet, but when you start the website locally to do some development, the images are not getting loaded. What's the problem?</p> <ul> <li>S3 Bucket Policies </li> <li>S3 CORS </li> <li>S3 ACLs </li> <li>S3 Encryption </li> </ul>"},{"location":"chap10/qz2_storage/#question-10","title":"Question 10","text":"<p>What's the maximum number of fields that can make a primary key in DynamoDB?</p> <p>partition key + sort key</p> <ul> <li>1</li> <li>2</li> <li>3</li> <li>4</li> </ul>"},{"location":"chap10/qz2_storage/#question-11","title":"Question 11","text":"<p>What's the maximum size of a row in DynamoDB ?</p> <ul> <li>1KB</li> <li>400KB</li> <li>1MB</li> <li>400MB</li> </ul>"},{"location":"chap10/qz2_storage/#question-12","title":"Question 12","text":"<p>You are writing item of 8 KB in size at the rate of 12 per seconds. What WCU do you need?</p> <p>8 * 12</p> <ul> <li>12</li> <li>24</li> <li>48</li> <li>96</li> </ul>"},{"location":"chap10/qz2_storage/#question-13","title":"Question 13","text":"<p>You are doing strongly consistent read of 10 KB items at the rate of 10 per second. What RCU do you need?</p> <p>10 KB gets rounded to 12 KB, divided by 4KB = 3, times 10 per second = 30</p> <ul> <li>100</li> <li>30</li> <li>20</li> <li>25</li> </ul>"},{"location":"chap10/qz2_storage/#question-14","title":"Question 14","text":"<p>You are doing 12 eventually consistent reads per second, and each item has a size of 16 KB. What RCU do you need?</p> <p>we can do 2 eventually consistent reads per seconds for items of 4 KB with 1 RCU</p> <p>(12/2)*(16/4)=24</p> <ul> <li>192</li> <li>48</li> <li>24</li> <li>12</li> </ul>"},{"location":"chap10/qz2_storage/#question-15","title":"Question 15","text":"<p>We are getting a ProvisionedThroughputExceededExceptions but after checking the metrics, we see we haven't exceeded the total RCU we had provisioned. What happened?</p> <p>remember RCU and WCU are spread across all partitions</p> <ul> <li>The metrics are slow to update </li> <li>We have a hot partition / hot key </li> <li>There's a bug in the code </li> </ul>"},{"location":"chap10/qz2_storage/#question-16","title":"Question 16","text":"<p>You are about to enter the Christmas sale and you know a few items in your website are very popular and will be read often. Last year you had a ProvisionedThroughputExceededException. What should you do this year?</p> <ul> <li>Increase the RCU to a very, very high value </li> <li>Create a DAX cluster </li> <li>Migrate the database away from DynamoDB to ElastiCache for the time of the sale </li> </ul>"},{"location":"chap10/qz2_storage/#question-17","title":"Question 17","text":"<p>You would like to react in real-time to users de-activating their account and send them an email to try to bring them back. The best way of doing it is to...</p> <ul> <li>Setup a trigger with SNS </li> <li>Setup CloudWatch Events cron job that triggers a Lambda function who searches for account de-activations every 5 minutes </li> <li>Enable Kinesis Streams </li> <li>Integrate Lambda with a DynamoDB stream </li> </ul>"},{"location":"chap10/qz2_storage/#question-18","title":"Question 18","text":"<p>You would like to have DynamoDB automatically delete old data for you. What should you use?</p> <ul> <li>Use TTL </li> <li>Use DynamoDB Streams</li> <li>Use DAX </li> <li>Use a Lambda function </li> </ul>"},{"location":"chap10/qz2_storage/#question-19","title":"Question 19","text":"<p>You are looking to improve the performance of your RDS database by caching some of the most common rows and queries. Which technology do you recommend?</p> <ul> <li>Redshift </li> <li>Athena </li> <li>ElastiCache </li> <li>EBS </li> </ul>"},{"location":"chap10/qz3_lambda/","title":"Quiz3 AWS Lambda","text":""},{"location":"chap10/qz3_lambda/#question-1","title":"Question 1","text":"<p>You are going to be working with objects arriving in S3. Once they arrive you want to use AWS Lambda as a part of an AWS Data Pipeline to process and transform the data. How can you easily configure Lambda to know the data has arrived in a bucket?</p> <ul> <li>Run a cron job to check for new objects arriving in S3 </li> <li>Configure S3 bucket notifications to lambda </li> <li>Configure S3 versioning to include writing logs to Lambda Use</li> <li>Cloudwatch logs and have Cloudwatch events trigger Lambda. </li> </ul> <p>Lambda functions are generally invoked by some sort of trigger. S3 has the ability to trigger a Lambda function whenever a new object appears in a bucket.</p>"},{"location":"chap10/qz3_lambda/#question-2","title":"Question 2","text":"<p>You are going to analyze the data coming in an Amazon Kinesis stream. You are going to use Lambda to process these records. What is a prerequisite when it comes to defining Lambda to access Kinesis stream records ?</p> <ul> <li>The Kinesis stream should be in the same account </li> </ul> <p>Lambda must be in the same account as the service triggering it, in addition to having an IAM policy granting it access.</p> <ul> <li>The stream should not be older than 3 hours </li> <li>The Kinesis stream should have its policy document to allow for AWS Lambda </li> </ul> <p>It's actually Lambda that needs an IAM policy allowing Kinesis access, not the other way around.</p> <ul> <li>None of these </li> </ul>"},{"location":"chap10/qz3_lambda/#question-3","title":"Question 3","text":"<p>How can you make sure your Lambda functions have access to the other resources you are using in your big data architecture like S3, Redshift, etc.?</p> <ul> <li>Using a lifecycle policy for lambda </li> <li>Using proper IAM users </li> <li>Using proper IAM roles </li> <li>Using Cognito pools. </li> </ul> <p>IAM roles define the access a Lambda function has to the services it communicates with.</p>"},{"location":"chap10/qz3_lambda/#question-4","title":"Question 4","text":"<p>You are creating a Lambda - Kinesis stream environment in which Lambda is to check for the records in the stream and do some processing in its Lambda function. How does Lambda know there has been changes / updates to the Kinesis stream ?</p> <ul> <li>Kinesis streams has options to configure cron jobs to invoke Lambda </li> <li>Cloudwatch logs notify Lambda </li> <li>Kinesis streams notify lambda </li> </ul> <p>Conceptually this might be how you think of a Lambda trigger, but it's not how it actually works under the hood.</p> <ul> <li>Lambda polls Kinesis streams </li> </ul> <p>Although you think of a trigger as \"pushing\" events, Lambda actually polls your Kinesis streams for new activity.</p>"},{"location":"chap10/qz3_lambda/#question-5","title":"Question 5","text":"<p>When using an Amazon Redshift database loader, how does Lambda keep track of files arriving in S3 to be processed and sent to Redshift ?</p> <ul> <li>In a DynamoDB table</li> <li>In Lambda memory </li> <li>In Lambda parameters </li> <li>In Redshift cluster memory </li> </ul>"},{"location":"chap10/qz4_glue/","title":"Quiz4 AWS Glue","text":"<p>Check your knowledge on some of the finer points of AWS Glue crawlers, data catalogs, and ETL jobs.</p>"},{"location":"chap10/qz4_glue/#question-1","title":"Question 1","text":"<p>You want to load data from a MySQL server installed in an EC2 t2.micro instance to be processed by AWS Glue. What applies the best here?</p> <ul> <li>Not possible with instance, must use RDS </li> <li>MySQL configuration should have glue support enabled </li> <li>Instance should be in your VPC </li> </ul> <p>Although we didn't really discuss access controls, you could arrive at this answer through process of elimination. You'll find yourself doing that on the exam a lot. This isn't really a Glue specific question; it's more about how to connect an AWS service such as Glue to EC2.</p>"},{"location":"chap10/qz4_glue/#question-2","title":"Question 2","text":"<p>What is the simplest way to make sure the metadata under Glue Data Catalog is always up-to-date and in-sync with the underlying data without your intervention each time?</p> <ul> <li>Schedule crawlers to run periodically </li> <li>Using Glue API </li> <li>Using the AWS console </li> </ul> <p>Crawlers may be easily scheduled to run periodically while defining them.</p>"},{"location":"chap10/qz4_glue/#question-3","title":"Question 3","text":"<p>Which programming languages can be used to write ETL code for AWS Glue?</p> <ul> <li>Python and Java </li> <li>Python and Scala </li> <li>Python and Node.js </li> <li>Scala and C# </li> </ul> <p>Glue ETL runs on Apache Spark under the hood, and these happen to be the primary languages used for Spark development.</p>"},{"location":"chap10/qz4_glue/#question-4","title":"Question 4","text":"<p>Can you run existing ETL jobs with AWS Glue?</p> <ul> <li>Yes</li> </ul> <p>You can run your existing Scala or Python code on AWS Glue. Simply upload the code to Amazon S3 and create one or more jobs that use that code. You can reuse the same code across multiple jobs by pointing them to the same code location on Amazon S3.</p>"},{"location":"chap10/qz4_glue/#question-5","title":"Question 5","text":"<p>How can you be notified of the execution of AWS Glue jobs?</p> <ul> <li>Using Cloudwatch + SNS </li> <li>Using Cloudwatch + SES </li> <li>Using Glue events + SES </li> </ul> <p>AWS Glue outputs its progress into CloudWatch, which in turn may be integrated with the Simple Notification Service.</p>"},{"location":"chap10/qz5_emr/","title":"Quiz5 EMR and the Hadoop Ecosystem","text":""},{"location":"chap10/qz5_emr/#question-1","title":"Question 1","text":"<p>Of the following tools with Amazon EMR, which one is used for querying multiple data stores at once?  </p> <ul> <li>Presto </li> <li>Hue</li> <li>Ganglia </li> <li>Ambari </li> </ul>"},{"location":"chap10/qz5_emr/#presto","title":"Presto","text":"<p>It can connect to many different \"big data\" databases and data stores at once, and query across them</p>"},{"location":"chap10/qz5_emr/#hue","title":"Hue","text":"<p>Graphical front-end for applications on your EMR cluster </p> <p>Ganglia (monitoring like cloudwatch) </p>"},{"location":"chap10/qz5_emr/#question-2","title":"Question 2","text":"<p>Which one of the following statements is NOT TRUE regarding EMR Notebooks? </p> <ul> <li>EMR notebook is stopped if is idle for an extended time </li> <li>EMR Notebooks currently do not integrate with repositories for version control. </li> <li>EMR Notebooks can be opened without logging into the AWS Management Console </li> <li>You cannot attach your notebook to a Kerberos enabled EMR cluster </li> </ul> <p>To create or open a notebook and run queries on your EMR cluster you need to log into the AWS Management Console. </p> <p>Kerberos</p> <p>Kerberos is a way of providing strong authentication through secret key cryptography.</p> <p>This is a network authentication protocol that ensures that passwords or other credentials aren't sent over the network in an unencrypted format</p>"},{"location":"chap10/qz5_emr/#question-3","title":"Question 3","text":"<p>How can you get a history of all EMR API calls made on your account for security or compliance auditing? </p> <ul> <li>Using CloudWatch </li> <li>Using AWS CloudTrail </li> <li>Using EMR logs </li> <li>Using AWS Gateway </li> </ul> <p>CloudTrail integration is one of the ways in which EMR integrates with AWS. </p>"},{"location":"chap10/qz5_emr/#question-4","title":"Question 4","text":"<p>If you don't want the data on your cluster to be ephemeral, be sure to store or copy it in S3. </p> <p>When you delete your EMR cluster, what happens to the EBS volumes? </p> <ul> <li>EMR will delete the volumes once the EMR cluster is terminated. </li> <li>EBS volumes are preserved </li> </ul>"},{"location":"chap10/qz5_emr/#question-5","title":"Question 5","text":"<p>Which one of the following statements is NOT TRUE regarding Apache Pig? </p> <ul> <li>Pig supports interactive and batch cluster types </li> <li>Pig is operated by a SQL-like language called Pig Latin </li> <li>When used with Amazon EMR, Pig allows accessing multiple filesystems </li> <li>Pig supports access through JDBC </li> </ul>"},{"location":"chap10/qz6_ka/","title":"Quiz6 Kinesis Analytics","text":""},{"location":"chap10/qz6_ka/#question-1","title":"Question 1","text":"<p>From which sources can the input for Kinesis analytics be obtained ? </p> <ul> <li>MySQL and Kinesis Data Streams </li> <li>DynamoDB and Kinesis Firehose deliver streams </li> <li>Kinesis data streams and Kinesis Firehose delivery streams </li> <li>Kinesis Data Streams and DynamoDB </li> </ul> <p>Kinesis Analytics can only monitor streams from Kinesis, but both data streams and Firehose are supported. </p>"},{"location":"chap10/qz6_ka/#question-2","title":"Question 2","text":"<p>After real-time analysis has been performed on the input source, where may you send the processed data for further processin ? </p> <ul> <li>Amazon S3 </li> <li>Redshift </li> <li>Athena </li> <li>Kinesis Data Stream or Firehose </li> <li>All of the above </li> </ul> <p>While you might in turn connect S3 or Redshift to your Kinesis Analytics output stream, Kinesis Analytics must have a stream as its input, and a stream or Lambda function as its output. </p>"},{"location":"chap10/qz6_ka/#question-3","title":"Question 3","text":"<p>If a record arrives late to your application during stream processing, what happens to it? </p> <ul> <li>The record is written to the error stream</li> <li>The record is processed with the late timestamp </li> <li>The record is discarded entirely </li> <li>None of the above </li> </ul> <p>Application error stream:</p> <p>Certain records like a type mismatch or late arrival wiil be written out to the erro stream. </p>"},{"location":"chap10/qz6_ka/#question-4","title":"Question 4","text":"<p>You have heard from your AWS consultant that Amazon Kinesis Data Analytics elastically scales the application to accommodate the data a-IVUULpUa. What though is defaultfault capacity of the processing application in terms of memory? </p> <ul> <li>48GB </li> <li>12GB </li> <li>24GB </li> <li>32GB</li> </ul> <p>Kinesis Data Analytics provisions capacity in the form of Kinesis Processing Units (KPU). A single KPU provides you with the memory (4 GB) and corresponding computing and networking. The default limit for KPUs for your application is eight. </p>"},{"location":"chap10/qz6_ka/#question-5","title":"Question 5","text":"<p>You have configured data analytics and have been streaming the source data to the application. You have also configured the destination correctly. However, even after waiting for a while, you are not seeing any data come up in the destination. What might be a possible cause? </p> <ul> <li>Issue with IAM role </li> <li>Mismatched name for the output stream </li> <li>Destination service is currently unavailable </li> <li>Any of the above </li> </ul>"},{"location":"chap10/qz7_ES/","title":"Quiz7 Amazon ES","text":""},{"location":"chap10/qz7_ES/#question-1","title":"Question 1","text":"<p>How can you ensure maximum security for your Amazon ES cluster? </p> <ul> <li>Bind with a VPC </li> <li>Use security groups </li> <li>Use IAM policies </li> <li>Use access policies associated with the Elasticsearch domain creation </li> <li>All of the above </li> </ul>"},{"location":"chap10/qz7_ES/#question-2","title":"Question 2","text":"<p>As recommended by AWS, you are going to ensure you have dedicated master nodes for high performance. As a user, what can you configure for the master nodes? </p> <ul> <li>The count and instance types of the master nodes </li> <li>The EBS volume associated with the node </li> <li>The upper limit of network traffic / bandwidth </li> <li>All of the above. </li> </ul>"},{"location":"chap10/qz7_ES/#question-3","title":"Question 3","text":"<p>Which are supported ways to import data into your Amazon ES domain? </p> <ul> <li>Directly from an RDS instance</li> <li>Via Kinesis, Logstash, and Elasticsearch's API's</li> <li>Via Kinesis, SQS, and Beats </li> <li>Via SOS, Firehose, and Logstash </li> </ul> <p>Kinesis, DynamoDB, Logstash / Beats, and Elasticsearch's native API's offer means to import data into Amazon ES. </p> <p>No SQS </p>"},{"location":"chap10/qz7_ES/#question-4","title":"Question 4","text":"<p>What can you do to prevent data loss due to nodes within your ES domain failing? </p> <ul> <li>Raise a ticket with AWS support to have the ES launched in 2 or more regions at a time </li> <li>Use the multi-AZ balancing feature </li> <li>Maintain snapshots of the Elasticsearch Service domain </li> <li>Enable serverless mode in Amazon ES </li> </ul> <p>Amazon ES created daily snapshots to S3 by default, and you can create them more often if you wish. </p>"},{"location":"chap10/qz7_ES/#question-5","title":"Question 5","text":"<p>You are going to setup an Amazon ES cluster and have it configured in your VPC. You want your customers outside your VPC to visualize the logs reaching the ES using Kibana. How can this be achieved? </p> <ul> <li>Use a reverse proxy </li> <li>Use a VPN </li> <li>Use VPC Direct Connect </li> <li>Any of the above. </li> </ul>"},{"location":"chap10/qz8_athena/","title":"Quiz8 Amazon Athena","text":""},{"location":"chap10/qz8_athena/#question-1","title":"Question 1","text":"<p>As a Big Data analyst, you need to query/analyze data from a set of CSV files stored in S3. Which of the following serverless services helps you with this? </p> <ul> <li>AWS Glacier </li> <li>AWS EMR </li> <li>AWS Athena </li> <li>AWS Redshift </li> </ul>"},{"location":"chap10/qz8_athena/#question-2","title":"Question 2","text":"<p>What are two columnar formats supported by Athena </p> <ul> <li>GZip and LZO </li> <li>AVRO and Parquet </li> <li>AVRO and ORC </li> <li>Parquet and ORC </li> </ul>"},{"location":"chap10/qz8_athena/#question-3","title":"Question 3","text":"<p>Your organization is querying JSON data stored in S3 using Athena, and wishes to reduce costs and improve performance with Athena. What steps might you take? </p> <ul> <li>Reduce the server count for Athena </li> <li>Convert the data from JSON to ORC format, and analyze the ORC data with Athena </li> <li>Convert the data from JSON to AVRO format, and analyze the AVRO data with Athena </li> <li>Enable slow logging for Athena </li> </ul> <p>\"Slow logs\" is a feature in Amazon Elasticsearch Service, but it's not a thing with Athena. </p> <p>Athena is serverless; this isn't something you control. </p> <p>Using columnar formats such as ORC and Parquet can reduce costs 30-90%, while improving performance at the same time.</p>"},{"location":"chap10/qz8_athena/#question-4","title":"Question 4","text":"<p>When using Athena, you are charged separately for using the AWS Glue Data Catalog. True or False ? </p> <ul> <li>True </li> <li>False </li> </ul>"},{"location":"chap10/qz8_athena/#question-5","title":"Question 5","text":"<p>Which of the following statements is NOT TRUE regarding Athena pricing? </p> <ul> <li>Amazon Athena charges you for cancelled queries </li> <li>Amazon Athena charges you for failed queries </li> <li>You will get charged less when using a columnar format </li> <li>Amazon Athena is priced per query and charges based on the amount of data scanned by the query </li> </ul>"},{"location":"chap10/qz9_redshift/","title":"Quiz9 Amazon Redshift","text":""},{"location":"chap10/qz9_redshift/#question-1","title":"Question 1","text":"<p>You are working as Big Data Analyst of a data warehousing company. The company uses RedShift clusters for data analytics. For auditing and compliance purpose, you need to monitor API calls to  RedShift instance and also provide secured data. </p> <p>Which of the following services helps in this regard ? </p> <ul> <li>CloudTrail logs </li> <li>Cloud Watch logs </li> <li>Redshift Spectrum </li> <li>AmazonMQ </li> </ul>"},{"location":"chap10/qz9_redshift/#question-2","title":"Question 2","text":"<p>You are working as a Big Data analyst of a Financial enterprise which has a large data set that needs to have columnar storage to reduce disk IO. It is also required that the data should be queried fast so as to generate reports. Which of the following service is best suited for this scenario? </p> <ul> <li>DynamoDB </li> <li>RDS </li> <li>Athena </li> <li>Redshift </li> </ul>"},{"location":"chap10/qz9_redshift/#question-3","title":"Question 3","text":"<p>You are working for a data warehouse company that uses Amazon RedShift cluster. It is required that VPC flow logs is used to monitor all COPY and UNLOAD traffic of the cluster that moves in and out of the VPC. Which of the following helps you in this regard ? </p> <ul> <li>By using RedShift Spectrum </li> <li>By enabling Enhanced VPC routing on the Amazon Redshift cluster </li> <li>By using RedShift WLM </li> <li>By enabling audit logging in the Redshift cluster </li> </ul>"},{"location":"chap10/qz9_redshift/#question-4","title":"Question 4","text":"<p>You are working for a data warehousing company that has large datasets (20TB of structured data and 20TB of unstructured data). They are planning to host this data in AWS with unstructured data storage on S3. At first they are planning to migrate the data to AWS and use it for basic analytics and are not worried about performance. Which of the following options fulfills their requirement? </p> <ul> <li>node type ds2.xlarge </li> <li>node type ds2.8xlarge </li> <li>with node type dc2.8xlarge </li> <li>node type dc2.xlarge </li> </ul> <p>Since they are not worried about performance, storage (ds) is more important than computing power (dc,) and expensive 8xlarge instances aren't necessary. </p>"},{"location":"chap10/qz9_redshift/#question-5","title":"Question 5","text":"<p>Which of the following services allows you to directly run SQL queries against exabytes of unstructured  data in Amazon S3? </p> <ul> <li>Athena </li> <li>Redshift Spectrum </li> <li>Elasticache </li> <li>RDS </li> </ul>"},{"location":"chap10/qz_final/","title":"AWS Certified Data Analytics Specialty Practice Exam","text":""},{"location":"chap10/qz_final/#question-1","title":"Question 1","text":"<p>What are THREE ways in which EMR integrates Pig with Amazon S3? </p> <ul> <li>Submitting work from the EMR console using Pig scripts stored in S3  (Correct) </li> <li>Loading custom JAR files from S3 with the REGISTER command (Correct)</li> <li>Integration with AWS Glue to infer schemas on S3 data </li> <li>Directly writing to HCatalog tables in S3 (Correct) </li> <li>Importing permissions from S3 buckets for use in your Pig Latin scripts </li> </ul> <p>Explanation You can configure EMRFS, backed by S3, as your data store in Pig, which allows it to read and write to S3 as it would with HDFS. </p>"},{"location":"chap10/qz_final/#question-2","title":"Question 2","text":"<p>An organization has a large body of web server logs stored on Amazon S3, and wishes to quickly analyze their data using Amazon Athena. Most queries are operational in nature, and are limited to a single day's logs.</p> <p>How should the log data be prepared to provide the most performant queries in Athena, and to minimize costs? </p> <ul> <li>Convert the data into Apache Parquet format, compressed with Snappy, stored in a directory structure of <code>year=XXXX/month=XX/day=XX/</code>   (Correct)</li> <li>Convert the data into AVRO format, with filenames that may be sorted by date </li> <li>Convert the data into Apache ORC format, uncompressed, and rotate their LI directories daily </li> <li>Compress the log data with gzip, and rotate their directories daily </li> </ul> <p>Explanation Athena works best with columnar data; Parquet and ORC are both examples of columnar formats (Gzip and AVRO are not.) </p> <p>Compressing the data will allow them to be transferred more efficiently, and partitioning it using the \"partition key=value\" format in directory names further allows Athena to process only the data it needs. </p>"},{"location":"chap10/qz_final/#question-3","title":"Question 3:","text":"<p>A large news website needs to produce personalized recommendations for articles to its readers, by training a machine learning model on a daily basis using historical click data. The influx of this data is fairly constant, except during major elections when traffic to the site spikes considerably. </p> <p>Which system would provide the most cost-effective and reliable solution? </p> <ul> <li>Publish click data into Amazon Elasticsearch using Kinesis Firehose, and query  the Elasticsearch data to produce recommendations in real-time. </li> <li>Publish click data into Amazon S3 using Kinesis Streams, and process the data in real time using Splunk on an EMR cluster with spot instances added as needed.Publish the model's results to DynamoDB for producing recommendations in real-time. </li> <li>Publish click data into Amazon S3 using Kinesis Firehose, and process the data nightly using Apache Spark and MLLib using spot instances in an EMR cluster. Publish the model's results to DynamoDB for producing recommendations in real-time.  (Correct)</li> <li>Publish click data into Amazon S3 using Kinesis Firehose, and process the data nightly using Apache Spark and MLLib using reserved instances in an EMR cluster. Publish the model's results to DynamoDB for producing recommendations in real-time.</li> </ul> <p>Explanation</p> <p>The use of spot instances in response to anticipated surges in usage is the most cost-effective approach for scaling up an EMR cluster, which rules out \"Publish click data into Amazon S3 using Kinesis Firehose, and process the data nightly using Apache Spark and MLLib using reserved instances in an EMR cluster. Publish the model's results to DynamoDB for producing recommendations in real-time.\". </p> <p>Kinesis streams is over-engineering because we do not have a real-time streaming requirement, ruling out \"Publish click data into Amazon S3 using Kinesis Streams, and process the data in real time using Splunk on an EMR cluster with spot instances added as needed. Publish the model's results to DynamoDB for producing recommendations in real-time.\" </p> <p>\"Publish click data into Amazon Elasticsearch using Kinesis Firehose, and query the Elasticsearch data to produce recommendations in real-time.\" doesn't make sense because Elasticsearch is not a recommender engine. </p>"},{"location":"chap10/qz_final/#question-4","title":"Question 4:","text":"<p>Of the 4 four types of identity principals for authentication supported by AWS IoT, which one is commonly used by mobile applications? </p> <ul> <li>IAM users, groups and roles </li> <li>X.509 certificates </li> <li>Federated Identities  </li> <li>Cognito Identities (Correct)</li> </ul> <p>Explanation </p> <p>For IoT mobile applications, the standard is to leverage Cognito. </p>"},{"location":"chap10/qz_final/#question-5","title":"Question 5:","text":"<p>An e-commerce company wishes to assign product categories, such as sporting goods or books, to new products that have no category assigned to them. The company has a large corpus of existing product data with manually assigned categories in place. They wish to use their existing data to predict categories on new products, based on other attributes of the products such as its keywords and seller ID, using Amazon Machine Learning. </p> <p>Which type of machine learning model would they use? </p> <ul> <li>Binary classification model </li> <li>Multi-class classification model  (Correct)</li> <li>Regression model </li> <li>Unary classification model </li> </ul> <p>Explanation </p> <p>Since you are trying to predict categorical data and there are more than two categories, this is a multi-class classification model. Unary classification isn't really a thing. Under the hood, Amazon ML would use a logistic regression to implement a classification model. </p>"},{"location":"chap10/qz_final/#question-6","title":"Question 6:","text":"<p>You are looking to reduce the latency down from your Big Data processing job that operate in Singapore but source data from Virginia. The Big Data job must always operate against the latest version of the data. What do you recommend? </p> <ul> <li>Enable S3 Cross Region Replication (Correct)</li> <li>Install a CloudFront distribution on top of your S3 bucket</li> <li>Use S3 Transfer Acceleration </li> <li>Create a Data Pipeline job to transfer the data regularly between two S3 buckets located in different regions </li> </ul> <p>Explanation </p> <p>Here to reduce the latency you must move the data to another S3 bucket. The DataPipeline job may work but won't be able to replicate the latest data continuously, and CloudFront will cache some data and may provide outdated data to the Big Data Job. S3 Transfer acceleration will not help. Here, you must enable S3 Cross Region Replication </p>"},{"location":"chap10/qz_final/#question-7","title":"Question 7:","text":"<p>You are deploying your web servers being a Load Balancer. The Load Balancer is in a public subnet and the web servers sit in a private subnet. For security reasons, the private subnet does not have access to internet and you would like to ensure the web servers within this subnet have access to DynamoDB. What do you recommend? </p> <ul> <li>Enable Direct Connect between your VPC and DynamoDB </li> <li>Create an Internet Gateway in the public subnet </li> <li>Create a DynamoDB table within your VPC and attach a security group to it LI authorizing traffic from your EC2 instances. </li> <li>Provision a VPC Endpoint Gateway (Correct)</li> </ul> <p>Explanation </p> <p>An internet gateway will work but will break the security in place. Direct Connect only helps connecting on premise data centers to AWS VPC. DynamoDB tables cannot be provisioned within a VPC. So you need to create a VPC Endpoint of type Gateway (please note they're not Interfaces, they're gateway). </p>"},{"location":"chap10/qz_final/#question-8","title":"Question 8:","text":"<p>A financial services company has a large, secure data lake stored in Amazon S3. They wish to analyze this data using a variety of tools, including Apache Hive, Amazon Athena, Amazon Redshift, and Amazon QuickSight. </p> <p>How should they connect their data and analysis tools in a way that minimizes costs and development work? </p> <ul> <li>Use the AWS Database Migration Service to load the S3 data into an Amazon Aurora database, and use replication to keep the data in sync. Connect Hive, Athena, Redshift, and QuickSight to the Aurora database. </li> <li>Write an Apache Spark script on EMR to transform and load the S3 data nightly into Amazon Redshift. Connect Hive, Athena, and Quicksight to the Redshift cluster. </li> <li>Write an Apache Spark script on EMR to transform the S3 data into a Hive database on a nightly basis, connect Redshift to the Hive repository, and connect Athena and QuickSight to Redshift. </li> <li>Run an AWS Glue Crawler on the data lake to populate a AWS Glue Data Catalog. Share the glue data catalog as a metadata repository between Athena, Redshift, Hive, and QuickSight.  (Correct)</li> </ul> <p>Explanation </p> <p>AWS Glue crops up a lot on the exam. Knowing that Glue can be used to connect to Athena, Redshift, and Quicksight - as well as being used as a Hive metastore -is key to understanding this question. The other options are unnecessarily complex and require development work that could be avoided with Glue. </p>"},{"location":"chap10/qz_final/#question-9","title":"Question 9:","text":"<p>You are working for a data warehouse company that uses Amazon RedShift cluster. For security reasons, it is required that VPC flow logs should be analyzed by Athena to monitor all COPY and UNLOAD traffic of the cluster that moves in and out of the VPC. Which of the following helps you in this regard ? </p> <ul> <li>Use Redshift WLM </li> <li>Use Redshift Spectrum </li> <li>By enabling audit logging in Redshift cluster </li> <li>Use Enhanced VPC Routing  (Correct)</li> </ul> <p>Explanation </p> <p>Enhanced VPC Routing forces Redshift to use the VPC for all COPY and UNLOAD commands, which in turn will help us make sure that all that traffic appears on the VPC Flow logs. </p>"},{"location":"chap10/qz_final/#question-10","title":"Question 10","text":"<p>Users of your Redshift cluster include analysts running complex, long-running queries as well as automated systems running short, transactional read-only queries. During peak usage times, your transactional queries are timing out while the analysts are running their jobs. What would be the simplest solution to this problem? </p> <ul> <li>Use Automatic WLM with concurrency scaling</li> <li>Resize the cluster with Elastic Resize </li> <li>Use Short Query Acceleration (SQA)   (Correct)</li> <li>Use Manual WLM with concurrency scaling </li> </ul> <p>Explanation </p> <p>SQA can be used in place of WLM as a simple way to ensure short queries are not scheduled behind longer ones. </p>"},{"location":"chap10/qz_final/#question-11","title":"Question 11","text":"<p>You are running a Glue ETL job on a schedule to transform new log data from your webservers stored in S3. What is the simplest approach for ensuring data is not re-processed in subsequent job runs? </p> <ul> <li>Delete data from S3 once it is processed </li> <li>Use job bookmarks    (Correct)</li> <li>Enable the \"data tracking\" feature in Glue </li> <li>Use a DynamoDB table to track where each job left off </li> </ul> <p>Explanation </p> <p>Job bookmarks are made for this use case. The \"data tracking\" feature doesn't exist, and the other options are more complex. </p>"},{"location":"chap10/qz_final/#question-12","title":"Question 12","text":"<p>You are tasked with using Hive on Elastic MapReduce to analyze data that is currently stored in a large relational database. </p> <p>Which approach could meet this requirement? </p> <ul> <li>Extract the database into csv files in Amazon S3, and point your EMR file systpm to that S3 bucket </li> <li>Use AWS Glue to create a Hive metastore used by your EMR cluster </li> <li>Use Apache Sqoop on the EMR cluster to copy the data into HDFS (Correct)</li> <li>Use Apache Flume to stream data from the database into HDFS </li> </ul> <p>Explanation </p> <p>Sqoop is an open-source system for transferring data between Hadoop and relational databases. </p> <p>Flume is intended for real-time streaming applications, Glue is intended for use with S3, and you can't direct EMRFS to arbitrary S3 buckets. </p>"},{"location":"chap10/qz_final/#question-13","title":"Question 13","text":"<p>Your management wants a dashboard to monitor current revenue against their annual revenue goal. Whick Quicksight visualization would be most appropriate? </p> <ul> <li>KPI</li> <li>Donut Chart </li> <li>Line Chart</li> <li>Pie Chart </li> </ul> <p>Explanation </p> <p>KPI, or Key Performance Indicator, is a newer visualization in Quicksight that lets you visualize a comparison between a key value and its target value. </p>"},{"location":"chap10/qz_final/#question-14","title":"Question 14","text":"<p>A company wishes to copy 500GB of data from their Amazon Redshift cluster into an Amazon RDS PostgreSQL database, in order to have both columnar and row-based data stores available. The Redshift cluster will continue to receive large amounts of new data every day that must be kept in sync with the RDS database. </p> <p>What strategy would be most efficient? </p> <ul> <li>Use the Amazon Database Migration Service to sync the two databases using replication </li> <li>Use a materialized view to cache data between the databases, refreshing it periodically using Amazon Lambda </li> <li>Copy data using the dblink function into PostgreSQL tables (Correct) </li> <li>Use AWS Glue to allow both databases to share a common metadata store </li> </ul> <p>Explanation </p> <p>Dblink allows you to offload queries in Redshift to another database entirely. A materialized view could work for this, but it will always copy from the beginning of the table, and not just handle what has changed since the last incremental update. Read through https://amzn.to/2fraaHv if this question confused you. </p>"},{"location":"chap10/qz_final/#question-15","title":"Question 15","text":"<p>Your company collects data from various sources into Kinesis and the stream is delivered using Kinesis Data Firehose into S3. Once in S3, your data scientist team uses Athena to query the most recent data, and usage has shown that after a month, the team queries the data less and less, and finally after two months does not use it. For regulatory reasons, it is required to keep all the data for 5 years and no one should be able to delete it. What do you recommend? (select two)  after 60 days. </p> <ul> <li>Create a lifecycle rule to migrate the data to S3 IA after 30 days and Glacier </li> <li>Implement a Glacier Vault Lock Policy (Correct)</li> <li>Implement a Glacier Vault Access Policy </li> <li>Create a lifecycle rule to migrate the data to S3 Athena one day 1 and S3 Athena IA after 30 days. </li> <li>Create a lifecycle rule to migrate all the data to S3 IA after 30 IA days and delete the data after 60 days. Create a rule to have a replica of all source data into Glacier from the first day.  (Correct)</li> </ul> <p>Explanation </p> <p>S3 Athena is not a storage class. Data should be moved to S3 IA after 30 days. If the data is moved to Glacier after 60 days, then there are no guarantees for it not to be deleted by anyone for the first 60 days. Hence a replica of the data should be delivered to Glacier right away. Finally, to prevent deletion in Glacier, you must use a Glacier Vault Lock Policy. </p>"},{"location":"chap10/qz_final/#question-16","title":"Question 16:","text":"<p>A user or application has been changing configuration on your production S3 bucket and you would like to understand who did this. What do you recommend? </p> <ul> <li>Analyze the S3 access logs with Athena </li> <li>Use CloudTrail </li> <li>Use the IAM action logs </li> <li>Write a custom S3 bucket policy </li> </ul> <p>Explanation </p> <p>Very simply, we're looking at searching through API calls done on your account, which CloudTrail was made for. </p>"},{"location":"chap10/qz_final/#question-17","title":"Question 17:","text":"<p>A hospital monitoring sensor data from heart monitors wishes to raise immediate alarms if an anomaly in any individual's heart rate is detected. Which architecture meets these requirements in a scalable manner? </p> <ul> <li>Publish sensor data into S3, and use Kinesis Firehose to publish the data into a Spark Streaming application that detects anomalies and raises alarms. </li> <li>Publish sensor data into a Kinesis data stream, and route the data into a custom application on an EC2 instance that analyzes the data for anomalies and sends out alarms as needed. </li> <li>Publish sensor data into a Kinesis data stream, and create a Kinesis Data Analytics application using <code>RANDOM_CUT_FOREST</code> to detect anomalies. When an anomaly is detected, use a Lambda function to route an alarm to Amazon SNS. (Correct)</li> <li>Publish sensor data into S3, and use AWS Glue to query the data using Amazon Redshift Spectrum. Run a periodic script to query the data for anomalies using SQL and raise alarms when needed</li> </ul> <p>Explanation </p> <p><code>RANDOM_CUT_FOREST</code> is a function in Kinesis Data Analytics intended for anomaly detection. By using serverless services such as Kinesis, Lambda, and SNS we ensure the scalability of this system, and the choice of Kinesis Streams instead of Firehose ensures real-time delivery of the data. </p>"},{"location":"chap10/qz_final/#question-18","title":"Question 18:","text":"<p>You are launching an EMR cluster and plan on running custom python scripts that will end up invoking custom Lambda functions deployed within your VPC. How can you ensure the EMR cluster has the right to invoke the functions?  \u2014taws/credentials file </p> <ul> <li>Create an IAM user and put the credentials into the <code>~/.aws/credentials</code> file</li> <li>Create an IAM role and attach it to the EMR instances (Correct) </li> <li>Attach a VPC Endpoint to Lambda and map a route to EMR </li> <li>Create an AWS Lambda policy and authorize the EMR cluster security groups</li> </ul> <p>Explanation </p> <p>As EMR is made of EC2 instances, the best and most secure way for them to be allowed to invoke a Lambda function is to attach IAM roles. There's no Lambda policy or VPC Endpoint that can help for that matter. </p>"},{"location":"chap10/qz_final/#question-19","title":"Question 19:","text":"<p>You would like to process data coming from IoT devices, and processing that date takes approximately 2 minutes per data point. You would also like to be able to scale in terms of number of processes that will consume that data, based on the load your are receiving, and no ordering constraints are required. What do you recommend? </p> <ul> <li>Define an IoT rules actions to send data to Kinesis Data Firehose and consume with AWS Lambda </li> <li>Define an ioT rules actions to send data to Kinesis Data Streams and consume the data with AWS Lambda </li> <li>Define an IoT rules actions to send data to SQS and consume the LI data with EC2 instances in an Auto Scaling group   (Correct) </li> <li>Define an loT rules actions to send data to Kinesis Data Streams and consume -1 the data with KCL </li> </ul> <p>Explanation </p> <p>Kinesis Data Streams doesn't work because it doesn't scale as the load increases.</p> <p>Kinesis Data Firehose doesn't work as Lambda cannot be a consumer of KDF. Lambda can only be used for transformations of data going through KDF before being delivered to S3, Redshift, ElasticSearch or Splunk. </p> <p>Here the lack of ordering and the fact the processing may be long, and needs to scale based on the number of messages make SQS a great fit, that will also be more cost efficient </p>"},{"location":"chap10/qz_final/#question-20","title":"Question 20:","text":"<p>A produce export company has multi-dimensional data for all of its shipments, such as the date, price, category, and destination of every shipment. A data analyst wishes to explore this data, with the primary purpose of looking for trends and outliers in the information. </p> <p>Which QuickSight visualization would be best suited for this? </p> <ul> <li>Stacked horizontal bar chart </li> <li>Heat map </li> <li>Pivot table </li> <li>Scatter plot </li> </ul> <p>Explanation </p> <p>You can think of heat maps as pivot tables that highlight outliers and trends using color. </p>"},{"location":"chap10/qz_final/#question-21","title":"Question 21:","text":"<p>Your data lake in S3 for user transaction data is stored in CSV format. To save costs, data older than one year is archived to Glacier. You have received a request from your legal team to retrieve any records for a specific user ID going back seven years, and they need it today. What is the most cost-effective way to fulfill their request? </p> <ul> <li>Import the Glacier data into Redshift and query it there </li> <li>Use Glacier Select to run a query against the Glacier data for this user ID, and merge it with the same query run with S3 Select.   (Correct)</li> <li>Use S3 Select to automatically query both S3 and Glacier together </li> <li>Restore 7 years' of data from Glacier to S3, query the S3 data with Athena then delete the restored data. </li> </ul> <p>Explanation </p> <p>Glacier Select allows you to perform filtering directly against Glacier objects using standard SQL statements. It is the simplest, quickest, and most cost-effective option for querying cold data stored in Glacier. </p>"},{"location":"chap10/qz_final/#question-22","title":"Question 22:","text":"<p>An Amazon Elasticsearch domain has been installed within a VPC. </p> <p>What are TWO methods which could be employed to securely allow access to Kibana from outside the VPC? </p> <ul> <li>Set up a reverse proxy server between your browser and Amazon Elasticsearch servcer (Correct)</li> <li>Configurean IAM policy to your browser to access Kibana. </li> <li>Create a security group to allow your IP access to the subnet attached to the VPC on port 443</li> <li>Use KMS between your browser and Kibana. </li> <li>Set up an SSH tunnel with port forwarding to allow access on on port 5601. (Correct)</li> </ul> <p>Explanation </p> <p>Kibana runs on port 5601 by default, so opening up port 443 won't help. IAM doesn't know about your browser, and KMS does not integrate with Kibana. </p>"},{"location":"chap10/qz_final/#question-23","title":"Question 23:","text":"<p>You need to add more nodes to your Redshift cluster and change the node type in the process. Which process allows you to do this while minimizing downtime? </p> <ul> <li>Short Query Acceleration </li> <li>Elastic resize </li> <li>Classic resize with snapshot / restore / resize \uff08Correct)</li> <li>WLM </li> </ul> <p>Explanation </p> <p>While it is possible to change node types with elastic resize, the snapshot / restore / resize approach with classic resize minimizes the downtime involved. Elastic resize only holds connections open if you only change the number of nodes, not the node type. </p> <p>Question 24: </p> <p>What are THREE ways in which EMR optionally integrates HBase with S3? </p> <ul> <li>Storage of HBase StoreFiles and metadata on S3  \uff08Correct)</li> <li>HBase read-replicas on S3 \uff08Correct)</li> <li>Automatic backup from HDFS-based StoreFiles to </li> <li>AWS Glue integration to infer schemas of S3 data </li> <li>Snapshots of HBase data to S3 \uff08Correct)</li> </ul> <p>Explanation </p> <p>EMR allows you use S3 instead of HDFS for HBase's data via EMRFS. </p> <p>Although you can export snapshots to S3, </p> <p>HBase itself does not automate this for you. </p>"},{"location":"chap10/qz_final/#question-25","title":"Question 25:","text":"<p>New data arrives in S3 on an irregular schedule that you wish to import into an Amazon Elasticsearch cluster as it is received. The raw data in S3 requires some custom parsing before it is loaded into Elasticsearch. </p> <p>Which solution minimizes ongoing maintenance and maximizes scalability? </p> <ul> <li>Use AWS Glue to connect Elasticsearch directly to your S3 bucket </li> <li>Use Spark Streaming on an EMR cluster with reserved instances to monitor the S3 bucket and redirect the data to Elasticsearch </li> <li>Use Kinesis Firehose to pump data from S3 directly into Elasticsearch </li> <li>Use a Lambda function to respond to event triggers from S3, and stream data from S3 into Elasticsearch as it is received  \uff08Correct)</li> </ul> <p>Explanation </p> <p>Glue does not integrate with Elasticsearch, ruling out \"Use AWS Glue to connect Elasticsearch directly to your S3 bucket\". </p> <p>EMR clusters require manual scaling as your needs evolve, which involves ongoing maintenance we could avoid - so \"Use Spark Streaming on an EMR cluster with reserved instances to monitor the S3 bucket and redirect the data to Elasticsearch\" is also a poor choice. </p> <p>While Firehose can sit between S3 and Elasticsearch, the requirement to perform custom parsing means a Lambda function would be useful - leading us to \"Use a Lambda function to respond to event triggers from S3, and stream data from S3 into Elasticsearch as it is received\" </p>"},{"location":"chap10/qz_final/#question-26","title":"Question 26:","text":"<p>A real estate company wishes to display interactive charts on their website summarizing their prior month's sales activity. </p> <p>Which TWO solutions would provide this capability in a scalable and inexpensive manner? </p> <ul> <li>Use Tableau to visualize the data on the web, backed by an Amazon Aurora RDS database. </li> <li>Publish data in csv format to Amazon Cloudtront via S3, and use Highcharts to visualize the data on the web. \uff08Correct)</li> <li>Publish data in csv format to Amazon Cloudfront via S3, and use d3.js to visualize the data on the web. \uff08Correct)</li> <li>Embed Amazon Quicksight into the website, querying an underlying Redshift data warehouse. </li> <li>Embed a Jupyter Notebook hosted on EMR into the website. </li> </ul> <p>Explanation </p> <p>Both d3 and Highcharts are Javascript libraries intended for interactive charts and graphs on websites. Quicksight and Tableau are data analysis tools not intended for public deployment. </p>"},{"location":"chap10/qz_final/#question-27","title":"Question 27","text":"<p>Your company has data from a variety of sources, including Microsoft Excel spreadsheets stored in S3, log data stored in a S3 data lake, and structured data stored in Redshift. </p> <p>Which is the simplest solution for providing interactive dashboards that span this data? </p> <ul> <li>Create an Excel macro to dump the Excel data to csv files stored in S3, then -1 use Amazon Quicksight to visualize it and the other data sources together. </li> <li>Create Excel macros to import the log and Redshift data into Excel, and -1 visualize it all within Excel. </li> <li>Use Amazon Quicksight directly on top of the Excel, S3, and Redshift data.  (Correct)  Write Python code in a Jupyter Notebook on an EMR cluster that processes LI the data and generates graphs. </li> </ul> <p>Explanation </p> <p>The key to this question is remembering that Quicksight can actually consume Excel spreadsheets directly. Knowing that, \"Use Amazon Quicksight directly on top of the Excel, S3, and Redshift data.\" is clearly the simplest approach. </p>"},{"location":"chap10/qz_final/#question-28","title":"Question 28:","text":"<p>You are dealing with PII datasets and would like to leverage Kinesis Data Streams for your pub-sub solution. Regulators imposed the constraint that the data must be encrypted end-to-end using an internal key management system. What do you recommend? </p> <ul> <li>Implement a custom encryption code in the Kinesis Producer LI Library (KPL) (Correct)</li> <li>Use the Kinesis Client Library (KCL) to encrypt the data </li> <li>Encrypt the data with the MD5 algorithm before pushing it to Kinesis </li> <li>Enable KMS encryption at rest for Kinesis and transfer the data over HTTPS to get in-flight encryption </li> </ul> <p>Explanation </p> <p>We cannot use KMS as we cannot leverage an internal key management system. MD5 is not an encryption algorithm and encryption must happen at the producer level (KPL), while decryption will happen at the consumption level (KCL). </p>"},{"location":"chap10/qz_final/#question-29","title":"Question 29","text":"<p>You are an online retailer and your website is a storefront for millions of products. You have recently run a big sale on one specific electronic and you have encountered Provisioned Throughput Exceptions. You would like to ensure you can properly survive an upcoming sale that will be three times as big. What do you recommend? </p> <ul> <li>Enable DynamoDB DAX </li> <li>Triple the provisioned RCU </li> <li>Triple the provisioned WCU </li> <li>Enable DynamoDB Streams </li> </ul> <p>Explanation </p> <p>Here we are in a hot partition situation where one item is constantly being requested. Adding RCU will be costly and won't be effective as even though we have tripled the table capacity, the one partition will still experience throughput exceptions. Enabling DynamoDB Streams will not help, but a DAX cluster will provide caching for hot items and will definitely help in this situation. </p>"},{"location":"chap10/qz_final/#question-30","title":"Question 30:","text":"<p>You are collecting data from various IoT thermostat and would like to have the data in S3 to ensure you can perform analytics on it using Hive running on EMR. The data scientists will use Hive to query the data based on a date range and will  need to delete the data in S3 regularly if it becomes out of date to save cost.  What do you recommend for the storage strategy in S3? </p> <ul> <li><code>&lt;device-id&gt;/&lt;YYYY&gt;/&lt;MM&gt;/&lt;DD&gt;</code></li> <li>All the data at the root of your S3 bucket </li> <li><code>&lt;YYYY&gt;/&lt;MM&gt;/&lt;DD&gt;/&lt;device-id&gt;/</code>  (Correct)</li> <li><code>&lt;DD&gt;/&lt;MM&gt;/&lt;YYYY&gt;/&lt;device-id&gt;/</code></li> </ul> <p>Explanation </p> <p>As all the data will often get queried and deleted based on a date range, it's much better to use a date as the root key for your S3 objects. </p> <p>Starting with the year is better as it will allow you to query based on years efficiently. </p>"},{"location":"chap10/qz_final/#question-31","title":"Question 31","text":"<p>You are processing data using a long running EMR cluster and you like to ensure that you can recover data in case an entire availability zone goes down, as well as process the data locally for the various Hive jobs you plan on running. What do you recommend to do this at a minimal cost? </p> <ul> <li>Store the data in S3 and directlyvperform Hive jobs against it </li> <li>Store the data in S3 and keep a warm copy in HDFS (Correct) </li> <li>Store the data in HDFS and mirror it to another EMR cluster in another region </li> <li>Enable regular EBS backups </li> </ul> <p>Explanation </p> <p>EBS backups will be expensive and very painful to deal with as the dataset will be distributed over many different snapshots due to HDFS block replication mechanisms. </p> <p>Storing all the data in S3 and none in HDFS will incur some extra costs as the data is constantly read and written back to S3. </p> <p>It's better to keep a local copy on HDFS. Finally, maintaining an entirely new EMR cluster for disaster recovery is too expensive. </p>"},{"location":"chap10/qz_final/#question-32","title":"Question 32","text":"<p>You are creating an EMR cluster that will process the data in several MapReduce steps. Currently you are working against the data in S3 using EMRFS, but the network costs are extremely high as the processes write back temporary data to S3 before reading it. You are tasked with optimizing the process and bringing the  cost down, what should you do? </p> <ul> <li>Add a preliminary step that will use a S3DistCp command</li> <li>Use I3 type of instances </li> <li>Enable EMRFS local caching feature </li> <li>Enable LUKS encryption </li> </ul> <p>Explanation Here, using an S3DistCp command is the right thing to do to copy data from S3 into HDFS and then make sure the data is processed locally by the EMR cluster MapReduce job. Upon completion, you will use S3DistCp again to push back the final result data to S3. LUKS encryption will not help, EMRFS does not have a local caching feature, and changing the EC2 instance types won't help </p>"},{"location":"chap10/qz_final/#question-33","title":"Question 33:","text":"<p>What security mechanisms are supported by tMFC' (Select three) </p> <ul> <li>KMS encryption (Correct) </li> <li>LUKS encryption (Correct) </li> <li>SSE-KMS (Correct) </li> <li>External HSM encryption </li> <li>Transparent Data Encryption (TDE) </li> <li>SSE-C </li> </ul> <p>Explanation https://aws.amazon.com/blogs/big-data/best-practices-for-securing-amazon-emr/ </p>"},{"location":"chap10/qz_final/#question-34","title":"Question 34:","text":"<p>An application processes sensor data in real-time by publishing it to Kinesis Data Streams, which in turn sends data to an AWS Lambda function that processes it and feeds it to DynamoDB. During peak usage periods, it's been observed that some data is lost. You've determined that you have sufficient capacity allocated for Kinesis shards and DynamoDB reads and writes. </p> <p>What might be TWO possible solutions to the problem? </p> <ul> <li>Allocate more Lambda nodes </li> <li>Enable replication in Lambda </li> <li>Provision more Kinesis shards </li> <li>Process data in smaller batches to avoid hitting Lambda's timeout (Correct) </li> <li>Increase your Lambda function's timeout value (Correct) </li> </ul> <p>Explanation </p> <p>Lambda is serverless, and you don't need to concern yourself with how many nodes it might be using under the hood, or how it automatically handles replication and redundancy. However, lambda functions do have a timeout associated with them, and if the processing you're doing takes longer than this, events will be rejected. </p>"},{"location":"chap10/qz_final/#question-35","title":"Question 35:","text":"<p>A financial services company wishes to back up its encrypted data warehouse in Amazon Redshift daily to a different region. </p> <p>What is the simplest solution that preserves encryption in transit and at rest? </p> <ul> <li>Configure a second Redshift cluster in another region, and use a daily COPY  command triggered by Lambda to transfer the encrypted data to the other cluster. </li> <li>Move the data into S3 and use Amazon Redshift from multiple regions to query it. </li> <li>Configure Redshift to automatically copy snapshots to another region, using an AWS KMS customer master key in the destination region.  (Correct)</li> <li>Configure Redshift to replicate its data to a standby cluster in another region. </li> </ul> <p>Explanation </p> <p>Note that we said \"daily,\" which means we don't need real-time replication. Snapshots will do just fine. </p> <p>\"Move the data into S3 and use Amazon Redshift from multiple regions to query it.\" is a little bit misleading, as it doesn't matter where you run Redshift itself from if the data is stored elsewhere - but moving the data isn't exactly a simple solution. </p> <p>Question 36</p> <p>You would like to design an application that will be able to sustain storing 100s of TB of data in a database that will get low latency on reads and won't require you to manage scaling. What do you recommend? </p> <ul> <li>Redshift </li> <li>Aurora </li> <li>DynamoDB   (Correct)</li> <li>ElastiCache </li> </ul> <p>Explanation </p> <p>Redshift cannot be used for low latency reads, Aurora will not scale past 64 TB and ElastiCache most likely won't scale and require you to manage scaling anyway. </p> <p>DynamoDB complies with the requirements and has built-in support for auto scaling. </p>"},{"location":"chap10/qz_final/#question-37","title":"Question 37:","text":"<p>A MapReduce job on an EMR cluster needs to process data that is currently stored in very large, compressed files in HDFS, which limits the cluster's ability to distribute its processing.</p> <p>Which TWO solutions would best help the MapRedue job to operate more efficiently? </p> <ul> <li>Uncompress the data and split it into 64MB chunks (CorrecT) </li> <li>Compress the file with Snappy </li> <li>Convert the file to AVRO format (Correct) </li> <li>Compress the file with GZIP </li> <li>Uncompress the data and split it into 64K chunks </li> </ul> <p>Explanation </p> <p>AVRO is a format that can easily be split and distributed by MapReduce as needed. Alternately, the data could be split manually into different files - but ideally you'd want these files to be close to the default HDFS chunk size of 64MB in order to make the best use of HDFS. </p>"},{"location":"chap10/qz_final/#question-38","title":"Question 38:","text":"<p>You have an S3 bucket that your entire organization can read. For security reasons you would like the data sits encrypted there and you would like to define a strategy in which users can only read the data which they are allowed to decrypt, which may be a different partial set of objects within the bucket for each  user. How can  \u201cnn achieve that? </p> <ul> <li>Use SSE-KMS to encrypt the files (Correct)</li> <li>Change the bucket policy </li> <li>Use SSE-S3 to encrypt the files </li> <li>Use identity federation </li> </ul> <p>Explanation </p> <p>Here, the key is that users should be able to decrypt different files based on their rights. </p> <p>Bucket policies do not scale for that matter if you have a lot of users and diverse data directories. </p> <p>SSE-S3 uses only one encryption key and does not enable granular permissions. Identity federation would not help either to solve that problem, as it does not define an authorization model. </p> <p>SSE-KMS will allow you to use different KMS keys to encrypt the objects, and then you can grant users access to specific sets of KMS keys to give them access to the objects in S3 they should be able to decrypt. </p>"},{"location":"chap10/qz_final/#question-39","title":"Question 39","text":"<p>You are working for an e-commerce website and that website uses an on-premise PostgreSQL database as its main OLTP engine. You would like to perform analytical queries on it, but the Solutions Architect recommended not doing it off of the main database. What do you recommend? </p> <ul> <li>Use DMS to replicate the database to RDS </li> <li>Create an on-premise PostgreSQL Read Replica </li> <li>Create an RDS Read Replica </li> <li>Create an Aurora Read Replica </li> </ul> <p>Explanation Read Replicas cannot be instantiated from an on-premise database. Here using a solution like DMS (Database Migration Service) is the right way to replicate the database state. </p>"},{"location":"chap10/qz_final/#question-40","title":"Question 40","text":"<p>A manager wishes to make a case for hiring more people in her department, by showing that the number oming tasks for her department have grown at a faster rate than other departments over the past year. </p> <p>Which type of graph in Amazon Quicksight would be best suited to illustrate this </p> <ul> <li>Heat map </li> <li>A sequence of slides in a QuickSight Story </li> <li>Area line chart \uff08Correct) </li> <li>Stacked vertical bar chart </li> </ul> <p>Explanation </p> <p>When you're looking for trends over time, line charts are usually the right choice. </p>"},{"location":"chap10/qz_final/#question-41","title":"Question 41:","text":"<p>You wish to analyze an S3 data lake using standard SQL. Which solution results in the least amount of ongoing administration from you, as your data grows? </p> <ul> <li>Apache Spark on EMR </li> <li>Amazon Athena \uff08Correct) </li> <li>Amazon Redshift Spectrum </li> <li>Amazon RDS </li> </ul> <p>Explanation </p> <p>Of the above choices, only Amazon Athena is a \"serverless\" solution that does not require you to provision capacity as your data and usage grows. </p>"},{"location":"chap10/qz_final/#question-42","title":"Question 42:","text":"<p>As part of your application development, you would like your users to be able to get Row Level Security. The application is to be deployed on web servers and the users of the application should be able to use their <code>amazon.com</code> accounts. What do you recommend for the database and security? </p> <ul> <li>Enable Web Identity federation. Use RDS and reference <code>${www.amazon.com:user_id}</code> in the attached IAM policy </li> <li>Enable Web Identity federation. Use DynamoDB and reference <code>${aws:username}</code> in the attached IAM policy </li> <li>Enable Web Identity federation. Use DynamoDB and reference <code>${www.amazon.com:user_id}</code> in the attached IAM policy </li> <li>Enable Web Identity federation. Use RDS and reference <code>${aws:username}</code> in the attached IAM policy </li> </ul> <p>Explanation </p> <p>RDS does not allow authorization through IAM policies, so we have to rule out RDS as a database technology for our purpose. </p> <p>DynamoDB is the technology of choice. As we're using Web Identity Federation with amazon.com, our IAM policy should use the <code>${www.amazon.com:user_id}</code> policy variable </p>"},{"location":"chap10/qz_final/#question-43","title":"Question 43","text":"<p>Your financial organization has hundreds of Terabytes of data stored within its on premise data centers, and data is being produced at the rate of Gigabytes per second, and could be consumed within 3 days. As part of their AWS cloud migration, what solution do you recommend for them? </p> <ul> <li> <p>Transfer your historical data using Snowball and use Kinesis Data Streams for ongoing data collection.  (Correct) </p> </li> <li> <p>Install Direct Connect between your data center and AWS and transfer all the data over a 10Gbps line. Use Kinesis Data Firehose for ongoing data collection. </p> </li> <li>Transfer your historical data using Snowball and use Kinesis Data Firehose for ongoing data collection. </li> <li>Install Direct Connect between your data center and AWS and transfer all the Li data over a 10Gbps line. Use Kinesis Data Streams for ongoing data collection. </li> </ul> <p>Explanation As your organization has hundreds of Terabytes of data, it is going to be much quicker and much more efficient to use Snowball to transport that data to AWS. </p> <p>As the data streams must be stored for at least 3 days, you must use Kinesis Data Streams which has a configurable data retention of between 1 and 7 days. </p>"},{"location":"chap10/qz_final/#question-44","title":"Question 44:","text":"<p>You have programmed a Lambda function that will be automating the creation of an EMR cluster, which in turn should perform some transformations in S3 through EMRFS. Your Lambda function will be triggered by Cloud Watch Events. How can you ensure your Lambda function can properly perform its actions? </p> <ul> <li>Deploy in a VPC</li> <li>Use a Lambda policy  </li> <li>Attach an IAM role   (Correct)</li> <li>Attach an IAM user </li> </ul> <p>Explanation As the Lambda function will be performing API calls on our infrastructure, it needs to have an IAM role attached. Deploying it in a VPC won't help, and we can't create users for Lambda functions. </p> <p>as possible and without impacting the current read an </p>"},{"location":"chap10/qz_final/#question-45","title":"Question 45:","text":"<p>As part of an effort to limit cost and maintain under control the size of your DynamoDB table, your AWS account manager would like to ensure old data is deleted in DynamoDB after 1 month. How can you do so with as little maintenance d write operations? </p> <ul> <li>Enable DynamoDB TTL and add a TTL column (Correct)</li> <li>Create a Lambda function that gets triggered on a daily basis </li> <li>Create a lifecycle rule to delete your items after 30 days </li> <li>Scan your table from EMR and issue a delete statement afterwards </li> </ul> <p>Explanation Lifecycle rules do not exist on DynamoDB, and a Lambda function would require maintenance and add load on the WCU as you delete items. So will an EMR scan. The TTL will automatically expire old items and will not affect your usage of WCU and RCU upon item deletion. </p>"},{"location":"chap10/qz_final/#question-46","title":"Question 46:","text":"<p>Which are the two technologies that support VPC Endpoint Gateway? (select two) </p> <ul> <li>DynamoDB (Correct) </li> <li>SQS (Correct) </li> <li>SNS </li> <li>CloudFormation </li> </ul> <p>Explanation DynamoDB &amp; S3 are the only technologies that have VPC Endpoint Gateways, the rest are VPC Endpoint Interfaces. </p>"},{"location":"chap10/qz_final/#question-47","title":"Question 47:","text":"<p>A data scientist wishes to develop a machine learning model to predict stock prices using Python in a Jupyter Notebook, and use a cluster on AWS to train and tune this model, and to vend predictions from it at large scale. </p> <p>Which system allows you to do this?</p> <ul> <li>Amazon SageMaker (Correct) </li> <li>Apache Zeppelin </li> <li>Amazon Machine Learning </li> <li>Amazon Comprehend </li> </ul> <p>Explanation </p> <p>SageMaker enables developers and data scientists to build, train, and deploy machine learning models at any scale, using hosted Jupyter notebooks. Zeppelin also uses a hosted Jupyter notebook, but does not integrate with AWS to train and tune models. Amazon Machine Learning does not use notebooks, and Amazon Comprehend is a natural language processing tool. </p>"},{"location":"chap10/qz_final/#question-48","title":"Question 48","text":"<p>You are looking to query data storage in DynamoDB from your EMR cluster. Which of the following technology will allow you to do so? </p> <ul> <li>Hive (Correct) </li> <li>Pig </li> <li>Spark </li> <li>HBase </li> </ul> <p>Explanation </p> <p>Amongst the four listed above, Hive can have DynamoDB as a source for its queries. </p> <p>Question 49: </p> <p>A produce export company has multi-dimensional data for all of its shipments, such as the date, price, category, and destination of every shipment. A data analyst wishes to interactively explore this data, applying statistical functions to different rows and columns and sorting them in different ways. </p> <p>Which QuickSight visualization would be best suited for this? </p> <ul> <li>Stacked horizontal bar chart </li> <li>Heat map </li> <li>Pivot table </li> <li>Scatter plot </li> </ul> <p>Explanation </p> <p>Interactive exploration of multi-dimensional data usually calls for a pivot table, as long as you're not looking to quickly identify outliers at the same time. </p>"},{"location":"chap10/qz_final/#question-50","title":"Question 50","text":"<p>You are storing gaming data for your game that is becoming increasingly popular. An average game data will contain 80KB of data and as your games are quick. You expect about 400 games to be written per second to your database. Additionally, a lot of people would like to retrieve this game data and you expect about 1800 eventually consistent reads per second. How should you provision your DynamoDB table? </p> <ul> <li>3200 WCU &amp; 36000 RCU </li> <li>32000 WCU &amp; 18000 RCU (Correct) </li> <li>32000 WCU &amp; 144000 RCU </li> <li>32000 WCU &amp; 36000 RCU </li> </ul> <p>Explanation </p> <p><code>1 WCU = 1 KB/s</code> so we need </p> <p><code>80KB * 400/s = 32000 WCU</code>. <code>1 RCU = 2</code> eventually consistent reads per second of 4 KB so we need <code>1800 * 80 / 8 = 18000 RCU</code>. </p>"},{"location":"chap10/qz_final/#question-51","title":"Question 51","text":"<p>Which tool on Amazon Elastic MapReduce allows you to monitor your cluster's performance as a whole, and at individual nodes? </p> <ul> <li>Presto </li> <li>Ganglia (Correct\uff09 </li> <li>Hue</li> <li>Ambbari</li> </ul> <p>Explanation </p> <p>Ganglia is the operational dashboard provided with EMR. Hue and Ambari are graphical front-ends for interacting with a cluster, but only Hue is provided with EMR. </p> <p>Presto is used for querying multiple data stores at once. </p>"},{"location":"chap10/qz_final/#question-52","title":"Question 52","text":"<p>As an e-cornmerce retailer, you would like to onboard clickstream data onto Kinesis from your web servers Java applications. You want to ensure that a retry mechanism is in place, as well as good batching capability and asynchronous mode. You also want to collect server logs with the same constraints. What do you recommend? </p> <ul> <li>Use the Klnems Agent to se. the ell, stream and collect the server logs</li> <li>Use the AWS Kinesis SDK for Java in your web servers and use Kness 0 Producer Lama, to collect server logs </li> <li>Use the Knems Producer Library to send the Clickstream and the Kineis agent to collect the Server Logs (Correct\uff09 </li> <li>Use Kinesis Producer Library to send the ell, stream and collect the server </li> </ul> <p>Explanation </p> <p>The KPL has the mechanisms in place for retry and batching, as well as asynchronous mode. The Kinesis agent is meant to retrieve server logs with lust configuration files. </p>"},{"location":"chap10/qz_final/#question-53","title":"Question 53","text":"<p>You are working for a bank and your company is regularly uploading 100 MB files to Amazon S3 and analyzed by Athena. It has come to light that recently some of the uploads have been corrupted and made a critical big data job tails. Your company would like a stronger guarantee that uploads are done successfully and that the files have the some content on premise and on S3. It looks to do so at minimal cost. What do you recommend? </p> <ul> <li>Upload a hash header as part of the S3 metadata which will trigger an S3 failure upon server side check for corruption </li> <li>Use the S3 Etag and compare to the local MD5 hash  (Correct) </li> <li>Transfer the data over HTTP with gzip compression enabled </li> <li>Download the data from S3 after uploading it a. compare the SHA-1 signature </li> </ul> <p>Explanation </p> <p>Here the S3 tag will compute the MD5 hash of the file on the server and this can be used to compare it to the local MD5 hash of the file that has been uploaded. </p> <p>Downloading data back from S3 might work, but will be way too costly. There's no feature to upload a hash header to S3 and transferring the data on HTTP will not help, and will decrease security. </p>"},{"location":"chap10/qz_final/#question-54","title":"Question 54","text":"<p>Your esports application hosted on AWS need to process game results immediately in real time and later perform analytics on the same game results in the order they came at the end of business hours. Which of the AWS service will be the best fit for your needs? </p> <ul> <li>SQS FIFO Queues </li> <li>DynamoDB</li> <li>Kinesis Data Streams (Correct) </li> <li>SQS Standard Queues </li> </ul> <p>Explanation </p> <p>Here Kinesis is the best fit as the data can be replayed in the same order. </p> <p>SQS does not allow data replays, and DynamoOB would allow to replay some data, but it'd be different to get some ordering constraints working as well as well as enable real time use cases. </p>"},{"location":"chap10/qz_final/#question-55","title":"Question 55","text":"<p>You are required to maintain a real-time replica of your Amazon Redshift data warehouse across multiple availability zones. </p> <p>What is one approach toward accomplishing this? </p> <ul> <li>Snapshot your Redshift to Amazon S3, and copy it to a different availability zone periodically from a Lambda function </li> <li>Enable the trulti-AZ option when creating your Redsrytt cluster </li> <li>Spin up separate redshibt clusters in multiple availability zones, using Amazon Kinesis to simultaneously write data into each cluster. Use Route 53 to direct your analytics tools to the nearest cluster when querying your data.    (Correct)</li> <li>Snapshot your Redshift data to Amazon S3, where it may be restored from any availability zone, </li> </ul> <p>Explanation </p> <p>Redshift does not come with multi-AZ redundancy, so this is something you must build yourself as described in \"Spin up separate redshift clusters in multiple availability zones, using Amazon Kinesis to simultaneously write data into each cluster. </p> <p>Use Route 53 to direct your analytics tools to the nearest cluster when querying your date. </p> <p>As S3 is mutli-AZ, snapshotting your data to S3, which Redshift does do automatically, does provide you with some protection - but it does not satisfy the real-bore replication requirement stated in the question. </p>"},{"location":"chap10/qz_final/#question-56","title":"Question 56","text":"<p>Your daily Spark jobs runs against files created by a Kinesis Firehose pipeline in S3. Due to a low throughput, you observe that each of the many files created by Kinesis Firehose is about 100KB. You would like to optimise your Spark job as best as possible to query the data efficiently. What do you recommend? </p> <ul> <li>Use multl-part download with Spark. </li> <li>Compress the files using GZIP </li> <li>Consolidate files on a daily basis usng DataPipeline  (Correct)</li> <li>Increase the batch flush time in Mnesis Data Firehose to 1 hour </li> </ul> <p>Explanation </p> <p>Multi part download is not a Spark feature, which does not deal well with many small files. </p> <p>GZIP will not solve the problems, the files will still be small and you will have many of them. Kinesis Data Firehose does not haves flush time greater than 5 minutes, which will still create many small files. Bottom line, you should use a DataPipeline job to consolidate the files on a daily basis into a larger file. </p>"},{"location":"chap10/qz_final/#question-57","title":"Question 57","text":"<p>You have an ETL process that collects data from different sources and 3rd party providers and would be to ensure that data is loaded into Redshift once all the parts from all the providers related to one specific jobs have been gathered, which is the process that can happen over the course of one hour to one day. What the least costly way of doing that? </p> <ul> <li>Use the multi part upload feature of S3 to collect data from different sources </li> <li>Create an AWS Lambda that responds to S3 upload events and will check if all the parts are there before uploading to Redshift  (Correct)</li> <li>Create a Kinesis Data Firehose pipeline and program a Python condition that will trigger a buffer flush upon receiving all the necessary parts </li> <li>Load data in Redshif regularly using a Lambda cron job into a temporary table and use Redshift database triggers to assemble the final clata when all the parts are ready. </li> </ul> <p>Explanation </p> <p>Loading the data in Redshift will be costly and inefficient and Redshift does not support database triggers. </p> <p>Multi Part is not helpful for data coming from various sources. Kinesis Firehose does not have a Python condition for buffer flush (only time and size). </p> <p>Here a Lambda function that reacts to events happening in $3 is the right answer. </p>"},{"location":"chap10/qz_final/#question-58","title":"Question 58","text":"<p>You work for a gaming company and each game's data is stored in DynamoDB tables. In order to provide a game search functionality to your users, you need to move that data over to ElasticSearch. How can you achieve it efficiently and as close to real time as possible? </p> <ul> <li>Enable DynamoDB Streams and connect it with Kinesis Data Firehose</li> <li>Create a DataPipeline job scheduled on ab hourly basis</li> <li>Enable DynamoDB Streams and write a Lambda function (Correct)</li> <li>Use DynamoDB Global Rephcation and select ElastmSearch Service as your target</li> </ul> <p>Explanation </p> <p>DynamoDB Streams do not have direct integration with Firehose,</p> <p>DataPipeline will not have the data fast enough into ElasticSearch, and DynamoDB Global Tables do not integrate with ElasticSearch. </p> <p>Here we need to write a Lambda function that is triggered from a DynamoDB Stream </p>"},{"location":"chap10/qz_final/#question-59","title":"Question 59","text":"<p>You have created a system that recommends items similar to other items on an e-commerce website, by training a recommender system using Mahout on an EMR cluster. </p> <p>Which would be a performant means to vend the resulting table of similar items for any given item to the website at high transaction rates?</p> <ul> <li>Publish the data into HBase (Correct) </li> <li>Load the data Into a Redshdt cluster and query It from the website</li> <li>Expose the data via Hive and JDBC </li> <li>Load data mto Amazon Aurora / HOS and query It from website</li> </ul> <p>Explanation </p> <p>This is an OLTP use case for which a \"NoSQL\" database is a good fit HBase is the only option presented designed tor OLTP and not (KAP, plus it has the advantage of already being present in EMR. </p> <p>DynamoDB would also be an appropriate technology to use. </p>"},{"location":"chap10/qz_final/#question-60","title":"Question 60","text":"<p>You wish to use Amazon Redshitt Spectrum to analyze data in an Amazon S3 bucket that is in a different account than Redshift Spectrum. </p> <p>How would you authorize access between Spectrum and S3 across accounts? </p> <ul> <li>Add a ploicy to the S3 bucket allowing S3 GET and LIST operations for an IAM role for Spectrum on the Redshift account (Correct)</li> <li>Add a policy to the S3 bucket allowing S3 GET and LIST operations for the user agent \"AWS Redshift/Spectrum\"</li> <li>Create an IAM role allowing access for COPY operations on S3 </li> <li>Create a VPC endpoint to S3 accessible by your Redshift Spectrum</li> </ul> <p>Explanation </p> <p>Only \"Add a policy to the S3 bucket allowing S3 GET and LIST operations for an IAM role for Spectrum on the Redshift account\" specifically addresses the problem of cross-account access to the S3 bucket. </p>"},{"location":"chap10/qz_final/#question-61","title":"Question 61","text":"<p>Your enterprise would like to leverage AWS Redshift to query data. Currently that data is produced at the rate of 5 PB of historical data and another 3 TB per month that you would like to get with less than two days delay, and you are tasked with finding the most efficient data transfer solution into S3. What do you recommend? (select two) </p> <ul> <li>Use Snowball to transfer the newly created monthly data </li> <li>Establish Direct Connect transfer the historical data over a 10Gpbs connection </li> <li>Use Snowball to transfer the historical data (Correct) </li> <li>Establish Direct Connect and do a daily upload created monthly data directly into S3  (Correct)</li> <li>Establish Site-to-Site VPN and transfer the historical data over a public 10Gbps connection</li> </ul> <p>Explanation </p> <p>Snowball is the only way to transfer your historical data as it would take a very long time to transfer over the network, even with Direct Conned or Site-to-Site VPN. </p> <p>For ongoing data, it's the equivalent of 300 GB a day, which will take less than an hour to upload each day versus Snowball which will definitely take longer than 2 days to reach AWS. </p>"},{"location":"chap10/qz_final/#question-62","title":"Question 62","text":"<p>You need to load several hundred GB of data every day from Amazon 53 into Amazon Redshift, which is stored in a single file. You've found that loading this data is prohibitively slow. </p> <p>Which approach would optimize this loading best? </p> <ul> <li>Avoid loading the data in the same order as your sort key. </li> <li>Split the data into fres between 1GB and 125GB rafter compressiond and specify GZIP compression from multiple COPY commands run concurrently </li> <li>Split the data into fres between 1MB and 125MB (after comprssion) and specify GZIP conhoression from a single COPY command (Correcrt) </li> <li>Split the data into files between 1MB and 125MB (after compressiond and specify GZIP compression from multiple COPY commands run concurrently </li> </ul> <p>Explanation </p> <p>Multiple concurrent COPY commands might sound like a good idea, but in reality it forces Redshift to perform a slow, serialized load followed by a VACUUM Process, If you want to load data in parallel, it's best to split your data into separate files no more than 1GB apie\u00e5ce. </p> <p>Compressing the data also helps. Loading data in the same order as your sort key can also speed up the import process, which is the opposite of \"Avoid loading the data in the same order as your sort key\".</p>"},{"location":"chap10/qz_final/#question-63","title":"Question 63","text":"<p>Your team has developed a Spark Streaming applications that performs real time transformations on an on-premise Apache KM ka cluster and finally delivers the data in real time to S3. As part of a migration to the cloud and switch to Kinesis as an underlying streaming store, what do you recommend? </p> <ul> <li>Produce data using Spark Streaming to Kinesis Data Streams, and read the o data with Spark Streaming frorn Kinesis Data Frehose to write it to S3 </li> <li>Produce data using Spark Streaming to Kinesis Data Firehose and deliver the data to S3 using Kinesis Data Firehose. </li> <li>Produce data using Spark Streaming to Kinesis Data Firehose and deliver the data S3 using Spark Streaming reading from Kinesis Data Streams. </li> <li>Produce data using Spark Streaming to Kinesis Data Streams, and read the data min Spark Streaming from Kinesis Data Streams to write it to S3.  (Correct) </li> </ul> <p>Explanation </p> <p>Here, the key requirement is the real-time constraint Kinesis Data Firehose is near real time\" (60 seconds minimum batch size) and thus cannot be used tor delivery to S3 in real time. Finally, Spark Streaming can read and write to Kinesis Data Streams only. </p>"},{"location":"chap10/qz_final/#question-64","title":"Question 64","text":"<p>An application on AWS generates frequent logs on S3. The operational support team needs to analyze the logs to understand various patterns of the application failures and try to come up with a plan to fix those issues. Which option is cost-effective and requires the LEAST engineering effort? </p> <ul> <li>Create AWS Glue Data Catalogue metadata and analyze logs via Amazon Athena.  (Correct)</li> <li>Download Me log files Korn SS and manually check the failure reasons. </li> <li>Migrate the logs to the Elasticsearch platform and analyze further using Kihana. </li> <li>Create AWS Glue Data Catalogue metadata and spin up an ENID cluster with a Hive metastore pointing to AWS Glue Data Catalogue. Use Spark and Hive to analyze the logs further. </li> </ul> <p>Explanation </p> <p>Amazon Athena is meant for analysis of files on S3 after creation of metadata on AWS Glue. </p>"},{"location":"chap10/qz_final/#question-65","title":"Question 65","text":"<p>You need to ETL streaming data from web server logs as it is streamed in, for analysis in Athena. Upon talking to the stakeholders, you've determined that the ETL does not strictly need to happen in real-time, but transforming the data within a minute is desirable. </p> <p>What is a viable solution to this requirement? </p> <ul> <li>Perform any initial ETL you can using Amazon Kinesis, store the 0 data in S3, and trigger a Glue ETL job to complete the transformations needed. (Correct)</li> <li>Perform any initial ETL you can with Kinesis Analytics, and send Me output of 0 Kinesis Analytios directly. a Spark Streaming application to Olathe remaining transformations. </li> <li>Create an AWS Glue ETL job, and schedule it to it every minute </li> <li>Publish your data into DynamoDB, and use DynamoDB strearns together with AWS Glue to perform the ETL </li> </ul> <p>Explanation </p> <p>Glue jobs can be scheduled at a minimum of 5 minutes, ruling out \"Create an AWS Glue ETL job, and schedule it to run every minute\". </p> <p>Glue does not integrate directly with DynamoDB, ruling out \"Publish your data into DynamoDB, and use DynamoDB streams together with AWS Glue to perform the ETL\"</p> <p>Kinesis Analytics cannot connect directly to Spark Streaming, ruling out \"Perform any initial ETL you can with Kinesis Analytics, and send the output of Kinesis Analytics directly to a Spark Streaming application to handle the remaining transformations\"</p> <p>\"Perform any initial ETL you can using Amazon Kinesis, store the data in S3, and trigger a Glue ETL job to complete the transformations needed.\" is the recommended approach from AWS. An alternative approach would be to use Kinesis Firehose and a Lambda function to transform the data before storing it in S3. </p>"},{"location":"chap11/chap11_10data_mining/","title":"\u7b2c\u5341\u8282 \u6570\u636e\u6316\u6398","text":""},{"location":"chap11/chap11_10data_mining/#1","title":"1\u3001\u6316\u6398\u5168\u6d41\u7a0b","text":"<p>\u6570\u636e\u6316\u6398\u5c31\u662f\u4ee5\u6570\u636e\u4f5c\u4e3a\u7814\u7a76\u7684\u5bf9\u8c61\uff0c\u4ece\u6570\u636e\u4e2d\u5bfb\u627e\u4ef7\u503c\uff0c\u83b7\u53d6\u77e5\u8bc6\u7684\u8fc7\u7a0b\uff0c\u81f3\u4e8e\u8bf4\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u6216\u8005\u6570\u636e\u7684\u7edf\u8ba1\u5206\u6790\uff0c\u8fd9\u4e9b\u90fd\u662f\u624b\u6bb5\u3002</p> <p>CRISP-DM\uff08cross-industry standard process for data mining\uff09\uff0c\u7ffb\u8bd1\u8fc7\u6765\u7684\u610f\u601d\u662f\u8de8\u884c\u4e1a\u6570\u636e\u6316\u6398\u6807\u51c6\u6d41\u7a0b\uff0c</p> <p></p> <ol> <li>\u7406\u89e3\u4e1a\u52a1</li> <li>\u7406\u89e3\u6570\u636e</li> <li>\u51c6\u5907\u6570\u636e</li> <li>\u6784\u5efa\u6a21\u578b</li> </ol> <p>\u6211\u4eec\u5e38\u89c1\u7684\u95ee\u9898\u901a\u5e38\u53ef\u4ee5\u8f6c\u5316\u6210\u5206\u7c7b\u3001\u805a\u7c7b\u3001\u56de\u5f52\u548c\u5173\u8054\u5206\u6790\u56db\u79cd\u95ee\u9898\uff0c\u8fdb\u800c\u9009\u62e9\u5bf9\u5e94\u7684\u7b97\u6cd5\u6784\u5efa\u6a21\u578b\u3002\u6bd4\u5982\u8bf4\u6211\u4eec\u7684\u6587\u672c\u6284\u88ad\u68c0\u6d4b\uff1a</p> <ul> <li>\u53ef\u4ee5\u8f6c\u5316\u6210\u5206\u7c7b\u95ee\u9898\uff0c\u628a\u76f8\u4f3c\u548c\u4e0d\u76f8\u4f3c\u770b\u4f5c\u662f\u4e8c\u5206\u7c7b\uff0c\u628a\u6587\u672c\u6570\u636e\u8f6c\u5316\u6210\u6570\u503c\u6570\u636e\uff0c\u4f7f\u7528\u5206\u7c7b\u7b97\u6cd5\u6784\u5efa\u5206\u7c7b\u6a21\u578b\uff1b</li> <li>\u53ef\u4ee5\u628a\u5b83\u8f6c\u5316\u4e3a\u4e00\u4e2a\u805a\u7c7b\u95ee\u9898\uff0c\u628a\u6587\u672c\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u6839\u636e\u805a\u7c7b\u7684\u8ddd\u79bb\u6765\u5224\u5b9a\u662f\u5426\u6284\u88ad\uff1b</li> <li>\u53ef\u4ee5\u628a\u591a\u79cd\u65b9\u6cd5\u7ec4\u5408\u8d77\u6765\u4f7f\u7528\u3002</li> </ul> <p>5.\u6a21\u578b\u8bc4\u4f30</p> <p>\u4ece\u6570\u5b66\u539f\u7406\u65b9\u9762\uff0c\u6211\u4eec\u6709\u8bf8\u5982\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u00a0Score \u7b49\u6307\u6807\u6765\u8bc4\u5224\u4e00\u4e2a\u6a21\u578b\u7684\u6548\u679c\u3002</p> <p>6.\u90e8\u7f72\u4e0a\u7ebf</p> <p>7.\u4e0b\u4e00\u6b21\u8fed\u4ee3</p> <p>\u53ef\u80fd\u662f\u4e3a\u4e86\u5feb\u901f\u4e0a\u7ebf\uff0c\u4e5f\u53ef\u80fd\u662f\u7531\u4e8e\u5f53\u524d\u7684\u67d0\u4e9b\u6761\u4ef6\u4e0d\u5177\u5907\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u7248\u670d\u52a1\u8fd8\u5b58\u5728\u7740\u5f88\u5927\u7684\u4f18\u5316\u7a7a\u95f4\uff0c\u540c\u65f6\u6765\u81ea\u7ebf\u4e0a\u7684\u65e5\u5fd7\u6536\u96c6\u4e5f\u4e3a\u6211\u4eec\u51c6\u5907\u4e86\u5f88\u591a\u95ee\u9898\u6848\u4f8b</p> <p></p>"},{"location":"chap11/chap11_1bigdata_intro/","title":"\u7b2c\u4e00\u8282 \u5927\u6570\u636e\u4f53\u7cfb\u4e2d\u660e\u786e\u8def\u5f84","text":"<p>\u5927\u6570\u636e\u4f53\u7cfb\u5982\u6b64\u5e9e\u5927\uff0c\u5b83\u7684\u804c\u4e1a\u53d1\u5c55\u8def\u5f84\u65e0\u7591\u4e5f\u6709\u5f88\u591a\uff0c\u6211\u603b\u7ed3\u4e86 3 \u5927\u65b9\u5411</p> <ul> <li>\u201c\u5927\u6570\u636e\u67b6\u6784\u201d\u65b9\u5411\u3002\u4e3b\u8981\u5de5\u4f5c\u662f\u4ece\u4f17\u591a\u7684\u5927\u6570\u636e\u5de5\u5177\u4e2d\u9009\u53d6\u5408\u9002\u7684\u5de5\u5177\uff0c\u5e76\u80fd\u591f\u8ba9\u8fd9\u4e9b\u5de5\u5177\u5728\u5e9e\u5927\u7684\u4e91\u670d\u52a1\u5668\u6216\u8005\u96c6\u7fa4\u4e2d\u826f\u597d\u7684\u914d\u5408\u548c\u8fd0\u8f6c\uff0c\u6765\u652f\u6491\u4e0a\u5c42\u7684\u5e94\u7528\u3002\u804c\u4e1a\u53d1\u5c55\u8def\u5f84\u4e3a\uff1a\u6570\u636e\u8fd0\u7ef4\u5de5\u7a0b\u5e08 \u2192 \u9ad8\u7ea7\u8fd0\u7ef4\u5de5\u7a0b\u5e08 \u2192 \u67b6\u6784\u5e08 \u2192 \u6280\u672f\u4e13\u5bb6\u3002\u6240\u6d89\u53ca\u7684\u6280\u80fd\u4e3b\u8981\u5728\u4e0a\u9762\u56fe\u8c31\u7684\u5de6\u534a\u90e8\u5206\uff0c\u6bd4\u5982\u901a\u7528\u6846\u67b6\u3001\u6d41\u5f0f\u8ba1\u7b97\u3001\u6d88\u606f\u961f\u5217\u3001\u8d44\u6e90\u8c03\u5ea6\u7b49\u3002</li> <li>\u201c\u5927\u6570\u636e\u5f00\u53d1\u201d\u65b9\u5411\u3002\u6bcf\u5bb6\u516c\u53f8\u7684\u60c5\u51b5\u5404\u4e0d\u76f8\u540c\uff0c\u4e1a\u52a1\u4e5f\u5404\u4e0d\u76f8\u540c\uff0c\u56e0\u6b64\u8981\u60f3\u6570\u636e\u80fd\u591f\u5728\u8fd9\u4e9b\u5de5\u5177\u4e2d\u826f\u597d\u5730\u8fd0\u8f6c\uff0c\u4ee5\u53ca\u9002\u914d\u516c\u53f8\u4e1a\u52a1\uff0c\u5c31\u9700\u8981\u5927\u6570\u636e\u5f00\u53d1\u5de5\u7a0b\u5e08\u6765\u8fdb\u884c\u5efa\u8bbe\u3002\u804c\u4e1a\u53d1\u5c55\u8def\u5f84\u4e3a\uff1a\u5f00\u53d1\u5de5\u7a0b\u5e08 \u2192 \u9ad8\u7ea7\u5f00\u53d1\u5de5\u7a0b\u5e08 \u2192 \u7ec4\u4ef6\u4ee3\u7801\u63d0\u4ea4\u8005\u3002\u6240\u6d89\u53ca\u7684\u6280\u80fd\u4e5f\u662f\u56fe\u8c31\u7684\u5de6\u534a\u90e8\u5206\u5c45\u591a\uff0c\u4f46\u4e0e\u67b6\u6784\u65b9\u5411\u4e0d\u540c\uff0c\u91cd\u70b9\u5728\u4e8e\u719f\u6089\u8fd9\u4e9b\u5de5\u5177\u7684\u7528\u6cd5</li> <li>\u201c\u6570\u636e\u6316\u6398\u4e0e\u5206\u6790\u201d\u65b9\u5411\u3002\u6709\u4e86\u5e95\u5c42\u7684\u6846\u67b6\u548c\u9002\u914d\u516c\u53f8\u4e1a\u52a1\u7684\u5404\u79cd\u7cfb\u7edf\uff0c\u8fd9\u65f6\u5019\u5c31\u8f6e\u5230\u6570\u636e\u6316\u6398\u4e0e\u5206\u6790\u5de5\u7a0b\u5e08\u6765\u5bf9\u6570\u636e\u8fdb\u884c\u7cbe\u52a0\u5de5\uff0c\u4ece\u800c\u5728\u5927\u6570\u636e\u4e2d\u53d1\u73b0\u5bf9\u4e1a\u52a1\u6709\u5e2e\u52a9\u7684\u90e8\u5206\uff0c\u6700\u7ec8\u5b9e\u73b0\u6570\u636e\u5230\u73b0\u91d1\u7684\u8f6c\u5316\u3002\u8fd9\u4e00\u65b9\u5411\u7684\u804c\u4e1a\u53d1\u5c55\u8def\u5f84\u4e3a\uff1a\u6570\u636e\u6e05\u6d17\u5e08 \u2192 \u6570\u636e\u5206\u6790\u5e08 \u2192 \u9ad8\u7ea7\u6570\u636e\u5206\u6790\u5e08 \u2192 \u6570\u636e\u79d1\u5b66\u5bb6\u3002\u8be5\u65b9\u5411\u7684\u6280\u80fd\u4e3b\u8981\u5206\u5e03\u5728\u56fe\u8c31\u7684\u53f3\u4fa7\uff0c\u6bd4\u5982\u6570\u636e\u53ef\u89c6\u5316\u3001\u673a\u5668\u5b66\u4e60\u5de5\u5177\u3001\u7b97\u6cd5\u4e0e\u6570\u636e\u7ed3\u6784\u7b49\u3002</li> </ul>"},{"location":"chap11/chap11_1bigdata_intro/#1-5","title":"1\u3001\u8bfe\u7a0b\u5171\u5212\u5206 5 \u4e2a\u6a21\u5757","text":"<ul> <li>\u6a21\u5757\u4e00\uff0c\u5927\u6570\u636e\u7b80\u4ecb</li> <li>\u6a21\u5757\u4e8c\uff0c\u5927\u6570\u636e\u67b6\u6784</li> <li>\u6a21\u5757\u4e09\uff0c\u5927\u6570\u636e\u5f00\u53d1</li> <li>\u6a21\u5757\u56db\uff0c\u6570\u636e\u6316\u6398\u4e0e\u5206\u6790</li> <li>\u6a21\u5757\u4e94\uff0c\u5927\u6570\u636e\u5e94\u7528</li> </ul>"},{"location":"chap11/chap11_1bigdata_intro/#2","title":"2\u3001\u5927\u6570\u636e\u7b80\u4ecb","text":""},{"location":"chap11/chap11_1bigdata_intro/#2-1-4","title":"2-1 \u5927\u6570\u636e\u7684 4 \u4e2a\u91cd\u8981\u7279\u70b9","text":"<p>\u6570\u91cf\u591a\uff08Volume\uff09\u3001\u79cd\u7c7b\u591a\uff08Variety\uff09\u3001\u901f\u5ea6\u5feb\uff08Velocity\uff09\u53ca\u6570\u636e\u4ef7\u503c\uff08Value\uff09\u3002</p> <p>\u5927\u6570\u636e\u662f\u6709\u4ef7\u503c\u7684\uff0c\u4f46\u662f\u5927\u6570\u636e\u4ef7\u503c\u6709\u4e00\u4e2a\u7279\u8272\u2014\u2014\u4ef7\u503c\u5bc6\u5ea6\u4f4e\u3002</p>"},{"location":"chap11/chap11_1bigdata_intro/#2-2","title":"2-2 \u5927\u6570\u636e\u7684\u5de5\u4f5c\u73af\u8282","text":"<ul> <li>\u6570\u636e\u7684\u91c7\u96c6</li> <li>\u6570\u636e\u7684\u5b58\u50a8</li> <li>\u6570\u636e\u7684\u8ba1\u7b97<ul> <li>\u76ee\u524d\u4e3b\u6d41\u7684\u5c31\u662f\u6279\u5904\u7406\u548c\u6d41\u5904\u7406\u4e24\u79cd\u65b9\u5f0f\uff0c\u800c\u9488\u5bf9\u8fd9\u4e9b\u65b9\u5f0f\uff0c\u53c8\u6709\u591a\u79cd\u8ba1\u7b97\u6846\u67b6\u88ab\u7814\u5236\u51fa\u6765\uff0c\u6bd4\u5982\u5f53\u524d\u5e94\u7528\u5e7f\u6cdb\u7684 Spark\u3001Flink \u7b49\u3002 </li> </ul> </li> <li>\u6570\u636e\u6316\u6398\u4e0e\u5206\u6790</li> <li>\u6570\u636e\u7684\u5e94\u7528</li> <li>\u6570\u636e\u5b89\u5168</li> </ul>"},{"location":"chap11/chap11_1bigdata_intro/#3de","title":"3\u3001\u5927\u6570\u636ede\u53d1\u5c55","text":""},{"location":"chap11/chap11_1bigdata_intro/#3-1","title":"3-1 \u5927\u6570\u636e\u7684\u53d1\u5c55\u8fc7\u7a0b","text":"<p>\u65e9\u5728 1980 \u5e74\uff0c\u5927\u6570\u636e\u8fd9\u4e2a\u8bcd\u88ab\u963f\u5c14\u6587\u00b7\u6258\u592b\u52d2\u5199\u5728\u4e86\u4ed6\u7684\u65b0\u4e66\u300a\u7b2c\u4e09\u6b21\u6d6a\u6f6e\u300b\u91cc\uff0c\u4e0d\u4ec5\u5982\u6b64\uff0c\u4ed6\u8fd8\u58f0\u79f0\u5927\u6570\u636e\u662f\u7b2c\u4e09\u6b21\u6d6a\u6f6e\u7684\u534e\u5f69\u4e50\u7ae0\uff0c\u8fd9\u5c31\u662f\u5927\u6570\u636e\u4e00\u8bcd\u7684\u7531\u6765\u3002\u963f\u5c14\u6587\u00b7\u6258\u592b\u52d2\u662f\u4e00\u4f4d\u8457\u540d\u7684\u672a\u6765\u5b66\u5bb6\uff0c\u4ed6\u975e\u5e38\u6210\u529f\u5730\u9884\u6d4b\u4e86\u5927\u6570\u636e\u7684\u7206\u53d1\u3002</p> <p>2004 \u5e74\u524d\u540e\uff0c\u8c37\u6b4c\u53d1\u8868\u4e86\u4e09\u7bc7\u8bba\u6587\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u5e38\u8bf4\u7684\u5927\u6570\u636e\u4e09\u9a7e\u9a6c\u8f66\uff1a</p> <ul> <li>\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edfGFS\uff1b</li> <li>\u5927\u6570\u636e\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6MapReduce\uff1b</li> <li>NoSQL \u6570\u636e\u5e93\u7cfb\u7edfBigTable\u3002</li> </ul> <p>\u8fd9 3 \u7bc7\u8bba\u6587\u7684\u53d1\u8868\u60ca\u9192\u4e86\u5f88\u591a\u61f5\u61c2\u7684\u4eba\uff0c\u4e5f\u89e3\u51b3\u4e86\u5927\u6570\u636e\u4f53\u7cfb\u4e2d\u6700\u6838\u5fc3\u7684 3 \u4e2a\u95ee\u9898\uff1a</p> <ul> <li>GFS \u6587\u4ef6\u7cfb\u7edf\u89e3\u51b3\u4e86\u6570\u636e\u7684\u5e95\u5c42\u5b58\u50a8\u95ee\u9898\uff1b</li> <li>\u8ba1\u7b97\u6846\u67b6 MapReduce \u89e3\u51b3\u4e86\u6570\u636e\u7684\u5904\u7406\u8fd0\u7b97\u95ee\u9898\uff1b</li> <li>BigTable \u6570\u636e\u5e93\u7cfb\u7edf\u89e3\u51b3\u4e86\u6570\u636e\u7684\u6709\u5e8f\u7ec4\u7ec7\u95ee\u9898\u3002</li> </ul>"},{"location":"chap11/chap11_1bigdata_intro/#3-2","title":"3-2 \u5de5\u4f5c\u65b9\u5411\u9009\u62e9","text":"<p>1\u3001\u5927\u6570\u636e\u67b6\u6784\u65b9\u5411</p> <p>\u5927\u6570\u636e\u67b6\u6784\u65b9\u5411\u6d89\u53ca\u504f\u5411\u5927\u6570\u636e\u5e95\u5c42\u4e0e\u5927\u6570\u636e\u5de5\u5177\u7684\u4e00\u4e9b\u5de5\u4f5c\u3002\u505a\u8fd9\u4e00\u65b9\u5411\u7684\u5de5\u4f5c\u66f4\u6ce8\u91cd\u7684\u662f\uff1a</p> <ul> <li>Hadoop\u3001Spark\u3001Flink \u7b49\u5927\u6570\u636e\u6846\u67b6\u7684\u5b9e\u73b0\u539f\u7406\u3001\u90e8\u7f72\u3001\u8c03\u4f18\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff1b</li> <li>\u5728\u67b6\u6784\u6574\u5408\u3001\u6570\u636e\u6d41\u8f6c\u548c\u6570\u636e\u5b58\u50a8\u65b9\u9762\u6709\u6bd4\u8f83\u6df1\u5165\u7684\u7406\u89e3\uff0c\u80fd\u591f\u6d41\u7545\u5730\u843d\u5730\u5e94\u7528\uff1b</li> <li>\u719f\u77e5\u5404\u79cd\u76f8\u5173\u5de5\u5177\u4e2d\u8be5\u5982\u4f55\u642d\u914d\u7ec4\u5408\u624d\u80fd\u591f\u83b7\u53d6\u66f4\u9ad8\u7684\u6548\u7387\uff0c\u66f4\u52a0\u7b26\u5408\u516c\u53f8\u6574\u4f53\u7684\u4e1a\u52a1\u573a\u666f\u3002</li> </ul> <p>\u4ece\u4e8b\u8fd9\u4e00\u65b9\u5411\u7684\u5de5\u4f5c\uff0c\u9700\u8981\u5177\u5907\u4ee5\u4e0b\u6280\u672f\u3002</p> <ul> <li>\u5927\u6570\u636e\u6846\u67b6\uff1aHadoop\u3001Spark\u3001Flink\u3001\u9ad8\u53ef\u7528\u3001\u9ad8\u5e76\u53d1\u3001\u5e76\u884c\u8ba1\u7b97\u7b49\u3002</li> <li>\u6570\u636e\u5b58\u50a8\uff1aHive\u3001HDFS\u3001Cassandra\u3001ClickHouse\u3001Redis\u3001MySQL\u3001MongoDB \u7b49\u3002</li> <li>\u6570\u636e\u6d41\u8f6c\uff1aKafka\u3001RocketMQ\u3001Flume \u7b49\u3002</li> </ul> <p>2\u3001\u5927\u6570\u636e\u5206\u6790\u65b9\u5411</p> <ul> <li>\u6570\u636e\u5206\u6790\uff1aETL\u3001SQL\u3001Python\u3001\u7edf\u8ba1\u3001\u6982\u7387\u8bba\u7b49\u3002</li> <li>\u6570\u636e\u6316\u6398\uff1a\u7b97\u6cd5\u3001\u673a\u5668\u5b66\u4e60\u3001\u6df1\u5ea6\u5b66\u4e60\u3001\u805a\u7c7b\u3001\u5206\u7c7b\u3001\u534f\u540c\u8fc7\u6ee4\u7b49\u3002</li> </ul> <p>3\u3001\u5927\u6570\u636e\u5f00\u53d1\u65b9\u5411</p> <p>\u5927\u6570\u636e\u5f00\u53d1\u662f\u5927\u6570\u636e\u5728\u516c\u53f8\u5185\u4f7f\u5404\u4e2a\u73af\u8282\u5f97\u4ee5\u6253\u901a\u548c\u5b9e\u65bd\u7684\u6865\u6881\u548c\u7ebd\u5e26\uff0c\u722c\u866b\u7cfb\u7edf\u3001\u670d\u52a1\u5668\u7aef\u5f00\u53d1\u3001\u6570\u636e\u5e93\u5f00\u53d1\u3001\u53ef\u89c6\u5316\u5e73\u53f0\u5efa\u8bbe\u7b49\u5404\u4e2a\u6570\u636e\u52a0\u5de5\u73af\u8282\uff0c\u90fd\u79bb\u4e0d\u5f00\u5927\u6570\u636e\u5f00\u53d1\u7684\u8eab\u5f71\u3002\u5927\u6570\u636e\u5f00\u53d1\u9700\u8981\u5177\u5907 2 \u65b9\u9762\u7684\u80fd\u529b\uff1a</p> <ul> <li>\u8981\u4e86\u89e3\u5927\u6570\u636e\u5404\u7c7b\u5de5\u5177\u7684\u4f7f\u7528\u65b9\u6cd5\uff1b</li> <li>\u8981\u5177\u5907\u826f\u597d\u7684\u4ee3\u7801\u80fd\u529b\u3002</li> </ul> <p>\u9700\u8981\u5177\u5907\u7684\u6280\u672f\u6709\u8fd9\u4e9b\uff1a\u6570\u4ed3\u3001\u63a8\u8350\u5f15\u64ce\u3001Java\u3001Go\u3001\u722c\u866b\u3001\u5b9e\u65f6\u3001\u5206\u5e03\u5f0f\u7b49\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/","title":"\u7b2c\u4e8c\u8282 \u5927\u6570\u636e\u67b6\u6784 &amp; Hadoop\u4ecb\u7ecd","text":""},{"location":"chap11/chap11_2bigdata_structure/#1","title":"1\u3001\u4e92\u8054\u7f51\u5927\u5382\u7684\u5927\u6570\u636e\u89e3\u51b3\u65b9\u6848","text":""},{"location":"chap11/chap11_2bigdata_structure/#1-1","title":"1-1 \u6ef4\u6ef4\u7684\u5927\u6570\u636e\u4f53\u7cfb","text":"<ul> <li>\u6700\u4e0a\u5c42\u7684\u7ea2\u8272\u7bad\u5934\u6807\u5fd7\u5c55\u793a\u7684\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u6570\u636e\u5e73\u53f0\u5f00\u53d1\u5de5\u7a0b\u7684\u53d1\u5e03\u6d41\u7a0b\uff0c\u5f53\u7136\uff0c\u8fd9\u4e2a\u6d41\u7a0b\u8ddf\u5927\u6570\u636e\u7684\u5173\u7cfb\u5e76\u4e0d\u662f\u5f88\u5927\uff0c\u4efb\u4f55\u4e00\u4e2a\u5de5\u7a0b\u57fa\u672c\u90fd\u8981\u9075\u7167\u8fd9\u4e2a\u8fc7\u7a0b\u8fdb\u884c\u53d1\u5e03\u3002</li> <li>\u7d27\u6328\u7740\u7684\u6d41\u7a0b\u662f\u673a\u5668\u5b66\u4e60\u90e8\u5206\uff0c\u673a\u5668\u5b66\u4e60\u4f1a\u6d89\u53ca\u6570\u636e\u6316\u6398 / \u6570\u636e\u5206\u6790 / \u6570\u636e\u5e94\u7528\u51e0\u4e2a\u6b65\u9aa4\u3002</li> <li>\u518d\u5f80\u4e0b\u662f\u5b9e\u65f6\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u548c\u79bb\u7ebf\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u3002</li> <li>\u5728\u67b6\u6784\u56fe\u7684\u6700\u5e95\u5c42\u662f\u76f8\u5173\u7684\u652f\u6301\uff0c\u5305\u62ec\u4e86\u6570\u636e\u5b89\u5168\u3001\u6570\u636e\u7ba1\u7406\u3001\u5f00\u53d1\u8fd0\u7ef4\u548c\u8ba1\u7b97\u5f15\u64ce\u56db\u4e2a\u90e8\u5206\u3002</li> </ul>"},{"location":"chap11/chap11_2bigdata_structure/#1-2","title":"1-2 \u5c31\u6ef4\u6ef4\u516c\u5e03\u7684\u5927\u6570\u636e\u53d1\u5c55\u5386\u7a0b\u6765\u770b","text":"<ul> <li>\u6ef4\u6ef4\u5927\u6570\u636e\u5148\u7ecf\u5386\u4e86\u88f8\u5954\u65f6\u4ee3\uff1a\u5f15\u64ce\u521d\u5efa\uff0c\u5373\u901a\u8fc7 Sqoop \u4ece MySQL \u5bfc\u5165 Hadoop\uff0c\u7528\u6237\u901a\u8fc7\u547d\u4ee4\u884c\u8bbf\u95ee\u5927\u6570\u636e\uff1b</li> <li>\u7136\u540e\u9010\u6b65\u5f15\u8fdb\u4e86\u76f8\u5173\u7684\u5de5\u5177\u5316\u5efa\u8bbe\uff0c\u4f46\u662f\u8fd9\u4e2a\u9636\u6bb5\u7684\u5de5\u5177\u8fd8\u5904\u4e8e\u5404\u81ea\u4e3a\u653f\u7684\u72b6\u6001\uff1a<ul> <li>\u79df\u6237\u7ba1\u7406</li> <li>\u6743\u9650\u7ba1\u7406</li> <li>\u4efb\u52a1\u8c03\u5ea6\u7b49\uff1b</li> </ul> </li> <li>\u5728\u90a3\u4e4b\u540e\uff0c\u9010\u6b65\u4ea7\u751f\u4e86\u5e73\u53f0\u5316\u601d\u7ef4\uff0c\u5f00\u59cb\u642d\u5efa\u4e00\u7ad9\u5f0f\u7684\u667a\u80fd\u5f00\u53d1\u548c\u751f\u4ea7\u5e73\u53f0\uff0c\u4f7f\u5176\u53ef\u4ee5\u8986\u76d6\u6574\u4e2a\u79bb\u7ebf\u573a\u666f\uff0c\u5e76\u4e14\u5185\u7f6e\u5f00\u53d1\u548c\u751f\u4ea7\u4e24\u5957\u903b\u8f91\u73af\u5883\uff0c\u89c4\u8303\u6570\u636e\u5f00\u53d1\u3001\u751f\u4ea7\u548c\u53d1\u5e03\u6d41\u7a0b\uff1b</li> <li>\u6700\u540e\uff0c\u4e5f\u5c31\u662f\u6700\u65b0\u7684\u4e00\u5957\u5927\u6570\u636e\u67b6\u6784\uff0c\u5728\u4e00\u7ad9\u5f0f\u5f00\u53d1\u751f\u4ea7\u5e73\u53f0\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u66f4\u591a\u7684\u6269\u5c55\uff0c\u5df2\u7ecf\u53ef\u4ee5\u96c6\u79bb\u7ebf\u5f00\u53d1\u3001\u5b9e\u65f6\u5f00\u53d1\u3001\u673a\u5668\u5b66\u4e60\u4e8e\u4e00\u4f53\u3002</li> </ul>"},{"location":"chap11/chap11_2bigdata_structure/#1-2_1","title":"1-2 \u963f\u91cc\u4e91\u7684\u5927\u6570\u636e\u4f53\u7cfb","text":"<p>\u6700\u4e0b\u9762\u662f\u8ba1\u7b97\u5b58\u50a8\u5f15\u64ce\uff0c\u8fd9\u91cc\u9762\u5305\u542b\u4e86\u901a\u7528\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u6846\u67b6\u3002</p> <ul> <li>\u5b58\u50a8\u65b9\u9762\uff0cOSS \u662f\u963f\u91cc\u4e91\u7684\u4e91\u5b58\u50a8\u7cfb\u7edf\uff0c</li> <li>\u5e95\u5c42\u7684 HDFS \u6587\u4ef6\u5b58\u50a8\u7cfb\u7edf\uff0c</li> <li>\u4ee5\u53ca\u5176\u4ed6\u7684\u5404\u79cd DB \u7cfb\u7edf\uff1b</li> <li> <p>\u5728\u8ba1\u7b97\u6846\u67b6\u65b9\u9762\uff0c\u6709 MapReduce \u8fd9\u79cd\u79bb\u7ebf\u8ba1\u7b97\u5e73\u53f0\u3001\u5b9e\u65f6\u8ba1\u7b97\u5e73\u53f0\u3001\u56fe\u8ba1\u7b97\u5f15\u64ce\u3001\u4ea4\u4e92\u5f0f\u5206\u6790\u5f15\u64ce\u7b49</p> </li> <li> <p>\u5728\u5b58\u50a8\u548c\u8ba1\u7b97\u7684\u57fa\u7840\u4e0a\uff0c\u662f\u5168\u57df\u6570\u636e\u96c6\u6210\uff0c\u8fd9\u91cc\u9762\u4e3b\u8981\u662f\u5bf9\u6570\u636e\u7684\u5404\u79cd\u91c7\u96c6\u548c\u4f20\u8f93\uff0c\u652f\u6301\u6279\u91cf\u540c\u6b65\u3001\u589e\u91cf\u540c\u6b65\u3001\u5b9e\u65f6\u540c\u6b65\u7b49\u591a\u79cd\u4f20\u8f93\u65b9\u5f0f\u3002</p> </li> <li>\u96c6\u6210\u540e\u7684\u6570\u636e\u8fdb\u5165\u5230\u7edf\u4e00\u5143\u6570\u636e\u4e2d\u5fc3\uff0c\u7edf\u4e00\u8fdb\u884c\u4efb\u52a1\u8c03\u5ea6\u3002</li> <li>\u518d\u5f80\u4e0a\u662f\u5f00\u53d1\u5c42\uff0c\u901a\u8fc7\u7ed3\u5408\u5404\u79cd\u7b97\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u624b\u6bb5\u5f00\u53d1\u5404\u79cd\u4e0d\u540c\u7684\u5e94\u7528\u3002</li> <li>\u6700\u4e0a\u9762\u7684\u6570\u636e\u7efc\u5408\u6cbb\u7406\uff0c\u5176\u5b9e\u662f\u5728\u5927\u6570\u636e\u5168\u6d41\u7a0b\u8d77\u5230\u4fdd\u969c\u4f5c\u7528\u7684\u4e00\u4e9b\u6a21\u5757\uff0c\u5305\u542b\u4e86\u667a\u80fd\u76d1\u63a7\u3001\u6570\u636e\u5b89\u5168\u7b49\u6a21\u5757</li> </ul>"},{"location":"chap11/chap11_2bigdata_structure/#1-3","title":"1-3 \u7f8e\u56e2\u7684\u5927\u6570\u636e\u4f53\u7cfb","text":"<p>\u6700\u5de6\u4fa7\u662f\u7f8e\u56e2\u7684\u5404\u79cd\u4e1a\u52a1\u670d\u52a1\uff0c</p> <p>\u4ece\u8fd9\u4e9b\u4e1a\u52a1\u7684\u6570\u636e\u5e93\u548c\u65e5\u5fd7\uff0c\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u4f20\u8f93\u3001\u65e5\u5fd7\u91c7\u96c6\u7b49\u624b\u6bb5\u5bf9\u6570\u636e\u8fdb\u884c\u6c47\u603b\uff0c</p> <ul> <li>\u4e00\u65b9\u9762\u5bf9\u4e8e\u8ba1\u7b97\u9700\u6c42\uff0c\u76f4\u63a5\u8fdb\u5165\u5230 Storm \u6d41\u5f0f\u8ba1\u7b97\u6846\u67b6\u8fdb\u884c\u8ba1\u7b97\uff0c\u628a\u7ed3\u679c\u5b58\u50a8\u4e8e HBase \u7b49\u5404\u79cd\u6570\u636e\u5e93\u4e2d\uff0c\u5e76\u5728\u4e1a\u52a1\u4e0a\u5e94\u7528\uff1b</li> <li>\u53e6\u4e00\u65b9\u9762\uff0c\u6570\u636e\u6c47\u603b\u5230Hadoop \u6846\u67b6\u7684\u5b58\u50a8\u4e2d\u5fc3\uff0c\u7ecf\u8fc7\u5404\u79cd\u89e3\u6790\u548c\u7ed3\u6784\u5316\u5b58\u50a8\u5728 Hive \u8868\u4e2d\uff0c\u5e76\u5728\u5404\u79cd\u673a\u5668\u5b66\u4e60\u548c\u6570\u636e\u6316\u6398\u9879\u76ee\u4e2d\u8fdb\u884c\u5e94\u7528\u3002</li> </ul> <p>\u5728\u5e95\u5c42\uff0c\u662f\u56f4\u7ed5\u7740 Hadoop \u67b6\u6784\u5efa\u8bbe\u7684\u8c03\u5ea6\u7cfb\u7edf\u3001\u914d\u7f6e\u4e2d\u5fc3\uff0c\u4ee5\u53ca\u6570\u636e\u5f00\u653e\u5e73\u53f0\u3002</p> <p>\u5728\u6700\u53f3\u4fa7\uff0c\u662f\u7ecf\u8fc7\u96c6\u6210\u7684\u67e5\u8be2\u4e2d\u5fc3\u548c\u67e5\u8be2\u5f15\u64ce\uff0c\u5e76\u901a\u8fc7\u5e73\u53f0\u5316\u5f00\u53d1\u5efa\u7acb\u4e86\u4e00\u5957\u6570\u636e\u5206\u6790\u4ea7\u54c1\u5e73\u53f0\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#1-4","title":"1-4 \u5927\u6570\u636e\u4f53\u7cfb\u7684\u5171\u540c\u70b9","text":"<ul> <li>\u6a21\u5757\u5316</li> </ul> <p>\u5927\u6570\u636e\u4f53\u7cfb\u6d89\u53ca\u4e86\u5173\u4e8e\u6570\u636e\u7684\u4e00\u7cfb\u5217\u52a8\u4f5c\u3002\u968f\u7740\u5927\u6570\u636e\u4f53\u7cfb\u5efa\u8bbe\u7684\u9010\u6e10\u5b8c\u5584\uff0c\u5404\u4e2a\u6b65\u9aa4\u53d8\u5f97\u66f4\u52a0\u6e05\u6670\u53ef\u5206\uff0c\u4e0d\u7ba1\u662f\u5b58\u50a8\u3001\u8c03\u5ea6\u3001\u8ba1\u7b97\u90fd\u88ab\u62c6\u5206\u6210\u5355\u72ec\u7684\u6a21\u5757\uff0c\u4ece\u800c\u53ef\u4ee5\u652f\u6301\u66f4\u591a\u7684\u4e1a\u52a1\uff0c\u5e76\u6839\u636e\u9700\u8981\u8fdb\u884c\u7075\u6d3b\u7684\u9009\u7528\u3002</p> <ul> <li>\u5e73\u53f0\u5316</li> </ul> <p>\u5efa\u8bbe\u4e00\u4e2a\u628a\u5404\u4e1a\u52a1\u7684\u76f8\u4f3c\u70b9\u7edf\u4e00\u8d77\u6765\uff0c\u53c8\u80fd\u591f\u5305\u5bb9\u5404\u4e1a\u52a1\u7684\u5dee\u522b\u7684\u5e73\u53f0\uff0c\u8ba9\u8fd9\u4e9b\u6570\u636e\u53d1\u6325\u51fa\u66f4\u5927\u7684\u4ef7\u503c\u6210\u4e86\u4e00\u4e2a\u8feb\u5728\u7709\u776b\u7684\u9700\u6c42</p> <ul> <li> <p>\u5b9e\u65f6\u5316</p> </li> <li> <p>\u6700\u65e9\u671f\u7684\u5f00\u6e90\u5927\u6570\u636e\u6846\u67b6 Hadoop \u90fd\u662f\u57fa\u4e8e\u78c1\u76d8\u5f00\u53d1\u7684\uff0c\u4e0d\u7ba1\u662f\u5e95\u5c42\u6570\u636e\u7684\u5b58\u50a8\u8fd8\u662f\u8ba1\u7b97\u7684\u4e2d\u95f4\u7ed3\u679c\u5b58\u50a8\u90fd\u653e\u5728\u78c1\u76d8\u4e0a\uff0c\u800c\u4e14\u5176\u4e2d\u7684\u8ba1\u7b97\u6846\u67b6 MapReduce \u4e5f\u662f\u57fa\u4e8e\u79bb\u7ebf\u7684\u6570\u636e\u6279\u5904\u7406\uff0c\u6ca1\u529e\u6cd5\u5bf9\u5b9e\u65f6\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\u3002</p> </li> <li> <p>\u800c\u770b\u73b0\u5728\u51e0\u5927\u516c\u53f8\u7684\u5927\u6570\u636e\u4f53\u7cfb\uff0c\u5b9e\u65f6\u8ba1\u7b97\u5df2\u7ecf\u6210\u4e86\u5927\u6570\u636e\u4f53\u7cfb\u4e2d\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u7ec4\u6210\u90e8\u5206\u3002</p> </li> <li> <p>\u4e0d\u5b8c\u5584</p> </li> </ul>"},{"location":"chap11/chap11_2bigdata_structure/#2hadoop","title":"2\u3001\u5927\u6570\u636e\u5f00\u53d1\u5fc5\u5907\u5de5\u5177\u2014\u2014Hadoop","text":""},{"location":"chap11/chap11_2bigdata_structure/#2-1-hadoop","title":"2-1 Hadoop \u7684\u6574\u4f53\u67b6\u6784","text":"<p>\u5173\u4e8e Hadoop \u6700\u6734\u7d20\u7684\u539f\u7406\uff0c\u5c31\u662f\u8981\u4f7f\u7528\u5927\u91cf\u7684\u666e\u901a\u8ba1\u7b97\u673a\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u7684\u5b58\u50a8\u548c\u5206\u6790\uff0c\u800c\u4e0d\u662f\u5efa\u9020\u4e00\u53f0\u8d85\u7ea7\u8ba1\u7b97\u673a</p> <ul> <li>\u8ba1\u7b97\u673a\u7684\u6545\u969c\u95ee\u9898\u3002\u60f3\u8c61\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u6709\u4e00\u4e07\u53f0\u8ba1\u7b97\u673a\u7ec4\u6210\u7684\u96c6\u7fa4\uff0c\u5176\u4e2d\u4e00\u53f0\u8ba1\u7b97\u673a\u51fa\u73b0\u95ee\u9898\u7684\u53ef\u80fd\u6027\u662f\u5f88\u9ad8\u7684\uff0c\u6240\u4ee5\u5728\u5927\u89c4\u6a21\u8ba1\u7b97\u673a\u96c6\u7fa4\u4e0a\u8981\u5904\u7406\u597d\u6545\u969c\u95ee\u9898\uff0c\u5c31\u8981\u505a\u5230\u4e00\u53f0\u8ba1\u7b97\u673a\u51fa\u73b0\u95ee\u9898\u4e0d\u4f1a\u5f71\u54cd\u6574\u4e2a\u96c6\u7fa4\u3002</li> <li>\u6570\u636e\u7684\u4f9d\u8d56\u5173\u7cfb\u3002\u96c6\u7fa4\u7531\u82e5\u5e72\u53f0\u8ba1\u7b97\u673a\u7ec4\u6210\uff0c\u6570\u636e\u4e5f\u662f\u5206\u5e03\u5728\u4e0d\u540c\u7684\u8ba1\u7b97\u673a\u4e0a\u9762\uff0c\u5f53\u4f60\u9700\u8981\u8ba1\u7b97\u4e00\u4e2a\u4efb\u52a1\u7684\u65f6\u5019\uff0c\u4f60\u6240\u9700\u8981\u7684\u6570\u636e\u53ef\u80fd\u8981\u4ece\u82e5\u5e72\u53f0\u8ba1\u7b97\u673a\u8fdb\u884c\u8bfb\u53d6\uff0c\u800c\u4f60\u7684\u8ba1\u7b97\u8fc7\u7a0b\u4e5f\u8981\u5206\u914d\u5230\u4e0d\u540c\u7684\u8ba1\u7b97\u673a\u4e0a\u3002</li> </ul> <p>Hadoop \u7cfb\u7edf\u7684\u4e00\u4e2a\u67b6\u6784\u56fe\uff0c\u4f46\u662f\u5176\u4e2d\u6700\u6838\u5fc3\u7684\u4e24\u90e8\u5206\u4f9d\u7136\u662f\u5e95\u5c42\u7684\u6587\u4ef6\u7cfb\u7edf HDFS\u548c\u7528\u4e8e\u8ba1\u7b97\u7684 MapReduce\u3002</p> <p></p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-1-hdfs","title":"2-1-1 HDFS\uff08\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\uff09","text":"<p>HDFS \u662f Hadoop Distributed File System \u7684\u7f29\u5199\uff0c\u4ece\u540d\u5b57\u5c31\u53ef\u4ee5\u770b\u51fa\u5b83\u662f\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u3002\u5b83\u5728 Hadoop \u4f53\u7cfb\u4e2d\u5e2e\u52a9\u89e3\u51b3\u6587\u4ef6\u7684\u5e95\u5c42\u5b58\u50a8\u95ee\u9898\uff0c\u80fd\u591f\u7528\u6765\u652f\u6301\u6d77\u91cf\u6570\u636e\u7684\u78c1\u76d8\u5b58\u50a8\uff0c\u80fd\u591f\u8fdb\u884c\u673a\u5668\u7684\u7ebf\u6027\u6269\u5145\uff0c\u53ea\u9700\u8981\u5728\u96c6\u7fa4\u4e2d\u589e\u52a0\u8282\u70b9\uff0c\u5b58\u50a8\u80fd\u529b\u5c31\u4f1a\u540c\u6b65\u589e\u957f\u3002</p> <p>\u4e0d\u4ec5\u5982\u6b64\uff0cHDFS \u8fd8\u5177\u5907\u975e\u5e38\u5f3a\u5927\u7684\u5bb9\u9519\u6027\u80fd\uff0c\u5176\u4e2d\u7684\u67d0\u4e9b\u8282\u70b9\u51fa\u73b0\u4e86\u6545\u969c\u4e0d\u5f71\u54cd\u7cfb\u7edf\u7684\u4f7f\u7528\uff0c\u901a\u5e38\u6570\u636e\u90fd\u6709\u5f88\u591a\u7684\u526f\u672c\u3002HDFS \u5c4f\u853d\u4e86\u90a3\u4e9b\u5b58\u50a8\u7684\u7ec6\u8282\uff0c\u5e76\u5728\u5ba2\u6237\u7aef\u4e3a\u5927\u5bb6\u63d0\u4f9b\u4e86\u4e00\u5957\u5b8c\u6574\u7684\u6587\u4ef6\u7ba1\u7406\u547d\u4ee4\uff0c\u628a\u5e95\u5c42\u7684\u6587\u4ef6\u4ee5\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u76ee\u5f55\u5f62\u5f0f\u5c55\u73b0\u7ed9\u7528\u6237\uff0c\u6211\u4eec\u53ef\u4ee5\u50cf\u4f7f\u7528 Linux \u6587\u4ef6\u64cd\u4f5c\u547d\u4ee4\u4e00\u6837\u4f7f\u7528 Hadoop \u547d\u4ee4\u6765\u8bbf\u95ee\u5bf9\u5e94\u7684\u6587\u4ef6\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-2-mapreduce","title":"2-1-2 MapReduce\uff08\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6\uff09","text":"<p>\u5728 Hadoop \u4e2d\u7684 MapReduce \u6846\u67b6\u5c31\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u7684\u95ee\u9898\uff0c\u5305\u62ec\u5176\u4e2d\u7684\u8fd0\u7b97\u903b\u8f91\u4e0e\u6570\u636e\u4f9d\u8d56\u3002\u5728 MapReduce \u7684\u5e94\u7528\u4e0a\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u7f16\u7a0b\u6a21\u578b\uff0c\u91cd\u70b9\u5c31\u662f\u5b9e\u73b0 map \u51fd\u6570\u548c reduce \u51fd\u6570\uff1a</p> <ul> <li>map \u51fd\u6570\u7528\u4e8e\u7ec4\u7ec7\u548c\u5206\u5272\u6570\u636e\uff1b</li> <li>reduce \u51fd\u6570\u4e3b\u8981\u8d1f\u8d23\u5728\u5206\u5e03\u5f0f\u8282\u70b9\u4e0a\u7684\u6570\u636e\u8fd0\u7b97\u3002</li> </ul> <p>MapReduce \u7f16\u7a0b\u652f\u6301\u591a\u79cd\u8bed\u8a00\u5b9e\u73b0\uff0c\u6bd4\u5982 Java\u3001Scala \u7b49\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-3-hive","title":"2-1-3 Hive\uff08\u6570\u4ed3\u7cfb\u7edf\uff09","text":"<p>\u5728 HDFS \u4e4b\u4e0a\uff0cHive \u662f Hadoop \u4f53\u7cfb\u7684\u6570\u636e\u4ed3\u5e93\u5de5\u5177\uff0c\u53ef\u4ee5\u5c06\u7ed3\u6784\u5316\u7684\u6570\u636e\u6587\u4ef6\u6620\u5c04\u6210\u4e00\u4e2a\u6570\u636e\u8868</p> <p>\u6ce8\u610f\u8fd9\u91cc\u7684\u91cd\u70b9\u662f\u7ed3\u6784\u5316\u7684\u6570\u636e\u6587\u4ef6\u3002</p> <p>\u5728 HDFS \u6587\u4ef6\u7cfb\u7edf\u4e2d\u53ef\u4ee5\u5b58\u50a8\u7ed3\u6784\u5316\u6570\u636e\u6587\u4ef6\uff0c\u4e5f\u53ef\u4ee5\u5b58\u50a8\u975e\u7ed3\u6784\u5316\u6570\u636e\u6587\u4ef6\uff0c\u800c Hive \u662f\u5904\u7406\u5176\u4e2d\u7684\u7ed3\u6784\u5316\u6570\u636e\u6587\u4ef6\uff0c\u5b83\u672c\u8eab\u5e76\u4e0d\u8fdb\u884c\u5b58\u50a8\u3002</p> <p>\u540c\u65f6\uff0cHive \u63d0\u4f9b\u4e86\u4e00\u5957Hive\u00a0SQL\u5b9e\u73b0 MapReduce \u8ba1\u7b97\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e0e SQL \u5341\u5206\u7c7b\u4f3c\u7684 Hive SQL \u5bf9\u8fd9\u4e9b\u7ed3\u6784\u5316\u7684\u6570\u636e\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u6240\u4ee5\u4ece\u67d0\u79cd\u610f\u4e49\u4e0a\u6765\u8bf4 Hive \u662f\u5bf9 MapReduce \u8fdb\u884c\u5305\u88c5\u540e\u4ea7\u751f\u7684\u5de5\u5177\u3002</p> <p>\u5728\u516c\u53f8\u4e2d\uff0cHive \u662f\u4e00\u4e2a\u975e\u5e38\u5e38\u7528\u7684\u6570\u4ed3\u5de5\u5177\uff0c\u5f88\u591a\u516c\u53f8\u90fd\u4f1a\u628a\u5b83\u5f53\u4f5c\u57fa\u7840\u6570\u4ed3\u6765\u4f7f\u7528\u3002\u4e0d\u8fc7 Hive \u4e5f\u6709\u4e00\u4e9b\u4e0d\u597d\u7528\u7684\u5730\u65b9\uff0c\u6bd4\u5982\u4e0d\u80fd\u8fdb\u884c\u5355\u6761\u6570\u636e\u66f4\u65b0\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-4-hbase","title":"2-1-4 HBase\uff08\u5206\u5e03\u5f0f\u6570\u636e\u5e93\uff09","text":"<p>\u5728\u5b58\u50a8\u65b9\u9762\uff0cHadoop \u67b6\u6784\u4e2d\u8fd8\u6709\u4e00\u4e2a Hbase \u6570\u636e\u5e93\u3002HBase \u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u9ad8\u5e76\u53d1\u7684K-V \u6570\u636e\u5e93\u7cfb\u7edf\uff0c\u5b83\u7684\u5e95\u5c42\u5f53\u7136\u4e5f\u662f\u7531 HDFS \u6765\u652f\u6491\uff0c\u800c HBase \u901a\u8fc7\u5bf9\u5b58\u50a8\u5185\u5bb9\u7684\u91cd\u65b0\u7ec4\u7ec7\uff0c\u514b\u670d\u4e86HDFS \u5bf9\u5c0f\u6587\u4ef6\u5904\u7406\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u7684\u5b9e\u65f6\u64cd\u4f5c\u3002</p> <p>\u5728\u4e92\u8054\u7f51\u516c\u53f8\u4e2d\uff0c\u5bf9\u4e8e\u91cf\u7ea7\u8f83\u5927\uff0c\u4e14\u53d8\u52a8\u8f83\u591a\u7684\u6570\u636e\u901a\u5e38\u9002\u5408\u4f7f\u7528 HBase \u8fdb\u884c\u5b58\u53d6</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-5-yarn","title":"2-1-5 Yarn\uff08\u8d44\u6e90\u8c03\u5ea6\u548c\u7ba1\u7406\u6846\u67b6\uff09","text":"<p>\u5728\u6700\u65e9\u7684 Hadoop 1.0 \u4e2d\u5176\u5b9e\u662f\u6ca1\u6709 Yarn \u7684\uff0c\u8d44\u6e90\u8c03\u5ea6\u7b49\u529f\u80fd\u90fd\u5305\u88c5\u5728 MapReduce \u7684 JobTracker \u4e2d\uff0c\u800c JobTracker \u8d1f\u62c5\u4e86\u592a\u591a\u7684\u529f\u80fd\uff0c\u63a5\u53d7\u4efb\u52a1\u3001\u8d44\u6e90\u8c03\u5ea6\u751a\u81f3\u662f\u76d1\u63a7TaskTracker \u7684\u8fd0\u884c\u60c5\u51b5\u3002</p> <p>\u5f53\u65f6\u5b58\u5728\u4e00\u4e2a\u95ee\u9898\uff0c\u5728\u96c6\u7fa4\u89c4\u6a21\u975e\u5e38\u5927\u7684\u65f6\u5019\u4f1a\u51fa\u73b0\u4e0d\u7a33\u5b9a\u7684\u60c5\u51b5\uff0c\u4e8e\u662f\u5728 2.0 \u4e2d\u5bf9\u5176\u8fdb\u884c\u4e86\u62c6\u5206\uff0c\u56e0\u6b64\u4ea7\u751f\u4e86\u72ec\u7acb\u7684 Yarn\u3002</p> <p>\u5728\u62c6\u5206\u51fa Yarn \u4e4b\u540e\uff0cMapReduce \u53ea\u8d1f\u8d23\u8ba1\u7b97\uff0c\u8fd9\u4e5f\u7ed9\u540e\u9762\u5176\u4ed6\u8ba1\u7b97\u6846\u67b6\u66ff\u6362 MapReduce \u63d0\u4f9b\u4e86\u65b9\u4fbf\uff0c\u4fdd\u969c\u4e86 Hadoop \u6574\u4e2a\u67b6\u6784\u957f\u76db\u4e0d\u8870\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-6-zookeeper","title":"2-1-6 ZooKeeper\uff08\u5206\u5e03\u5f0f\u534f\u4f5c\u670d\u52a1\uff09","text":"<p>ZooKeeper\uff0c\u76f4\u8bd1\u662f\u52a8\u7269\u56ed\u7ba1\u7406\u5458\u3002</p> <p>\u8fd9\u662f\u56e0\u4e3a\u5f88\u591a\u9879\u76ee\u90fd\u4ee5\u52a8\u7269\u7684\u540d\u5b57\u547d\u540d\uff0c\u800c ZooKeeper \u6700\u5e38\u7528\u7684\u573a\u666f\u662f\u4f5c\u4e3a\u4e00\u4e2a\u670d\u52a1\u7684\u6ce8\u518c\u7ba1\u7406\u4e2d\u5fc3\u3002</p> <ul> <li>\u751f\u4ea7\u8005\u628a\u6240\u63d0\u4f9b\u7684\u670d\u52a1\u63d0\u4ea4\u5230 ZooKeeper \u4e2d\uff0c</li> <li>\u800c\u6d88\u8d39\u8005\u5219\u53bb ZooKeeper \u4e2d\u5bfb\u627e\u81ea\u5df1\u9700\u8981\u7684\u670d\u52a1\uff0c\u4ece\u4e2d\u83b7\u53d6\u751f\u4ea7\u8005\u7684\u4fe1\u606f\uff0c\u7136\u540e\u518d\u53bb\u8c03\u7528\u751f\u4ea7\u8005\u7684\u670d\u52a1\u3002</li> </ul> <p>ZooKeeper \u50cf\u662f\u4e00\u4e2a\u9501\uff0c\u628a\u63a7\u5404\u79cd\u6570\u636e\u6d41\u8f6c\u670d\u52a1\u7684\u4e2d\u95f4\u73af\u8282\uff0c\u4fdd\u969c\u6570\u636e\u7684\u4e00\u81f4\u6027\u3002\u6bd4\u5982\u8bf4 HBase\u3001Kafka \u7b49\u90fd\u53ef\u4ee5\u901a\u8fc7 ZooKeeper \u8fdb\u884c\u6ce8\u518c\u3002</p> <p>\u5e78\u8fd0\u7684\u662f\u5728\u6211\u4eec\u7684\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u9700\u8981\u4e86\u89e3\u592a\u591a ZooKeeper \u7684\u7ec6\u8282\uff0c\u4e3b\u8981\u662f\u8fdb\u884c\u4e00\u4e9b\u4ee3\u7801\u4e0a\u7684\u914d\u7f6e\u5c31\u53ef\u4ee5\u4e86\u3002</p>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-7-hadoop","title":"2-1-7 Hadoop \u7684\u4f18\u70b9","text":"<ul> <li>\u5f3a\u5927\u7684\u6570\u636e\u5b58\u50a8\u548c\u5904\u7406\u80fd\u529b<ul> <li>\u901a\u8fc7\u6280\u672f\u624b\u6bb5\uff0cHadoop \u5b9e\u73b0\u4e86\u53ea\u9700\u8981\u589e\u52a0\u4e00\u4e9b\u666e\u901a\u7684\u673a\u5668\u5c31\u53ef\u4ee5\u83b7\u5f97\u5f3a\u5927\u7684\u5b58\u50a8\u548c\u8fd0\u7b97\u80fd\u529b\u3002 </li> </ul> </li> <li>\u9690\u85cf\u4e86\u5927\u91cf\u6280\u672f\u7ec6\u8282<ul> <li>\u53ea\u9700\u8981\u8c03\u7528\u76f8\u5173\u7684 API \u5c31\u53ef\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u5b58\u50a8\u548c\u8ba1\u7b97\u3002</li> </ul> </li> <li>\u826f\u597d\u7684\u6269\u5c55\u80fd\u529b<ul> <li>\u63d0\u4f9b\u4e86\u5f88\u591a\u4e0d\u540c\u7684\u7ec4\u4ef6</li> <li>\u516c\u53f8\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7684\u65b9\u6848\uff0c</li> <li>\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u4e1a\u52a1\u9700\u6c42\u6765\u8fdb\u884c\u7ec6\u8282\u4e0a\u7684\u8c03\u6574\u751a\u81f3\u662f\u81ea\u5df1\u7684\u5f00\u53d1\u3002\u6bd4\u5982\u8bf4\u5bf9\u4e8e\u8ba1\u7b97\u6846\u67b6 MapReduce\uff0c\u5728\u5f88\u591a\u516c\u53f8\u5df2\u7ecf\u4f7f\u7528\u6027\u80fd\u66f4\u597d\u7684 Spark \u6216\u8005 Flink \u8fdb\u884c\u4e86\u66ff\u6362\u3002 </li> </ul> </li> </ul>"},{"location":"chap11/chap11_2bigdata_structure/#2-1-8-hadoop","title":"2-1-8 Hadoop \u7684\u7f3a\u70b9","text":"<ul> <li> <p>\u5b9e\u65f6\u6027\u8f83\u5dee\u3002\u7531\u4e8e HDFS \u5b58\u50a8\u5e95\u5c42\u90fd\u662f\u5728\u78c1\u76d8\u4e2d\u8fdb\u884c\u7684\uff0c\u4ee5\u53ca\u539f\u751f\u7684 MapReduce \u7684\u4e2d\u95f4\u7ed3\u679c\u4e5f\u90fd\u8981\u5b58\u50a8\u5728\u78c1\u76d8\u4e0a\uff0c\u6240\u4ee5 Hadoop \u7684\u5b9e\u65f6\u6027\u4e0d\u592a\u597d\u3002</p> </li> <li> <p>\u5b66\u4e60\u96be\u5ea6\u8f83\u5927\u3002\u867d\u7136\u8bf4 Hadoop \u5df2\u7ecf\u5bf9\u5f88\u591a\u590d\u6742\u7684\u6280\u672f\u8fdb\u884c\u4e86\u5c01\u88c5\uff0c\u4f46\u662f\u4ecd\u7136\u6321\u4e0d\u4f4f\u5b83\u662f\u4e00\u4e2a\u5e9e\u5927\u800c\u590d\u6742\u7684\u7cfb\u7edf\u3002\u5c24\u5176\u662f\u5176\u4e2d\u7684\u5f88\u591a\u95ee\u9898\u90fd\u9700\u8981\u5728\u5b9e\u8df5\u4e2d\u4e0d\u65ad\u6478\u7d22\uff0c\u8981\u60f3\u5b66\u4e60\u6574\u4e2a\u4f53\u7cfb\u51e0\u4e4e\u662f\u5f88\u96be\u5728\u77ed\u65f6\u95f4\u5185\u5b9e\u73b0\u7684\u3002</p> </li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/","title":"\u7b2c\u4e09\u8282 \u5927\u6570\u636e\u4e2d\u7684\u6570\u636e\u6765\u6e90","text":""},{"location":"chap11/chap11_3bigdata_coll/#1","title":"1\u3001\u4f20\u611f\u5668","text":"<ul> <li>\u624b\u673a\u4e0a\u7684\u6307\u7eb9\u5f00\u5c4f\uff1b</li> <li>\u4f7f\u7528\u6307\u7eb9\u8fdb\u884c\u652f\u4ed8\uff1b</li> <li>\u5fae\u4fe1\u6b65\u6570\u7684\u91c7\u96c6\uff1b</li> <li>\u5404\u79cd\u624b\u73af\u548c\u8fd0\u52a8\u624b\u8868\u7b49\u8fd8\u53ef\u4ee5\u76d1\u6d4b\u5fc3\u7387\uff1b</li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/#2","title":"2\u3001\u722c\u866b\u91c7\u96c6","text":"<p>\u722c\u866b\u91c7\u96c6\u662f\u901a\u8fc7\u4e00\u5957\u7a0b\u5e8f\u53bb\u4e92\u8054\u7f51\u4e0a\u83b7\u53d6\u6570\u636e\u7684\u65b9\u6cd5\u3002\u5982\u679c\u628a\u4e00\u4e2a\u4e92\u8054\u7f51\u516c\u53f8\u7684\u6570\u636e\u5212\u5206\u6210\u7ad9\u5185\u6570\u636e\u548c\u7ad9\u5916\u6570\u636e\uff0c\u90a3\u4e48\u722c\u866b\u6240\u83b7\u53d6\u7684\u90fd\u5c5e\u4e8e\u7ad9\u5916\u6570\u636e\u3002</p>"},{"location":"chap11/chap11_3bigdata_coll/#3","title":"3\u3001\u65e5\u5fd7\u91c7\u96c6","text":"<p>\u8ddf\u786c\u4ef6\u4f20\u611f\u5668\u76f8\u6bd4\uff0c\u65e5\u5fd7\u8bb0\u5f55\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u79cd\u8f6f\u4ef6\u4f20\u611f\u5668\uff0c\u4f9d\u6258\u624b\u673a App \u5c31\u53ef\u4ee5\u5b9e\u73b0\uff0c\u8fd9\u901a\u5e38\u662f\u73b0\u5728\u7684\u4e92\u8054\u7f51\u516c\u53f8\u83b7\u53d6\u201c\u7ad9\u5185\u6570\u636e\u201d\u7684\u4e3b\u6d41\u65b9\u5f0f\u3002\u4e0b\u56fe\u5c31\u662f\u4e00\u4e2a\u5178\u578b\u7684\u65e5\u5fd7\u91c7\u96c6\u573a\u666f\uff1a</p> <ul> <li>\u66dd\u5149\u4e8b\u4ef6</li> <li>\u70b9\u51fb\u4e8b\u4ef6</li> <li>\u7528\u6237\u6ede\u7559\u4e8b\u4ef6</li> </ul> <p>\u5728\u65e5\u5fd7\u91c7\u96c6\u7684\u6570\u636e\u4e2d\uff0c\u901a\u5e38\u53c8\u53ef\u4ee5\u5206\u6210\u4e24\u79cd\u7c7b\u578b\uff0c\u4e00\u79cd\u79f0\u4e3a\u4e8b\u4ef6\uff0c\u4e00\u79cd\u79f0\u4e3a\u5c5e\u6027\u3002</p> <p></p>"},{"location":"chap11/chap11_3bigdata_coll/#4","title":"4\u3001\u4e8b\u4ef6","text":"<p>\u4e8b\u4ef6\u662f\u65e5\u5fd7\u91c7\u96c6\u7684\u91cd\u4e2d\u4e4b\u91cd</p> <ul> <li>\u66dd\u5149\u4e8b\u4ef6</li> </ul> <p>\u6700\u7b80\u5355\u7684\uff0c\u4e00\u4e2a item \u6216\u8005\u4e00\u4e2a\u9875\u9762\u88ab\u5c55\u793a\u51fa\u6765\uff0c\u5c31\u79f0\u4f5c\u66dd\u5149\u3002\u5728\u65e5\u5fd7\u4e2d\u8bb0\u5f55\u66dd\u5149\u4e8b\u4ef6\uff0c\u5c31\u662f\u8bb0\u5f55\u6bcf\u4e00\u4e2a\u88ab\u5c55\u793a\u51fa\u6765\u7684\u9875\u9762\u3001\u5546\u54c1\u6216\u8005\u5185\u5bb9\u3002</p> <ul> <li>\u70b9\u51fb\u4e8b\u4ef6</li> </ul> <p>\u800c\u70b9\u51fb\uff0c\u5219\u662f\u7528\u6237\u5728 App \u4e2d\u7684\u70b9\u51fb\u884c\u4e3a\u3002\u901a\u5e38\uff0cApp \u4e2d\u7684\u5404\u79cd\u9875\u9762\u90fd\u662f\u901a\u8fc7\u70b9\u51fb\u8fdb\u884c\u8df3\u8f6c\u7684\uff0c</p> <ul> <li>\u7528\u6237\u505c\u7559\u4e8b\u4ef6</li> </ul> <p>\u8fd9\u4e2a\u4e8b\u4ef6\u8bb0\u5f55\u7684\u662f\u4e00\u4e2a\u7528\u6237\u5728\u67d0\u4e2a\u9875\u9762\uff0c\u6216\u8005\u67d0\u79cd\u60c5\u51b5\u4e0b\u505c\u7559\u7684\u65f6\u95f4\u3002</p> <ul> <li>\u5728\u65b0\u95fb\u63a8\u8350\u573a\u666f\uff0c\u4f7f\u7528\u65b0\u95fb\u66dd\u5149\u548c\u65b0\u95fb\u70b9\u51fb\u53ef\u4ee5\u8ba1\u7b97\u67d0\u6761\u65b0\u95fb\u7684\u70b9\u51fb\u7387 </li> <li>\u5728\u89c6\u9891\u573a\u666f\uff0c\u4f7f\u7528\u70b9\u51fb\u548c\u7528\u6237\u505c\u7559\u65f6\u95f4\u53ef\u4ee5\u8ba1\u7b97\u89c2\u770b\u5b8c\u6210\u6bd4 </li> <li>\u5728\u4ea4\u6613\u573a\u666f\uff0c\u4f7f\u7528\u6d4f\u89c8\u70b9\u51fb\u548c\u4e0b\u5355\u70b9\u51fb\u53ef\u4ee5\u8ba1\u7b97\u8bbf\u8d2d\u7387 </li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/#5","title":"5\u3001\u5c5e\u6027","text":"<p>\u4e0e\u4e8b\u4ef6\u7684\u8fde\u8d2f\u6027\u4e0d\u540c\uff0c\u5c5e\u6027\u7684\u6536\u96c6\u5f80\u5f80\u662f\u4e00\u6b21\u6027\u7684\u3002\u5f53\u6211\u4eec\u6253\u5f00 App \u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u624b\u673a\u578b\u53f7\u3001\u7f51\u7edc\u5236\u5f0f\u3001App \u7248\u672c\u7b49\u4fe1\u606f\u90fd\u4f5c\u4e3a\u5c5e\u6027\u4e00\u6b21\u6027\u5730\u6536\u96c6\u8d77\u6765\u3002</p>"},{"location":"chap11/chap11_3bigdata_coll/#6","title":"6\u3001\u6570\u636e\u57cb\u70b9","text":"<p>\u5b9e\u73b0\u65e5\u5fd7\u91c7\u96c6\u6240\u4f7f\u7528\u7684\u624b\u6bb5\u88ab\u79f0\u4e3a\u6570\u636e\u57cb\u70b9\u3002</p> <p>\u6570\u636e\u57cb\u70b9\u5c31\u662f\u5728\u6211\u4eec App \u7684\u524d\u7aef\uff0c\u4e5f\u5c31\u662f UI \u5c42\u7684\u4ee3\u7801\u4e2d\u63d2\u5165\u4e00\u6bb5\u7528\u4e8e\u76d1\u89c6\u7528\u6237\u884c\u4e3a\u4e8b\u4ef6\u7684\u4ee3\u7801\u3002\u5f53\u7528\u6237\u5728 App \u4e0a\u53d1\u751f\u5bf9\u5e94\u7684\u884c\u4e3a\u65f6\uff0c\u5c31\u4f1a\u89e6\u53d1\u8fd9\u6bb5\u4ee3\u7801\uff0c\u4ece\u800c\u4e0a\u4f20\u8be5\u57cb\u70b9\u4e2d\u4e8b\u5148\u5df2\u7ecf\u5b9a\u4e49\u597d\u7684\u4e8b\u4ef6\u4fe1\u606f\u3002</p> <p>\u901a\u8fc7\u57cb\u70b9\u6536\u96c6\u5230\u7684\u4fe1\u606f\uff1a</p> <ul> <li>\u53ef\u4ee5\u4f5c\u4e3a\u76d1\u63a7\uff0c\u770b\u5230 App \u7684\u957f\u671f\u8868\u73b0\uff1b</li> <li>\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u57fa\u7840\u539f\u6599\uff0c\u8fdb\u884c\u590d\u6742\u7684\u8fd0\u7b97\uff0c\u7528\u4e8e\u7528\u6237\u6807\u7b7e\u3001\u6e20\u9053\u8f6c\u5316\u5206\u6790\u3001\u4e2a\u6027\u63a8\u8350\u7b49\u3002</li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/#7","title":"7\u3001\u6570\u636e\u57cb\u70b9\u7684\u56f0\u96be","text":"<ul> <li>\u6765\u6e90\u4f17\u591a<ul> <li>\u7f51\u9875\u7aef\u3001App\u7aef\uff08\u5b89\u5353\u3001iOS\u751a\u81f3\u5fae\u8f6f\u5ba2\u6237\u7aef\uff09\u3001\u5c0f\u7a0b\u5e8f </li> <li>\u8981\u628a\u4e0d\u540c\u6765\u6e90\u7684\u540c\u4e00\u5904\u884c\u4e3a\u6570\u636e\u8fdb\u884c\u5408\u5e76\u7edf\u8ba1  </li> </ul> </li> <li>\u9875\u9762\u4f17\u591a<ul> <li>\u6d4f\u89c8\u3001\u4e0b\u5355\u3001\u652f\u4ed8 </li> <li>\u4e0d\u540c\u7684\u9875\u9762\uff0c\u4e0d\u540c\u7684\u5f62\u5f0f  </li> </ul> </li> <li>\u6570\u636e\u683c\u5f0f\u5404\u4e0d\u76f8\u540c<ul> <li>\u4e0d\u540c\u7684\u4e1a\u52a1\u53ef\u80fd\u5bf9\u4e8e\u540c\u4e00\u4e2a\u9875\u9762\u7684\u57cb\u70b9\u5b58\u5728\u4e0d\u540c\u7684\u9700\u6c42 </li> </ul> </li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/#8","title":"8\u3001\u57cb\u70b9\u65b9\u5f0f","text":"<p>\u624b\u52a8\u57cb\u70b9\uff1a</p> <ul> <li>\u6240\u8c13\u7684\u57cb\u70b9\u5c31\u662f\u7a0b\u5e8f\u5458\u53bb\u589e\u52a0\u4e00\u4e9b\u4ee3\u7801 </li> <li>\u90a3\u4e48\u624b\u52a8\u57cb\u70b9\u81ea\u7136\u662f\u8bf4\u7a0b\u5e8f\u5458\u624b\u52a8\u5730\u53bb\u589e\u52a0\u4ee3\u7801 </li> </ul> <p>\u597d\u5904\uff1a</p> <ul> <li>\u6ca1\u6709\u5176\u4ed6\u7684\u5f00\u53d1\u91cf\uff0c\u5c5e\u4e8e\u61d2\u60f0\u5f00\u53d1\u7684\u4e00\u79cd\u60c5\u51b5 </li> <li>\u53ea\u6709\u5f53\u9700\u6c42\u63d0\u51fa\u7684\u65f6\u5019\u624d\u53bb\u589e\u52a0\u4e00\u4e2a\u57cb\u70b9 </li> </ul> <p>\u534a\u81ea\u52a8\u57cb\u70b9\uff1a</p> <ul> <li>\u534a\u81ea\u52a8\u7684\u57cb\u70b9\u901a\u5e38\u51fa\u73b0\u5728\u4ea7\u54c1\u5df2\u7ecf\u57fa\u672c\u6210\u719f\u7684\u65f6\u671f</li> <li>\u7a0b\u5e8f\u5458\u5bf9\u4e8e\u76ee\u524d\u4ee5\u53ca\u9884\u671f\u672a\u6765\u7684\u4e1a\u52a1\u6d41\u7a0b\u8fdb\u884c\u4e86\u68b3\u7406</li> <li>\u6574\u7406\u51fa\u4e00\u5957\u5e38\u7528\u7684\u57cb\u70b9\u65b9\u6848\uff0c\u5e76\u628a\u8fd9\u5957\u65b9\u6848\u5d4c\u5165\u5230\u4e1a\u52a1\u4ee3\u7801\u4e2d</li> <li>\u5982\u679c\u6709\u4e00\u4e9b\u5168\u65b0\u7684\u529f\u80fd\u6216\u8005\u9875\u9762\u4e0a\u7ebf\uff0c\u8fd8\u662f\u9700\u8981\u8fdb\u884c\u5f00\u53d1\u7684 </li> </ul> <p>\u5168\u81ea\u52a8\u57cb\u70b9 \uff1a</p> <ul> <li>\u5168\u81ea\u52a8\u57cb\u70b9\u5b8c\u5168\u5ffd\u7565\u4e86\u9700\u6c42\u7684\u5b58\u5728\uff0c\u76f4\u63a5\u4ece\u6700\u57fa\u672c\u7684\u4e8b\u4ef6\u548c\u5c5e\u6027</li> <li> <p>\u628a\u6240\u6709\u7684\u4e1c\u897f\u90fd\u7eb3\u5165\u57cb\u70b9\u7684\u8303\u7574\uff0c\u4e8b\u65e0\u5de8\u7ec6\u5730\u8bb0\u5f55\u4e0b\u6765 </p> </li> <li> <p>\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86\u57cb\u70b9\u7684\u9700\u6c42\uff0c\u4ece\u6b64\u89e3\u653e\u4e86\u53cc\u624b </p> </li> <li>\u6536\u96c6\u5168\u91cf\u4fe1\u606f\uff0c\u7f51\u7edc\u5f00\u9500\u5927\u3001\u5b58\u50a8\u6210\u672c\u9ad8 </li> <li>\u5927\u90e8\u5206\u6ca1\u7528\u7684\u4fe1\u606f\u5219\u4f1a\u5bfc\u81f4\u540e\u7eed\u6570\u636e\u5904\u7406\u7684\u901f\u5ea6\u7f13\u6162 </li> </ul>"},{"location":"chap11/chap11_3bigdata_coll/#9","title":"9\u3001\u8fdb\u9636","text":"<ul> <li>\u5728\u5f00\u53d1\u4e86\u57cb\u70b9\u4ee3\u7801\u7684\u524d\u7aef\u73af\u5883\u4e2d\u76d1\u63a7\u7528\u6237\u7684\u884c\u4e3a\uff0c\u5f53\u7528\u6237\u4ea7\u751f\u884c\u4e3a\u7684\u65f6\u5019\u4f1a\u901a\u8fc7 HTTP \u8bf7\u6c42\u628a\u8fd9\u4e9b\u4e8b\u4ef6\u8fdb\u884c\u4e0a\u62a5\uff0c\u8fdb\u5165\u5230\u65e5\u5fd7\u6536\u96c6\u670d\u52a1\u4e2d\u3002</li> <li>\u65e5\u5fd7\u6536\u96c6\u670d\u52a1\u4f1a\u628a\u8fd9\u4e9b\u65e5\u5fd7\u8f6c\u53d1\u5230\u65e5\u5fd7\u8bb0\u5f55\u670d\u52a1\u4e2d\uff0c\u65e5\u5fd7\u8bb0\u5f55\u670d\u52a1\u901a\u8fc7\u7b80\u5355\u7684\u65e5\u5fd7\u52a0\u5de5\u6c47\u603b\u6210\u4e3a\u539f\u59cb\u65e5\u5fd7\u3002</li> <li>\u5728\u8fd9\u4e2a\u4f4d\u7f6e\uff0c\u901a\u8fc7\u5b9e\u65f6\u7684 ETL \u628a\u539f\u59cb\u65e5\u5fd7\u5904\u7406\u6210\u6807\u51c6\u7684\u683c\u5f0f\uff0c\u6bd4\u5982\u8bf4\u6c47\u603b\u6210\u6211\u4eec\u6240\u9700\u8981\u7684\u7528\u6237 ID \u4e0e\u5546\u54c1 ID\u7684\u5173\u8054\uff0c\u4ee5\u53ca\u662f\u5426\u6709\u66dd\u5149\u3001\u70b9\u51fb\u3001\u4e0b\u5355\u3001\u8d2d\u4e70\u884c\u4e3a\uff0c\u5e76\u5f62\u6210\u4e2d\u95f4\u5c42\u65e5\u5fd7\uff0c\u7528\u4e8e\u5404\u79cd\u5b9e\u65f6\u4efb\u52a1\u3002</li> </ul> <p>\u540c\u65f6\uff0c\u539f\u59cb\u65e5\u5fd7\u548c\u4e2d\u95f4\u5c42\u65e5\u5fd7\u901a\u8fc7 Kafka \u6d88\u606f\u961f\u5217\u540c\u6b65\u5230 HDFS \u4e2d\u4ee5\u5907\u540e\u9762\u7684\u79bb\u7ebf\u5206\u6790\u3002</p> <p>\u5728\u4e0a\u9762\u7684\u4e00\u4e2a\u5206\u652f\u5219\u662f\u540e\u7aef\u670d\u52a1\u7684\u65e5\u5fd7\u91c7\u96c6\uff0c\u76f4\u63a5\u901a\u8fc7 Kafka \u961f\u5217\u6536\u96c6\u4fe1\u606f\u3002</p> <p>\u5b9e\u9645\u4e0a\uff0c\u9664\u4e86\u524d\u7aef\u4ea7\u751f\u7684\u65e5\u5fd7\uff0c\u540e\u7aef\u670d\u52a1\u540c\u6837\u4e5f\u4f1a\u4ea7\u751f\u5404\u79cd\u65e5\u5fd7\u4fe1\u606f\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u591a\u7528\u4e8e\u670d\u52a1\u8fd0\u884c\u72b6\u6001\u7684\u68c0\u6d4b\u3002</p>"},{"location":"chap11/chap11_4bigdata_hdfs/","title":"\u7b2c\u56db\u8282 HDFS\u89e3\u51b3\u5927\u6570\u636e\u5b58\u50a8\u95ee\u9898 &amp; Hadoop on K8S","text":""},{"location":"chap11/chap11_4bigdata_hdfs/#1","title":"1\u3001\u6587\u4ef6\u7cfb\u7edf","text":"<p>\u5728\u7535\u8111\u4e2d\uff0c\u5e38\u7528\u7684\u5b58\u50a8\u6709\u5185\u5b58\u548c\u786c\u76d8\u4e24\u79cd\u5f62\u5f0f\uff1a</p> <ul> <li>\u5185\u5b58\u7684\u901f\u5ea6\u5feb\uff0c\u4f46\u662f\u4ef7\u683c\u66f4\u8d35\uff0c\u6240\u4ee5\u4f7f\u7528\u7684\u5b58\u50a8\u5bb9\u91cf\u8f83\u5c0f\uff1b</li> <li>\u786c\u76d8\u4ef7\u683c\u4fbf\u5b9c\uff0c\u901f\u5ea6\u8981\u6162\u5f88\u591a\u3002</li> </ul> <p>\u7535\u8111\u4e2d\u4e00\u822c\u90fd\u4f7f\u7528\u786c\u76d8\u6765\u8fdb\u884c\u957f\u671f\u5b58\u50a8\uff0c\u800c\u5185\u5b58\u7528\u6765\u5b58\u50a8\u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u6570\u636e\u3002\u6240\u4ee5\uff0c\u5bf9\u4e8e\u6211\u4eec\u7684\u786c\u76d8\u6765\u8bf4\uff0c\u6700\u57fa\u672c\u7684\u529f\u80fd\u5c31\u662f\u8bfb\u53d6\u548c\u5199\u5165\u529f\u80fd\u3002</p> <ul> <li>\u786c\u76d8\u4e0a\u7684\u4f4d\u7f6e\u5982\u4f55\u5212\u5206\uff1b</li> <li>\u600e\u4e48\u80fd\u591f\u5c3d\u5feb\u5728\u786c\u76d8\u4e0a\u627e\u5230\u9700\u8981\u7684\u6570\u636e\uff1b</li> <li>\u5bf9\u4e8e\u4e00\u5757\u7a7a\u95f4\u5982\u4f55\u4fdd\u969c\u8bfb\u6570\u636e\u548c\u5199\u6570\u636e\u4e0d\u662f\u540c\u65f6\u8fdb\u884c\u7684\uff1b</li> </ul> <p>\u4e00\u4e2a\u6587\u4ef6\u5c31\u662f\u4e00\u4e2a\u5355\u5143\uff0c\u5360\u7528\u4e00\u4e2a\u72ec\u7acb\u7684\u5730\u5740\u7a7a\u95f4\uff0c\u7a0b\u5e8f\u53ef\u4ee5\u8bfb\u53d6\u6587\u4ef6\u6216\u8005\u521b\u5efa\u65b0\u7684\u6587\u4ef6\u3002</p> <p>\u800c\u5bf9\u8fd9\u4e9b\u6587\u4ef6\u8fdb\u884c\u7ba1\u7406\uff0c\u89e3\u51b3\u8fd9\u4e9b\u6587\u4ef6\u7684\u7ed3\u6784\u3001\u8bbf\u95ee\u3001\u4fdd\u62a4\u3001\u5bfb\u5740\u7b49\u529f\u80fd\u7684\u7cfb\u7edf\uff0c\u6211\u4eec\u5c31\u79f0\u4e3a\u6587\u4ef6\u7cfb\u7edf\u3002</p> <p>\u800c\u6211\u4eec\u6240\u8981\u4ecb\u7ecd\u7684 HDFS\uff0c\u5168\u79f0 Hadoop Distribute File System\uff0c\u4e5f\u5c31\u662f\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\u7684\u610f\u601d\uff0cHDFS \u662f\u6587\u4ef6\u7cfb\u7edf\u7684\u4e00\u79cd\u5b9e\u4f8b\u3002</p>"},{"location":"chap11/chap11_4bigdata_hdfs/#2hdfs","title":"2\u3001HDFS \u57fa\u7840","text":"<p>HDFS\uff0c\u5b83\u53ef\u4ee5\u5229\u7528\u5ec9\u4ef7\u7684\u666e\u901a\u670d\u52a1\u5668\u4f5c\u4e3a\u5176\u5b58\u50a8\uff0c\u7ec4\u5efa\u4e00\u4e2a\u5927\u89c4\u6a21\u5b58\u50a8\u96c6\u7fa4\uff0c\u4e3a\u5404\u7c7b\u8ba1\u7b97\u63d0\u4f9b\u6570\u636e\u8bbf\u95ee\u7684\u57fa\u7840\u3002\u90a3\u4e48 HDFS \u7684\u6587\u4ef6\u7cfb\u7edf\u6bd4\u8d77\u4e00\u822c\u7684\u6587\u4ef6\u7cfb\u7edf\u6709\u4ec0\u4e48\u7279\u8272\u5462\uff1f</p> <p>\u5176\u5b9e HDFS \u6587\u4ef6\u7cfb\u7edf\u6700\u5927\u7684\u7279\u8272\u5c31\u662f\u5b83\u5728\u5206\u5e03\u5f0f\u67b6\u6784\u4e0a\u7684\u5904\u7406\uff0c\u540c\u65f6 HDFS \u7684\u8bbe\u8ba1\u9002\u5408\u4e00\u6b21\u5199\u5165\uff0c\u591a\u6b21\u8bfb\u51fa\u7684\u573a\u666f\uff0c\u4e14\u4e0d\u652f\u6301\u6587\u4ef6\u7684\u4fee\u6539\uff0c\u6240\u4ee5\u4e0d\u9002\u5408\u53cd\u590d\u4fee\u6539\u6570\u636e\u7684\u573a\u666f\u3002</p>"},{"location":"chap11/chap11_4bigdata_hdfs/#2-1-hdfs","title":"2-1 HDFS \u7684\u67b6\u6784","text":"<p>1\u3001\u6570\u636e\u5757</p> <p>HDFS \u9ed8\u8ba4\u6700\u57fa\u672c\u7684\u5b58\u50a8\u5355\u4f4d\u662f 64MB \u7684\u6570\u636e\u5757\uff08\u5728 2.x \u7248\u672c\u4e2d\u662f 128MB\uff09\uff0c\u5927\u5c0f\u901a\u8fc7\u914d\u7f6e\u53ef\u8c03\u3002\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u672a\u8fbe\u5230\u6570\u636e\u5757\u5927\u5c0f\u7684\u6587\u4ef6\uff0c\u4e0d\u4f1a\u5360\u7528\u6574\u4e2a\u6570\u636e\u5757\u7684\u5b58\u50a8\u7a7a\u95f4\u3002</p> <p>2\u3001\u5143\u6570\u636e\u8282\u70b9\uff08NameNode\uff09</p> <p>\u5143\u6570\u636e\u8282\u70b9\u7b97\u662f HDFS \u4e2d\u975e\u5e38\u91cd\u8981\u7684\u4e00\u4e2a\u6982\u5ff5\uff0c\u7528\u4e8e\u7ba1\u7406\u6587\u4ef6\u7cfb\u7edf\u7684\u547d\u4ee4\u7a7a\u95f4\uff0c\u5c06\u6240\u6709\u6587\u4ef6\u548c\u6587\u4ef6\u5939\u7684\u5143\u6570\u636e\u4fdd\u5b58\u5728\u6587\u4ef6\u7cfb\u7edf\u6811\u4e2d\uff0c\u901a\u8fc7\u5728\u786c\u76d8\u4fdd\u5b58\u907f\u514d\u4e22\u5931\uff0c\u91c7\u7528\u6587\u4ef6\u547d\u540d\u7a7a\u95f4\u955c\u50cf\uff08fs image\uff09\u53ca\u4fee\u6539\u65e5\u5fd7\uff08edit log\uff09\u65b9\u5f0f\u4fdd\u5b58\u3002</p> <p>3\u3001\u6570\u636e\u8282\u70b9\uff08DataNode\uff09</p> <p>\u6570\u636e\u8282\u70b9\u5373\u662f\u771f\u6b63\u6570\u636e\u5b58\u50a8\u7684\u5730\u65b9\u3002</p> <p>4\u3001\u4ece\u5143\u6570\u636e\u8282\u70b9\uff08Secondary NameNode\uff09</p> <p>\u4ece\u5b57\u9762\u6765\u770b\u50cf\u662f\u5143\u6570\u636e\u8282\u70b9\u7684\u5907\u7528\u8282\u70b9\uff0c\u4f46\u5b9e\u9645\u4e0d\u7136\uff0c\u5b83\u548c\u5143\u6570\u636e\u8282\u70b9\u8d1f\u8d23\u4e0d\u540c\u7684\u4e8b\u60c5\uff0c\u4e3b\u8981\u8d1f\u8d23\u5c06\u547d\u540d\u7a7a\u95f4\u955c\u50cf\u4e0e\u4fee\u6539\u65e5\u5fd7\u6587\u4ef6\u5468\u671f\u6027\u5408\u5e76\uff0c\u907f\u514d\u6587\u4ef6\u8fc7\u5927\uff0c\u5408\u5e76\u8fc7\u540e\u6587\u4ef6\u4f1a\u540c\u6b65\u81f3\u5143\u6570\u636e\u8282\u70b9\uff0c\u540c\u65f6\u672c\u5730\u4fdd\u5b58\u4e00\u4efd\uff0c\u4ee5\u4fbf\u5728\u51fa\u73b0\u6545\u969c\u65f6\u6062\u590d\u3002</p> <p>5\u3001Client\uff0c\u5373\u5ba2\u6237\u7aef</p> <ul> <li>\u5ba2\u6237\u7aef\u662f\u6211\u4eec\u5e73\u65f6\u7528\u6765\u548c HDFS \u670d\u52a1\u8fdb\u884c\u4ea4\u4e92\u7684\u90e8\u5206\uff0c\u5ba2\u6237\u7aef\u4e2d\u5185\u7f6e\u4e86\u4e00\u5957\u6587\u4ef6\u64cd\u4f5c\u547d\u4ee4\u6765\u5e2e\u52a9\u6211\u4eec\u8bbf\u95ee HDFS \u670d\u52a1\uff0c\u6bd4\u5982\u8bf4\u6211\u4eec\u4e0a\u4f20\u6587\u4ef6\u3001\u4e0b\u8f7d\u6587\u4ef6\uff1b</li> <li>\u540c\u65f6\u5ba2\u6237\u7aef\u8fd8\u8d1f\u8d23\u628a\u6211\u4eec\u4e0a\u4f20\u7684\u6587\u4ef6\u6309\u524d\u9762\u8bf4\u7684\u6570\u636e\u5757\u8fdb\u884c\u5207\u5206\uff0c\u4ee5\u65b9\u4fbf\u540e\u7eed\u7684\u5b58\u50a8\uff1b</li> <li>\u56e0\u6b64\uff0c\u5ba2\u6237\u7aef\u5f53\u7136\u4e5f\u8d1f\u8d23\u4e0e NameNode \u548c DataNode \u8fdb\u884c\u4ea4\u4e92\u4ee5\u83b7\u53d6\u6587\u4ef6\u4f4d\u7f6e\u6216\u8005\u8bfb\u5199\u6587\u4ef6\u64cd\u4f5c\u7b49\u3002</li> </ul> <p>HDFS\u7684\u67b6\u6784</p> <p></p>"},{"location":"chap11/chap11_4bigdata_hdfs/#3hdfs","title":"3\u3001HDFS \u7684\u4f18\u7f3a\u70b9","text":""},{"location":"chap11/chap11_4bigdata_hdfs/#3-1","title":"3-1 \u4f18\u70b9","text":"<ul> <li> <p>\u9ad8\u5bb9\u9519\u6027\u3002</p> <ul> <li>\u5728 HDFS \u6587\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u6570\u636e\u90fd\u4f1a\u6709\u591a\u4e2a\u526f\u672c\u3002\u5176\u4e2d\u7684\u67d0\u4e00\u4e2a\u526f\u672c\u4e22\u5931\uff08\u67d0\u4e00\u4e2a\u8282\u70b9\u7684\u673a\u5668\u635f\u574f\uff09\u5e76\u4e0d\u5f71\u54cd\u6574\u4f53\u7684\u4f7f\u7528\uff0c\u53ef\u4ee5\u81ea\u52a8\u6062\u590d\u3002</li> </ul> </li> <li> <p>\u9002\u5408\u5927\u6570\u636e\u5904\u7406\u3002</p> <ul> <li>\u6570\u636e\u89c4\u6a21\uff1a\u80fd\u591f\u5904\u7406\u6570\u636e\u89c4\u6a21\u8fbe\u5230 GB\u3001TB\u3001\u751a\u81f3 PB \u7ea7\u522b\u7684\u6570\u636e\uff1b</li> <li>\u6587\u4ef6\u89c4\u6a21\uff1a\u80fd\u591f\u5904\u7406\u767e\u4e07\u89c4\u6a21\u4ee5\u4e0a\u7684\u6587\u4ef6\u6570\u91cf\uff0c\u76f8\u5f53\u4e4b\u5927\u3002</li> </ul> </li> <li> <p>\u63d0\u4f9b\u6570\u636e\u4e00\u81f4\u6027\u4fdd\u969c\u3002</p> </li> <li>\u4efb\u610f\u4e00\u4e2a\u8282\u70b9\u6240\u5360\u7528\u7684\u8d44\u6e90\u8f83\u5c11\uff0c\u53ef\u4ee5\u5728\u5ec9\u4ef7\u7684\u673a\u5668\u4e0a\u8fd0\u884c\uff0c\u652f\u6301\u7ebf\u6027\u6269\u5f20\u3002</li> </ul> <p>3-2 \u7f3a\u70b9</p> <ul> <li>\u4e0d\u9002\u5408\u4f4e\u5ef6\u65f6\u6570\u636e\u8bbf\u95ee\uff0c\u6bd4\u5982\u6beb\u79d2\u7ea7\u7684\u5b58\u50a8\u6570\u636e\uff0c\u662f\u505a\u4e0d\u5230\u7684\u3002</li> <li>\u65e0\u6cd5\u9ad8\u6548\u5730\u5bf9\u5927\u91cf\u5c0f\u6587\u4ef6\u8fdb\u884c\u5b58\u50a8\u3002<ul> <li>\u5b58\u50a8\u5927\u91cf\u5c0f\u6587\u4ef6\u7684\u8bdd\uff0c\u5b83\u4f1a\u5360\u7528 NameNode \u5927\u91cf\u7684\u5185\u5b58\u6765\u5b58\u50a8\u6587\u4ef6\u3001\u76ee\u5f55\u548c\u5757\u4fe1\u606f\u3002\u8fd9\u6837\u662f\u4e0d\u53ef\u53d6\u7684\uff0c\u56e0\u4e3a NameNode \u7684\u5185\u5b58\u603b\u662f\u6709\u9650\u7684\uff1b</li> <li>\u5c0f\u6587\u4ef6\u5b58\u50a8\u7684\u5bfb\u5740\u65f6\u95f4\u4f1a\u8d85\u8fc7\u8bfb\u53d6\u65f6\u95f4\uff0c\u5b83\u8fdd\u53cd\u4e86 HDFS \u7684\u8bbe\u8ba1\u76ee\u6807\u3002</li> </ul> </li> <li>\u4e0d\u652f\u6301\u5e76\u53d1\u5199\u5165\u3001\u6587\u4ef6\u968f\u673a\u4fee\u6539\u3002</li> </ul> <p>\u5bf9\u4e8e\u4e00\u4e2a\u6587\u4ef6\uff0c\u53ea\u80fd\u6709\u4e00\u4e2a\u7ebf\u7a0b\u5199\u5165\uff0c\u4e0d\u53ef\u4ee5\u591a\u4e2a\u7ebf\u7a0b\u540c\u65f6\u5199\u5165\u3002\u57fa\u672c\u4e0d\u80fd\u8fdb\u884c\u6587\u4ef6\u7684\u4fee\u6539\uff0c\u53ea\u652f\u6301\u6570\u636e\u7684\u8ffd\u52a0\uff0c\u5982\u679c\u60f3\u4fee\u6539\u9700\u8981\u4f7f\u7528\u65b0\u6587\u4ef6\u8986\u76d6\u6574\u4e2a\u65e7\u7684\u6587\u4ef6\u3002</p>"},{"location":"chap11/chap11_4bigdata_hdfs/#4kuberneteshadoop","title":"4\u3001\u5728Kubernetes\u5e73\u53f0\u4e0a\u8fd0\u884cHadoop\u7684\u5b9e\u8df5","text":"<p>\u672c\u6587\u6211\u4eec\u7ed9\u51faHadoop\u5728Kubernetes\u4e0a\u7684\u5b9e\u8df5\u6848\u4f8b\uff0c\u4ee5\u5f25\u8865\u8fd9\u79cd\u7f3a\u61be\u3002</p> <ul> <li>\u7b2c\u4e00\uff0c Hadoop\u96c6\u7fa4\u91cd\u5ea6\u4f9d\u8d56DNS\u673a\u5236\uff0c\u4e00\u4e9b\u7ec4\u4ef6\u8fd8\u4f7f\u7528\u4e86\u53cd\u5411\u57df\u540d\u89e3\u6790\uff0c\u4ee5\u786e\u5b9a\u96c6\u7fa4\u4e2d\u7684\u8282\u70b9\u8eab\u4efd\uff0c\u8fd9\u5bf9Hadoop\u5728Kubernetes\u4e0a\u7684\u5efa\u6a21\u548c\u8fd0\u884c\u5e26\u6765\u6781\u5927\u6311\u6218\uff0c\u9700\u8981\u6df1\u5165\u4e86\u89e3Hadoop\u96c6\u7fa4\u5de5\u4f5c\u539f\u7406\u5e76\u4e14\u7cbe\u901aKubernetes\uff0c\u624d\u80fd\u5f88\u597d\u89e3\u51b3\u8fd9\u4e00\u96be\u9898\u3002</li> <li>\u7b2c\u4e8c\uff0c Hadoop\u65b0\u7684Map-Reduce\u8ba1\u7b97\u6846\u67b6Yarn\u7684\u6a21\u578b\u51fa\u73b0\u7684\u6bd4\u8f83\u665a\uff0c\u5b83\u7684\u96c6\u7fa4\u673a\u5236\u8981\u6bd4HDFS\u590d\u6742\uff0c\u8d44\u6599\u4e5f\u76f8\u5bf9\u8f83\u5c11\uff0c\u589e\u52a0\u4e86Hadoop\u6574\u4f53\u5efa\u6a21\u4e0e\u8fc1\u79fbKubernetes\u5e73\u53f0\u7684\u96be\u5ea6\u3002</li> <li>\u7b2c\u4e09\uff0c Hadoop\u4e0eKubernetes\u5206\u522b\u5c5e\u4e8e\u4e24\u4e2a\u4e0d\u540c\u7684\u9886\u57df\uff0c\u4e00\u4e2a\u662f\u4f20\u7edf\u7684\u5927\u6570\u636e\u9886\u57df\uff0c\u4e00\u4e2a\u662f\u65b0\u5174\u7684\u5bb9\u5668\u4e0e\u5fae\u670d\u52a1\u67b6\u6784\u9886\u57df\uff0c\u8fd9\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u4ea4\u96c6\u672c\u6765\u5f88\u5c0f\uff0c\u52a0\u4e4bHadoop\u6700\u8fd1\u51e0\u5e74\u5df2\u7ecf\u5931\u53bb\u7126\u70b9\uff08\u8fd9\u70b9\u4ece\u767e\u5ea6\u641c\u7d22\u5173\u952e\u8bcd\u5c31\u80fd\u53d1\u73b0\uff09\uff0c\u6240\u4ee5\uff0c\u6ca1\u6709\u591a\u5c11\u4eba\u5173\u6ce8\u548c\u7814\u7a76Hadoop\u5728Kubernetes\u7684\u90e8\u7f72\u95ee\u9898\uff0c\u4e5f\u662f\u60c5\u7406\u4e4b\u4e2d\u7684\u4e8b\u60c5\u3002</li> </ul> <p>Hadoop 2.0\u5176\u5b9e\u662f\u7531\u4e24\u5957\u5b8c\u6574\u7684\u96c6\u7fa4\u6240\u7ec4\u6210\uff0c\u4e00\u4e2a\u662f\u57fa\u672c\u7684HDFS\u6587\u4ef6\u96c6\u7fa4\uff0c\u4e00\u4e2a\u662fYARN\u8d44\u6e90\u8c03\u5ea6\u96c6\u7fa4\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u56e0\u6b64\u5728Kubernetes\u5efa\u6a21\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5206\u522b\u5bf9\u8fd9\u4e24\u79cd\u96c6\u7fa4\u7684\u5de5\u4f5c\u673a\u5236\u548c\u8fd0\u884c\u539f\u7406\u505a\u51fa\u6df1\u5165\u7684\u5206\u6790\uff0c\u4e0b\u56fe\u662fHDFS\u96c6\u7fa4\u7684\u67b6\u6784\u56fe\uff1a</p> <p></p> <p>\u6211\u4eec\u770b\u5230\uff0cHDFS\u96c6\u7fa4\u662f\u7531NameNode\uff08Master\u8282\u70b9\uff09\u548cDatanode\uff08\u6570\u636e\u8282\u70b9\uff09\u7b49\u4e24\u7c7b\u8282\u70b9\u6240\u7ec4\u6210\uff0c\u5176\u4e2d\uff0c\u5ba2\u6237\u7aef\u7a0b\u5e8f\uff08Client\uff09\u4ee5\u53caDataNode\u8282\u70b9\u4f1a\u8bbf\u95eeNameNode\uff0c\u56e0\u6b64\uff0cNameNode\u8282\u70b9\u9700\u8981\u5efa\u6a21\u4e3aKubernetes Service\u4ee5\u63d0\u4f9b\u670d\u52a1\uff0c\u4ee5\u4e0b\u662f\u5bf9\u5e94\u7684Service\u5b9a\u4e49\u6587\u4ef6\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: k8s-hadoop-master\nspec:\n  // type: NodePort\n  type: clusterIP\n  selector:\n    app: k8s-hadoop-master\n  ports:\n    - name: rpc\n      port: 9000\n      targetPort: 9000\n    - name: http\n      port: 50070\n      targetPort: 50070\n      nodePort: 32007\n</code></pre> <p>\u5176\u4e2d\uff0cNameNode\u8282\u70b9\u66b4\u97322\u4e2a\u670d\u52a1\u7aef\u53e3\uff1a</p> <ul> <li>9000\u7aef\u53e3\u7528\u4e8e\u5185\u90e8IPC\u901a\u4fe1\uff0c\u4e3b\u8981\u7528\u4e8e\u83b7\u53d6\u6587\u4ef6\u7684\u5143\u6570\u636e</li> <li>50070\u7aef\u53e3\u7528\u4e8eHTTP\u670d\u52a1\uff0c\u4e3aHadoop \u7684Web\u7ba1\u7406\u4f7f\u7528</li> </ul> <p>\u4e3a\u4e86\u51cf\u5c11Hadoop\u955c\u50cf\u7684\u6570\u91cf\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u955c\u50cf\uff0c\u5e76\u4e14\u901a\u8fc7\u5bb9\u5668\u7684\u73af\u5883\u53d8\u91cf<code>HADOOP_NODE_TYPE</code>\u6765\u533a\u5206\u4e0d\u540c\u7684\u8282\u70b9\u7c7b\u578b\uff0c\u4ece\u800c\u542f\u52a8\u4e0d\u540c\u7684<code>Hadoop</code>\u7ec4\u4ef6\uff0c\u4e0b\u9762\u662f\u955c\u50cf\u91cc\u7684\u542f\u52a8\u811a\u672cstartnode.sh\u7684\u5185\u5bb9\uff1a</p> <pre><code>#!/usr/bin/env bash\nsed -i \"s/@HDFS_MASTER_SERVICE@/$HDFS_MASTER_SERVICE/g\" $HADOOP_HOME/etc/hadoop/core-site.xml\nsed -i \"s/@HDOOP_YARN_MASTER@/$HDOOP_YARN_MASTER/g\" $HADOOP_HOME/etc/hadoop/yarn-site.xml\nyarn-master\nHADOOP_NODE=\"${HADOOP_NODE_TYPE}\"\nif [ $HADOOP_NODE = \"datanode\" ]; then\n        echo \"Start DataNode ...\"\n        hdfs datanode  -regular\nelse\n    if [  $HADOOP_NODE = \"namenode\" ]; then\n        echo \"Start NameNode ...\"\n        hdfs namenode\n    else\n        if [ $HADOOP_NODE = \"resourceman\" ]; then\n            echo \"Start Yarn Resource Manager ...\"\n            yarn resourcemanager\n        else\n             if [ $HADOOP_NODE = \"yarnnode\" ]; then\n                 echo \"Start Yarn Resource Node  ...\"\n                 yarn nodemanager    \n             else               \n                echo \"not recoginized nodetype \"\n             fi\n        fi\n    fi  \nfi\n</code></pre> <p>\u6211\u4eec\u6ce8\u610f\u5230\uff0c\u542f\u52a8\u547d\u4ee4\u91cc\u628aHadoop\u914d\u7f6e\u6587\u4ef6\uff08<code>core-site.xml</code>\u4e0e<code>yarn-site.xml</code>\uff09\u4e2d\u7684HDFS Master\u8282\u70b9\u5730\u5740\u7528\u73af\u5883\u53d8\u91cf\u4e2d\u7684\u53c2\u6570<code>HDFS_MASTER_SERVICE</code>\u6765\u66ff\u6362\uff0cYARN Master\u8282\u70b9\u5730\u5740\u5219\u7528<code>HDOOP_YARN_MASTER</code>\u6765\u66ff\u6362\u3002</p> <p>\u4e0b\u56fe\u662fHadoop HDFS 2\u8282\u70b9\u96c6\u7fa4\u7684\u5b8c\u6574\u5efa\u6a21\u793a\u610f\u56fe\uff1a</p> <p></p> <p>\u56fe\u4e2d\u7684\u5706\u5708\u8868\u793aPod\uff0c\u53ef\u4ee5\u770b\u5230\uff0cDatanode\u5e76\u6ca1\u6709\u5efa\u6a21<code>Kubernetes Service</code>\uff0c\u800c\u662f\u5efa\u6a21\u4e3a\u72ec\u7acb\u7684Pod\uff0c\u8fd9\u662f\u56e0\u4e3aDatanode\u5e76\u4e0d\u76f4\u63a5\u88ab\u5ba2\u6237\u7aef\u6240\u8bbf\u95ee\uff0c\u56e0\u6b64\u65e0\u9700\u5efa\u6a21<code>Service</code>\u3002</p> <p>\u5f53Datanode\u8fd0\u884c\u5728Pod\u5bb9\u5668\u91cc\u7684\u65f6\u5019\uff0c\u6211\u4eec\u9700\u8981\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u4ee5\u4e0b\u53c2\u6570\uff0c\u53d6\u6d88<code>DataNode</code>\u8282\u70b9\u6240\u5728\u4e3b\u673a\u7684\u4e3b\u673a\u540d\uff08DNS\uff09\u4e0e\u5bf9\u5e94IP\u5730\u5740\u7684\u68c0\u67e5\u673a\u5236\uff1a</p> <pre><code>dfs.namenode.datanode.registration.ip-hostname-check=false\n</code></pre> <p>\u5982\u679c\u4e0a\u8ff0\u53c2\u6570\u6ca1\u6709\u4fee\u6539\uff0c\u5c31\u4f1a\u51fa\u73b0DataNode\u96c6\u7fa4\u201c\u5206\u88c2\u201d\u7684\u5047\u8c61\uff0c\u56e0\u4e3aPod\u7684\u4e3b\u673a\u540d\u65e0\u6cd5\u5bf9\u5e94Pod\u7684IP\u5730\u5740\uff0c\u56e0\u6b64\u754c\u9762\u4f1a\u663e\u793a2\u4e2a\u8282\u70b9\uff0c\u8fd9\u4e24\u4e2a\u8282\u70b9\u90fd\u72b6\u6001\u90fd\u4e3a\u5f02\u5e38\u72b6\u6001\u3002</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: k8s-hadoop-master\n  labels:\n    app: k8s-hadoop-master\nspec:\n  containers:\n    - name: k8s-hadoop-master\n      image: kubeguide/hadoop\n      imagePullPolicy: IfNotPresent\n      ports:\n        - containerPort: 9000\n        - containerPort: 50070    \n      env:\n        - name: HADOOP_NODE_TYPE\n          value: namenode\n        - name: HDFS_MASTER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDFS_MASTER_SERVICE\n        - name: HDOOP_YARN_MASTER\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDOOP_YARN_MASTER\n  restartPolicy: Always\n</code></pre> <p>\u4e0b\u9762\u662fHDFS\u7684Datanode\u7684\u8282\u70b9\u5b9a\u4e49\uff08<code>hadoop-datanode-1</code>\uff09\uff1a</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n    name: hadoop-datanode-1\n    labels:\n      app: hadoop-datanode-1\nspec:\n  containers:\n    - name: hadoop-datanode-1\n      image: kubeguide/hadoop\n      imagePullPolicy: IfNotPresent\n      ports:\n        - containerPort: 9000\n        - containerPort: 50070    \n      env:\n        - name: HADOOP_NODE_TYPE\n          value: datanode\n        - name: HDFS_MASTER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDFS_MASTER_SERVICE\n        - name: HDOOP_YARN_MASTER\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDOOP_YARN_MASTER        \n  restartPolicy: Always\n</code></pre> <p>\u5b9e\u9645\u4e0a\uff0cDatanode\u53ef\u4ee5\u7528DaemonSet\u65b9\u5f0f\u5728\u6bcf\u4e2aKubernerntes\u8282\u70b9\u4e0a\u90e8\u7f72\u4e00\u4e2a\uff0c\u5728\u8fd9\u91cc\u4e3a\u4e86\u6e05\u6670\u8d77\u89c1\uff0c\u5c31\u6ca1\u6709\u7528\u8fd9\u4e2a\u65b9\u5f0f \u5b9a\u4e49\u3002</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u6765\u770b\u770bYarn\u6846\u67b6\u5982\u4f55\u5efa\u6a21\uff0c\u4e0b\u56fe\u662fYarn\u6846\u67b6\u7684\u96c6\u7fa4\u67b6\u6784\u56fe\uff1a</p> <p></p> <p>\u6211\u4eec\u770b\u5230\uff0cYarn\u96c6\u7fa4\u4e2d\u5b58\u5728\u4e24\u79cd\u89d2\u8272\u7684\u8282\u70b9\uff1a</p> <p>ResourceManager\u4ee5\u53caNodeManger\uff0c\u524d\u8005\u5c5e\u4e8eYarn\u96c6\u7fa4\u7684\u5934\u8111\uff08Master\uff09\uff0c\u540e\u8005\u662f\u5de5\u4f5c\u627f\u8f7d\u8282\u70b9\uff08Work Node\uff09\uff0c\u8fd9\u4e2a\u67b6\u6784\u867d\u7136\u4e0eHDFS\u5f88\u76f8\u4f3c\uff0c\u4f46\u56e0\u4e3a\u4e00\u4e2a\u91cd\u8981\u7ec6\u8282\u7684\u5dee\u522b\uff0c\u65e0\u6cd5\u6cbf\u7528HDFS\u7684\u5efa\u6a21\u65b9\u5f0f\uff0c\u8fd9\u4e2a\u7ec6\u8282\u5c31\u662fYarn\u96c6\u7fa4\u4e2d\u7684ResourceManager\u8981\u5bf9NodeManger\u8282\u70b9\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\uff0c\u5373NodeManger\u8282\u70b9\u7684\u8282\u70b9\u6240\u5728\u4e3b\u673a\u7684\u4e3b\u673a\u540d\uff08DNS\uff09\u4e0e\u5bf9\u5e94IP\u5730\u5740\u4e25\u683c\u5339\u914d\uff0c</p> <p>\u7b80\u5355\u6765\u8bf4\uff0c\u5c31\u662f\u8981\u7b26\u5408\u5982\u4e0b\u89c4\u5219\uff1a</p> <p>NodeManger\u5efa\u7acbTCP\u8fde\u63a5\u65f6\u6240\u7528\u7684IP\u5730\u5740\uff0c\u5fc5\u987b\u662f\u8be5\u8282\u70b9\u4e3b\u673a\u540d\u5bf9\u5e94\u7684IP\u5730\u5740\uff0c\u5373\u4e3b\u673aDNS\u540d\u79f0\u89e3\u6790\u540e\u8fd4\u56de\u8282\u70b9\u7684IP\u5730\u5740\u3002</p> <p>\u6240\u4ee5\u6211\u4eec\u91c7\u7528\u4e86Kubernetes\u91cc\u8f83\u4e3a\u7279\u6b8a\u7684\u4e00\u79cdService\u2014\u2014Headless Service\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5373\u4e3a\u6bcf\u4e2aNodeManger\u8282\u70b9\u5efa\u6a21\u4e00\u4e2aHeadless Service\u4e0e\u5bf9\u5e94\u7684Pod\uff0c\u4e0b\u9762\u662f\u4e00\u4e2aResourceManager\u4e0e\u4e24\u4e2aNodeManger\u8282\u70b9\u6240\u7ec4\u6210\u7684Yarn\u96c6\u7fa4\u7684\u5efa\u6a21\u793a\u610f\u56fe\uff1a</p> <p>Headless Service\u7684\u7279\u6b8a\u4e4b\u5904\u5728\u4e8e\u8fd9\u79cdService\u6ca1\u6709\u5206\u914dCluster IP\uff0c</p> <p>\u5728Kuberntes DNS\u91ccPing\u8fd9\u79cdService\u7684\u540d\u79f0\u65f6\uff0c\u4f1a\u8fd4\u56de\u540e\u9762\u5bf9\u5e94\u7684Pod\u7684IP\u5730\u5740\uff0c\u5982\u679c\u540e\u9762\u6709\u591a\u4e2aPod\u5b9e\u4f8b\uff0c\u5219\u4f1a\u968f\u673a\u8f6e\u8be2\u8fd4\u56de\u5176\u4e2d\u4e00\u4e2a\u7684Pod\u5730\u5740\uff0c\u6211\u4eec\u7528Headless Service\u5efa\u6a21NodeManger\u7684\u65f6\u5019\uff0c</p> <p>\u8fd8\u6709\u4e00\u4e2a\u7ec6\u8282\u9700\u8981\u6ce8\u610f\uff0c\u5373Pod\u7684\u540d\u5b57\uff08\u5bb9\u5668\u7684\u4e3b\u673a\u540d\uff09\u5fc5\u987b\u4e0e\u5bf9\u5e94\u7684Headless Service\u7684\u540d\u5b57\u4e00\u6837\uff0c\u8fd9\u6837\u4e00\u6765\uff0c\u5f53\u8fd0\u884c\u5728\u5bb9\u5668\u91cc\u7684NodeManger\u8fdb\u7a0b\u5411ResourceManager\u53d1\u8d77TCP\u8fde\u63a5\u7684\u8fc7\u7a0b\u4e2d\u4f1a\u7528\u5230\u5bb9\u5668\u7684\u4e3b\u673a\u540d\uff0c\u800c\u8fd9\u4e2a\u4e3b\u673a\u540d\u6070\u597d\u662fNodeManger Service\u7684\u670d\u52a1\u540d\uff0c\u800c\u8fd9\u4e2a\u670d\u52a1\u540d\u89e3\u6790\u51fa\u6765\u7684IP\u5730\u5740\u53c8\u521a\u597d\u662f\u5bb9\u5668\u7684IP\u5730\u5740\uff0c\u8fd9\u6837\u4e00\u6765\uff0c\u5c31\u5de7\u5999\u7684\u89e3\u51b3\u4e86Yarn\u96c6\u7fa4\u7684DNS\u9650\u5236\u95ee\u9898\u3002</p> <p>\u4e0b\u9762\u4ee5yarn-node-1\u4e3a\u4f8b\uff0c\u7ed9\u51fa\u5bf9\u5e94\u7684Service\u4e0ePod\u7684YAM\u6587\u4ef6\uff0c\u9996\u5148\u662fyarn-node-1\u5bf9\u5e94\u7684Headless Service\u7684YAM\u5b9a\u4e49\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: yarn-node-1\nspec:\n  clusterIP: None\n  selector:\n    app: yarn-node-1\n  ports:\n     - port: 8040\n</code></pre> <p>\u6ce8\u610f\u5230\u5b9a\u4e49\u4e2d\u201cclusterIP:None\u201d\u8fd9\u53e5\u8bdd\uff0c\u8868\u660e\u8fd9\u662f\u4e00\u4e2aHeadless Service\uff0c\u6ca1\u6709\u81ea\u5df1\u7684Cluster IP\u5730\u5740\uff0c\u4e0b\u9762\u7ed9\u51faYAM\u6587\u4ef6\u5b9a\u4e49\uff1a</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: yarn-node-1\n  labels:\n    app: yarn-node-1\nspec:\n  containers:\n    - name: yarn-node-1\n      image: kubeguide/hadoop\n      imagePullPolicy: IfNotPresent\n      ports:\n        - containerPort: 8040\n        - containerPort: 8041   \n        - containerPort: 8042        \n      env:\n        - name: HADOOP_NODE_TYPE\n          value: yarnnode\n        - name: HDFS_MASTER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDFS_MASTER_SERVICE\n        - name: HDOOP_YARN_MASTER\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDOOP_YARN_MASTER          \n  restartPolicy: Always\n</code></pre> <p>ResourceManager\u7684YAML\u5b9a\u4e49\u6ca1\u6709\u4ec0\u4e48\u7279\u6b8a\u7684\u5730\u65b9\uff0c\u5176\u4e2dService\u5b9a\u4e49\u5982\u4e0b\uff1a</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: ku8-yarn-master\nspec:\n  type: NodePort\n  selector:\n    app: yarn-master\n  ports:\n     - name: \"8030\"       \n       port: 8030\n     - name: \"8031\"     \n       port: 8031\n     - name: \"8032\"\n       port: 8032     \n     - name: http\n       port: 8088\n       targetPort: 8088\n       nodePort: 32088\n</code></pre> <p>\u5bf9\u5e94\u7684Pod\u5b9a\u4e49\u5982\u4e0b\uff1a</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: yarn-master\n  labels:\n    app: yarn-master\nspec:\n  containers:\n    - name: yarn-master\n      image: kubeguide/hadoop\n      imagePullPolicy: IfNotPresent\n      ports:\n        - containerPort: 9000\n        - containerPort: 50070    \n      env:\n        - name: HADOOP_NODE_TYPE\n          value: resourceman\n        - name: HDFS_MASTER_SERVICE\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDFS_MASTER_SERVICE\n        - name: HDOOP_YARN_MASTER\n          valueFrom:\n            configMapKeyRef:\n              name: ku8-hadoop-conf\n              key: HDOOP_YARN_MASTER          \n  restartPolicy: Always\n</code></pre> <p>\u76ee\u524d\u8fd9\u4e2a\u65b9\u6848\uff0c\u8fd8\u9057\u7559\u4e86\u4e00\u4e2a\u95ee\u9898\u6709\u5f85\u89e3\u51b3\uff1aHDFS NameNode\u8282\u70b9\u91cd\u542f\u540e\u7684\u6587\u4ef6\u7cfb\u7edf\u683c\u5f0f\u5316\u95ee\u9898\uff0c\u8fd9\u4e2a\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u542f\u52a8\u811a\u672c\u6765\u89e3\u51b3\uff0c\u5373\u5224\u65adHDFS\u6587\u4ef6\u7cfb\u7edf\u662f\u5426\u5df2\u7ecf\u683c\u5f0f\u5316\u8fc7\uff0c\u5982\u679c\u6ca1\u6709\uff0c\u5c31\u542f\u52a8\u65f6\u5019\u6267\u884c\u683c\u5f0f\u5316\u547d\u4ee4\uff0c\u5426\u5219\u8df3\u8fc7\u683c\u5f0f\u5316\u547d\u4ee4\u3002</p> <p>\u5b89\u88c5\u5b8c\u6bd5\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6d4f\u89c8\u5668\u8bbf\u95eeHadoop\u7684HDFS\u7ba1\u7406\u754c\u9762\uff0c\u70b9\u51fb\u4e3b\u9875\u4e0a\u7684Overview\u9875\u7b7e\u4f1a\u663e\u793a\u6211\u4eec\u719f\u6089\u7684HDFS\u754c\u9762\uff1a</p> <p></p> <p>\u5207\u6362\u5230Datanodes\u9875\u7b7e\uff0c\u53ef\u4ee5\u770b\u5230\u6bcf\u4e2aDatanodes\u7684\u7684\u4fe1\u606f\u4ee5\u53ca\u5f53\u524d\u72b6\u6001\uff1a</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u53ef\u4ee5\u767b\u5f55\u5230NameNode\u6240\u5728\u7684Pod\u91cc\u5e76\u6267\u884cHDSF\u547d\u4ee4\u8fdb\u884c\u529f\u80fd\u6027\u9a8c\u8bc1\uff0c\u4e0b\u9762\u7684\u547d\u4ee4\u6267\u884c\u7ed3\u679c\u662f\u5efa\u7acb\u4e00\u4e2aHDFS\u76ee\u5f55\uff0c\u5e76\u4e14\u4e0a\u4f20\u4e00\u4e2a\u6587\u4ef6\u5230\u6b64\u76ee\u5f55\u4e2d\uff1a</p> <p></p> <p>\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5728HDFS\u7ba1\u7406\u754c\u9762\u4e2d\u6d4f\u89c8HDFS\u6587\u4ef6\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u521a\u624d\u7684\u64cd\u4f5c\u7ed3\u679c\uff1a</p> <p></p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u518d\u767b\u5f55\u5230hadoop-master\u5bf9\u5e94\u7684Pod\u4e0a\uff0c\u542f\u52a8\u4e00\u4e2aMap-Reduce\u6d4b\u8bd5\u4f5c\u4e1a\u2014\u2014wordcount\uff0c\u4f5c\u4e1a\u542f\u52a8\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5728Yarn\u7684\u7ba1\u7406\u754c\u9762\u4e2d\u770b\u5230\u4f5c\u4e1a\u7684\u6267\u884c\u4fe1\u606f\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u5f53\u4f5c\u4e1a\u6267\u884c\u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7\u754c\u9762\u770b\u5230\u8be6\u7ec6\u7684\u7edf\u8ba1\u4fe1\u606f\uff0c\u6bd4\u5982wordcount\u7684\u6267\u884c\u7ed3\u679c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u6700\u540e\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u88f8\u673a\u7248Hadoop\u96c6\u7fa4\u4e0eKubernetes\u4e4b\u4e0a\u7684Hadoop\u96c6\u7fa4\u7684\u6027\u80fd\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u73af\u5883\u4e3a\u5341\u53f0\u670d\u52a1\u5668\u7ec4\u6210\u7684\u96c6\u7fa4\uff0c\u5177\u4f53\u53c2\u6570\u5982\u4e0b\uff1a</p> <p>\u786c\u4ef6\uff1a</p> <ul> <li>CPU\uff1a<code>2*E5-2640v3-8Core</code></li> <li>\u5185\u5b58\uff1a<code>16*16G DDR4</code></li> <li>\u7f51\u5361\uff1a2*10GE\u591a\u6a21\u5149\u53e3</li> <li>\u786c\u76d8\uff1a12*3T SATA</li> </ul> <p>\u8f6f\u4ef6\uff1a</p> <ul> <li>BigCloud Enterprise Linux 7\uff08GNU/Linux 3.10.0-514.el7.x86_64 x86_64\uff09</li> <li>Hadoop2.7.2</li> <li>Kubernetes 1.7.4+ Calico V3.0.1</li> </ul> <p>\u6211\u4eec\u6267\u884c\u4e86\u4ee5\u4e0b\u8fd9\u4e9b\u6807\u51c6\u6d4b\u8bd5\u9879\uff1a</p> <ul> <li>TestDFSIO\uff1a\u5206\u5e03\u5f0f\u7cfb\u7edf\u8bfb\u5199\u6d4b\u8bd5</li> <li>NNBench\uff1aNameNode\u6d4b\u8bd5</li> <li>MRBench\uff1aMapReduce\u6d4b\u8bd5</li> <li>WordCount\uff1a\u5355\u8bcd\u9891\u7387\u7edf\u8ba1\u4efb\u52a1\u6d4b\u8bd5</li> <li>TeraSort\uff1aTeraSort\u4efb\u52a1\u6d4b\u8bd5</li> </ul> <p>\u7efc\u5408\u6d4b\u8bd5\u4e0b\u6765\uff0cHadoop\u8dd1\u5728Kuberntes\u96c6\u7fa4\u4e0a\u65f6\uff0c\u6027\u80fd\u6709\u6240\u4e0b\u964d\uff0c\u4ee5TestDFSIO\u7684\u6d4b\u8bd5\u4e3a\u4f8b\uff0c\u4e0b\u9762\u662fHadoop\u96c6\u7fa4\u6587\u4ef6\u8bfb\u53d6\u7684\u6027\u80fd\u6d4b\u8bd5\u5bf9\u6bd4\uff1a</p> <p></p> <p>\u6211\u4eec\u770b\u5230\uff0cKubernetes\u96c6\u7fa4\u4e0a\u7684\u6587\u4ef6\u8bfb\u6027\u80fd\u4e0e\u7269\u7406\u673a\u76f8\u6bd4\uff0c\u4e0b\u964d\u4e86\u5dee\u4e0d\u591a30%\u5de6\u53f3\uff0c\u5e76\u4e14\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u4e5f\u589e\u52a0\u4e0d\u5c11\uff0c\u518d\u6765\u5bf9\u6bd4\u6587\u4ef6\u5199\u5165\u7684\u6027\u80fd\uff0c\u6d4b\u8bd5\u7ed3\u679c\u5982\u4e0b\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u6211\u4eec\u770b\u5230\uff0c\u5199\u6587\u4ef6\u6027\u80fd\u7684\u5dee\u8ddd\u5e76\u4e0d\u5927\uff0c\u8fd9\u91cc\u7684\u4e3b\u8981\u539f\u56e0\u662f\u5728\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\uff0cHDFS\u5199\u78c1\u76d8\u7684\u901f\u5ea6\u8fdc\u8fdc\u4f4e\u4e8e\u8bfb\u78c1\u76d8\u7684\u901f\u5ea6\uff0c\u56e0\u6b64\u65e0\u6cd5\u62c9\u5f00\u5dee\u8ddd\u3002</p> <p>\u4e4b\u6240\u4ee5\u90e8\u7f72\u5728Kuberntes\u4e0a\u7684Hadoop\u96c6\u7fa4\u7684\u6027\u80fd\u4f1a\u6709\u6240\u4e0b\u964d\uff0c\u4e3b\u8981\u4e00\u4e2a\u539f\u56e0\u662f\u5bb9\u5668\u865a\u62df\u7f51\u7edc\u6240\u5e26\u6765\u7684\u6027\u80fd\u635f\u8017\uff0c\u5982\u679c\u7528Host Only\u6a21\u578b\uff0c\u5219\u4e24\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\u4f1a\u8fdb\u4e00\u6b65\u7f29\u5c0f\uff0c\u4e0b\u56fe\u662fTestDFSIO\u6d4b\u8bd5\u4e2dHadoop\u96c6\u7fa4\u6587\u4ef6\u8bfb\u53d6\u7684\u6027\u80fd\u6d4b\u8bd5\u5bf9\u6bd4\uff1a</p> <p></p> <p>\u56e0\u6b64\u6211\u4eec\u5efa\u8bae\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u91c7\u7528Host Only\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u4ee5\u63d0\u5347Hadoop\u7684\u96c6\u7fa4\u6027\u80fd\u3002</p> <p>\u653b\u4e0bHadoop\u5728Kubernetes\u4e0a\u7684\u90e8\u7f72\uff0c\u5e76\u4e14\u5728\u751f\u4ea7\u4e2d\u52a0\u4ee5\u9a8c\u8bc1\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u81ea\u8c6a\u7684\u8bf4\uff0c\u73b0\u5728\u6ca1\u6709\u4ec0\u4e48\u80fd\u591f\u96be\u5012\u5e94\u7528\u5411Kubernetes\u7684\u8fc1\u79fb\u7684\u6b65\u4f10\uff0c\u91c7\u7528\u7edf\u4e00\u7684PaaS\u6784\u5efa\u4f01\u4e1a\u7684\u5e94\u7528\u96c6\u7fa4\u548c\u5927\u6570\u636e\u96c6\u7fa4\uff0c\u5b9e\u73b0\u8d44\u6e90\u7684\u5171\u4eab\u548c\u670d\u52a1\u7684\u7edf\u4e00\u7ba1\u7406\u5c06\u4f1a\u5927\u5927\u7684\u63d0\u5347\u4f01\u4e1a\u7684\u4e1a\u52a1\u90e8\u7f72\u901f\u5ea6\u548c\u7ba1\u7406\u7684\u6548\u7387\u3002</p>"},{"location":"chap11/chap11_4bigdata_hdfs/#5hdfs","title":"5\u3001HDFS \u7b80\u5355\u4f7f\u7528","text":"<p>\u9664\u4e86\u8fd9\u4e9b\u547d\u4ee4\uff0cHDFS \u7684\u64cd\u4f5c\u8fd8\u6709\uff1a</p> <ul> <li>\u663e\u793a\u6587\u4ef6\u5185\u5bb9\u7684 cat \u547d\u4ee4\uff1b</li> <li>\u4e0a\u4f20\u6587\u4ef6\u7684 put \u547d\u4ee4\uff1b</li> <li>\u4e0b\u8f7d\u6587\u4ef6\u7684 get \u547d\u4ee4\uff1b</li> <li>\u79fb\u52a8\u6587\u4ef6\u7684 mv \u547d\u4ee4\uff1b</li> <li>\u5220\u9664\u6587\u4ef6\u7684 rm \u547d\u4ee4\uff1b</li> <li>\u2026\u2026</li> </ul>"},{"location":"chap11/chap11_5bigdata_hive_hbase/","title":"\u7b2c\u4e94\u8282 HBase \u548c Hive","text":"<p>\u5728\u65e5\u5e38\u5de5\u4f5c\u4e2d\u7ecf\u5e38\u7528\u7684\u800c\u4e14\u4e0e HDFS \u6709\u7d27\u5bc6\u8054\u7cfb\u7684\u4e24\u4e2a\u5de5\u5177 Hive \u548c HBase\u3002</p> <p>\u5728 Hadoop \u7cfb\u7edf\u4e2d\uff0c\u8d1f\u8d23\u8ba1\u7b97\u7684\u90e8\u5206\u662f MapReduce\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u4eec\u8981\u5904\u7406 HDFS \u4e2d\u5b58\u50a8\u7684\u6570\u636e\uff0c\u8fdb\u884c\u5404\u79cd\u7edf\u8ba1\u5206\u6790\u4ee5\u53ca\u8fd0\u7b97\u7684\u8bdd\u9700\u8981\u53bb\u5f00\u53d1\u4e00\u4e2a MapReduce \u7a0b\u5e8f\u3002</p> <p>\u867d\u7136\u8bf4 MapReduce \u5df2\u7ecf\u5bf9\u5206\u5e03\u5f0f\u8ba1\u7b97\u8fdb\u884c\u4e86\u5f88\u597d\u7684\u5c01\u88c5\uff0c \u4f46\u662f\u4f7f\u7528\u5176 API \u8fdb\u884c\u5f00\u53d1\u5bf9\u4e8e\u5f88\u591a\u4eba\u6765\u8bf4\u4ecd\u7136\u662f\u4e00\u4ef6\u5f88\u56f0\u96be\u7684\u4e8b\u60c5\u3002</p> <p>\u6bd4\u5982\u8bf4\u5f88\u591a\u7684\u6570\u636e\u4ea7\u54c1\u7ecf\u7406\u6216\u8005\u8fd0\u8425\u4eba\u5458\u53ea\u662f\u60f3\u7edf\u8ba1\u4e00\u4e0b\u6570\u5b57\uff0c\u5374\u8981\u53bb\u5b66\u4e60\u5982\u4f55\u5199\u4ee3\u7801\u5f00\u53d1\u7684\u4e00\u5957\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u96be\u5ea6\u53ef\u60f3\u800c\u77e5\uff0c\u56e0\u6b64 Hive \u4fbf\u5e94\u8fd0\u800c\u751f\u3002Hive \u4f1a\u89e3\u6790 SQL \u8bed\u53e5\u7136\u540e\u8f6c\u5316\u6210 MapReduce \u7684\u7a0b\u5e8f\u8fd0\u884c\uff0c\u53ea\u662f\u5b66\u4e60 SQL \u8bed\u53e5\u5bf9\u4e8e\u4e00\u4e2a\u4ea7\u54c1\u7ecf\u7406\u6765\u8bf4\u5c31\u8981\u7b80\u5355\u5f97\u591a\u4e86\u3002</p> <p>\u7b80\u5355\u6765\u8bf4\uff0cHive \u5c31\u662f\u4e00\u4e2a\u6570\u636e\u4ed3\u5e93\uff0c\u4ed3\u5e93\u4e2d\u7684\u6570\u636e\u90fd\u662f\u5728 HDFS\u4e2d\u7ba1\u7406\u7684\u6570\u636e\u6587\u4ef6\uff0c\u540c\u65f6 Hive \u652f\u6301\u7c7b\u4f3c SQL \u8bed\u53e5\u7684\u529f\u80fd\uff0c</p> <p>\u4f60\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e9b\u8bed\u53e5\u6765\u8fdb\u884c\u6570\u636e\u5206\u6790\uff0cHive \u4f1a\u628a\u8fd9\u4e9b\u8bed\u53e5\u8f6c\u6362\u6210\u53ef\u6267\u884c\u7684 MapReduce \u4ee3\u7801\uff0c\u7136\u540e\u8fdb\u884c\u8ba1\u7b97\u3002\u8fd9\u91cc\u7684\u8ba1\u7b97\uff0c\u4ec5\u9650\u4e8e\u67e5\u627e\u548c\u5206\u6790\u3002</p> <p>Hive \u6240\u5904\u7406\u7684\u662f\u5df2\u7ecf\u5b58\u50a8\u8d77\u6765\u7684\u6570\u636e\uff0c\u8fd9\u79cd\u8ba1\u7b97\u4e5f\u5c31\u662f\u6211\u4eec\u6240\u8bf4\u7684\u79bb\u7ebf\u8ba1\u7b97\uff08\u533a\u522b\u4e8e\u5b9e\u65f6\u8ba1\u7b97\uff09\u3002\u901a\u8fc7 Hive \u7684\u64cd\u4f5c\uff0c\u53ef\u4ee5\u8ba9\u4f60\u5728\u64cd\u4f5c\u6570\u636e\u65f6\u611f\u89c9\u662f\u5728\u4f7f\u7528 MySQL\uff0c\u4ece\u800c\u51cf\u5c11\u4f60\u7684\u5b66\u4e60\u6210\u672c\u3002</p> <p>Hive \u7684\u57fa\u672c\u4f53\u7cfb\u67b6\u6784\u3002\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1hive","title":"1\u3001Hive\u7684\u4f53\u7cfb\u67b6\u6784","text":"<p>\u5206\u6210\u4e24\u5927\u90e8\u5206\uff0c\u5de6\u4fa7\u662f Hive \u7684\u4e3b\u4f53\uff0c\u53f3\u4fa7\u662fHadoop \u7cfb\u7edf</p> <p>\u53f3\u4e0a\u662f MapReduce\uff0c\u53f3\u4e0b\u662f HDFS\uff0c\u4e2d\u95f4\u6709\u51e0\u6761\u7ebf\u8fde\u63a5\uff0c\u8bf4\u660e\u4e86 Hive \u4e0e Hadoop \u4e24\u5927\u6838\u5fc3\u7684\u5173\u7cfb</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1-1-ui","title":"1-1 UI","text":"<p>\u7528\u6237\u754c\u9762\uff0c\u4e3b\u8981\u8d1f\u8d23\u4e0e\u4f7f\u7528\u8005\u7684\u4ea4\u4e92\uff0c\u6211\u4eec\u901a\u8fc7 UI \u5411\u7cfb\u7edf\u63d0\u4ea4\u67e5\u8be2\u548c\u5176\u4ed6\u64cd\u4f5c\u3002</p> <p>\u5f53\u7136\uff0c\u5728 Hive \u4e2d\u8fd8\u5c01\u88c5\u4e86 ThriftServer\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u5f00\u53d1\u4e2d\u4f7f\u7528 Java\u3001 Python \u6216\u8005 C++ \u7b49\u8bed\u8a00\u6765\u8bbf\u95ee Server\uff0c\u4ece\u800c\u8c03\u7528 Hive\u3002</p> <p></p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1-2-driver","title":"1-2 \u9a71\u52a8\u5668\uff08Driver\uff09","text":"<ul> <li>\u9a71\u52a8\u5668\u5728\u63a5\u6536 HiveQL \u8bed\u53e5\u4e4b\u540e\uff0c</li> <li>\u521b\u5efa\u4f1a\u8bdd\u6765\u542f\u52a8\u8bed\u53e5\u7684\u6267\u884c\uff0c\u5e76\u76d1\u63a7\u6267\u884c\u7684\u751f\u547d\u5468\u671f\u548c\u8fdb\u5ea6\u3002</li> <li>\u5728\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230\uff0c\u9a71\u52a8\u5668\u65e2\u8d1f\u8d23\u4e0e\u7f16\u8bd1\u5668\u7684\u4ea4\u4e92\uff0c\u53c8\u8d1f\u8d23\u4e0e\u6267\u884c\u5f15\u64ce\u7684\u4ea4\u4e92\u3002</li> </ul>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1-3-compiler","title":"1-3 \u7f16\u8bd1\u5668\uff08Compiler\uff09","text":"<ul> <li>\u7f16\u8bd1\u5668\u63a5\u6536\u9a71\u52a8\u5668\u4f20\u6765\u7684 HiveQL\uff0c</li> <li>\u5e76\u4ece\u5143\u6570\u636e\u4ed3\u4e2d\u83b7\u53d6\u6240\u9700\u8981\u7684\u5143\u6570\u636e\uff0c</li> <li>\u7136\u540e\u5bf9 HiveQL \u8bed\u53e5\u8fdb\u884c\u7f16\u8bd1\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u8ba1\u5212\uff0c</li> </ul> <p>\u6309\u7167\u4e0d\u540c\u7684\u6267\u884c\u6b65\u9aa4\u62c6\u5206\u6210 MapReduce \u548c HDFS \u7684\u5404\u4e2a\u9636\u6bb5\u7684\u64cd\u4f5c\u5e76\u53d1\u9001\u7ed9\u9a71\u52a8\u5668\u3002</p> <p></p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1-4-execution-engine","title":"1-4 \u6267\u884c\u5f15\u64ce\uff08Execution Engine\uff09","text":"<p>\u5728\u7f16\u8bd1\u548c\u4f18\u5316\u4e4b\u540e\uff0c\u6267\u884c\u5668\u5c06\u6267\u884c\u4efb\u52a1\u3002\u5b83\u5bf9 Hadoop \u7684\u4f5c\u4e1a\u8fdb\u884c\u8ddf\u8e2a\u548c\u4ea4\u4e92\uff0c\u8c03\u5ea6\u9700\u8981\u8fd0\u884c\u7684\u4efb\u52a1\u3002</p> <p></p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#1-5-metastore","title":"1-5 \u6570\u636e\u4ed3\uff08Metastore\uff09","text":"<p>\u5143\u6570\u636e\u6307\u7684\u662f\u6211\u4eec\u6784\u5efa\u7684 Hive \u8868\u7684\u8868\u540d\u3001\u8868\u5b57\u6bb5\u3001\u8868\u7ed3\u6784\u3001\u5206\u533a\u3001\u7c7b\u578b\u3001\u5b58\u50a8\u8def\u5f84\u7b49\u7b49\uff0c\u5143\u6570\u636e\u901a\u5e38\u5b58\u50a8\u5728\u4f20\u7edf\u7684\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e2d\uff0c\u6bd4\u5982 MySQL\u3002</p> <p></p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#2hive","title":"2\u3001Hive\u7684\u4f18\u70b9","text":""},{"location":"chap11/chap11_5bigdata_hive_hbase/#2-1","title":"2-1 \u7b80\u5355\u6613\u4e0a\u624b","text":"<p>\u53ea\u9700\u8981\u4e86\u89e3 SQL \u8bed\u8a00\u5c31\u53ef\u4ee5\u4f7f\u7528 Hive\uff0c\u964d\u4f4e\u4e86\u4f7f\u7528 MapReduce \u8fdb\u884c\u6570\u636e\u5206\u6790\u7684\u96be\u5ea6\uff0c\u5f88\u591a\u4e92\u8054\u7f51\u516c\u53f8\u90fd\u4f1a\u4f7f\u7528 Hive \u8fdb\u884c\u65e5\u5fd7\u5206\u6790\uff0c\u6bd4\u5982\u8bf4\u6dd8\u5b9d\u3001\u7f8e\u56e2\u7b49\u7b49\uff0c\u4f7f\u7528 Hive \u7edf\u8ba1\u7f51\u7ad9\u7684 PV\u3001UV \u7b49\u4fe1</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#2-2-hive","title":"2-2 Hive \u63d0\u4f9b\u7edf\u4e00\u7684\u5143\u6570\u636e\u7ba1\u7406","text":"<p>\u901a\u8fc7\u5143\u6570\u636e\u7ba1\u7406\u53ef\u4ee5\u5b9e\u73b0\u63cf\u8ff0\u4fe1\u606f\u7684\u683c\u5f0f\u5316\uff0c\u4f7f\u5f97\u6570\u636e\u53ef\u4ee5\u5171\u4eab\u7ed9 Presto\u3001Impala\u3001SparkSQL \u7b49 SQL \u67e5\u8be2\u5f15\u64ce\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#2-3","title":"2-3 \u53ef\u6269\u5c55\u6027\u597d","text":"<p>\u8ddf Hadoop \u7684\u5176\u4ed6\u7ec4\u4ef6\u4e00\u6837\uff0cHive \u4e5f\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u53ea\u9700\u8981\u6dfb\u52a0\u673a\u5668\u5c31\u53ef\u4ee5\u90e8\u7f72\u5206\u5e03\u5f0f\u7684 Hive \u96c6\u7fa4\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#2-4-udf","title":"2-4 \u652f\u6301\u81ea\u5b9a\u4e49\u51fd\u6570\uff08UDF\uff09","text":"<p>SQL \u7684\u529f\u80fd\u867d\u7136\u975e\u5e38\u591a\uff0c\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e9b\u4e2a\u6027\u5316\u7684\u5b9a\u5236\u65b9\u6848\uff0c\u4f7f\u7528 SQL \u660e\u663e\u8981\u9ebb\u70e6\u5f88\u591a\uff0cHive \u652f\u6301\u4f7f\u7528\u81ea\u5b9a\u4e49\u51fd\u6570\u7684\u65b9\u5f0f\u6765\u52a0\u5165\u81ea\u5df1\u7f16\u5199\u7684\u529f\u80fd\uff0c\u65b9\u4fbf\u4e86\u5f00\u53d1\u4eba\u5458\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#3hive","title":"3\u3001Hive \u4e5f\u662f\u6709\u7f3a\u70b9","text":""},{"location":"chap11/chap11_5bigdata_hive_hbase/#3-1","title":"3-1 \u901f\u5ea6\u8f83\u6162","text":"<ul> <li>\u7531\u4e8e Hive \u7684\u5e95\u5c42\u6570\u636e\u4ecd\u7136\u662f\u5b58\u50a8\u5728 HDFS \u4e0a\u7684\uff0c\u6240\u4ee5\u901f\u5ea6\u6bd4\u8f83\u6162\uff0c\u53ea\u9002\u5408\u79bb\u7ebf\u67e5\u8be2\u3002</li> <li>\u5728\u5199\u7a0b\u5e8f\u65f6\u4e00\u822c\u4e5f\u662f\u4f7f\u7528 Hive \u6765\u4e00\u6b21\u6027\u52a0\u8f7d\u6570\u636e\uff0c\u4e0d\u9002\u5408\u5728\u4ee3\u7801\u4e2d\u53cd\u590d\u8bbf\u95ee\u3002</li> </ul>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#3-2","title":"3-2 \u4e0d\u652f\u6301\u5355\u6761\u6570\u636e\u64cd\u4f5c","text":"<p>\u4e0d\u80fd\u4efb\u610f\u4fee\u6539 HDFS \u91cc\u7684\u6570\u636e\uff0c\u6240\u4ee5 Hive \u4e5f\u4e0d\u884c\uff0c\u8981\u60f3\u4fee\u6539\u6570\u636e\u53ea\u80fd\u6574\u4e2a\u6587\u4ef6\u8fdb\u884c\u66ff\u6362\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#4hbase","title":"4\u3001HBase","text":"<p>\u8ddf Hive \u4e0d\u540c\uff0cHBase \u662f\u4e00\u4e2a\u5728 Hadoop \u5927\u6570\u636e\u4f53\u7cfb\u4e2d\u5e94\u7528\u5f88\u591a\u7684NoSQL \u6570\u636e\u5e93\uff0cHBase \u6e90\u4e8e\u8c37\u6b4c\u53d1\u8868\u7684\u8bba\u6587\uff1aBigtable\u3002</p> <p>HBase \u540c\u6837\u5229\u7528 HDFS \u4f5c\u4e3a\u5e95\u5c42\u5b58\u50a8\uff0c\u4f46\u662f\u5e76\u4e0d\u662f\u7b80\u5355\u5730\u4f7f\u7528\u539f\u672c\u7684\u6570\u636e\uff0c\u53ea\u662f\u4f7f\u7528 HDFS \u4f5c\u4e3a\u5b83\u7684\u5b58\u50a8\u7cfb\u7edf\u3002</p> <ul> <li>\u4e5f\u5c31\u662f\u8bf4\uff0cHBase \u53ea\u662f\u5229\u7528 Hadoop \u7684 HDFS \u5e2e\u52a9\u5176\u7ba1\u7406\u6570\u636e\u7684\u6301\u4e45\u5316\u6587\u4ef6\u3002</li> <li>HBase \u63d0\u4f9b\u5b9e\u65f6\u5904\u7406\u6570\u636e\u7684\u80fd\u529b\uff0c\u5f25\u8865\u4e86\u65e9\u671f Hadoop\u53ea\u80fd\u79bb\u7ebf\u5904\u7406\u6570\u636e\u7684\u4e0d\u8db3</li> </ul> <p></p> <p>\u884c\u952e\uff08Row Key) </p> <p>\u4e00\u884c\u6570\u636e\u7684\u552f\u4e00\u6807\u8bc6</p> <ul> <li>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cHBase\u5728\u5b58\u50a8Row Key\u7684\u65f6\u5019\u662f\u6309\u7167\u5b57\u5178\u987a\u5e8f\u5b58\u653e\u7684 </li> <li>\u9700\u8981\u8bbe\u8ba1\u5b58\u50a8\u7684Row Key\uff0c\u6bd4\u5982\u5728\u6bcf\u4e2a\u65e7\u7684\u524d\u9762\u90fd\u52a0\u4e00\u4e2aHASH\u503c\u6765\u63d0\u5347\u67e5\u8be2\u6027\u80fd </li> </ul> <p>\u5217\u7c07\uff08Column\u00a0Family\uff09</p> <p>\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u7ec4\u5217\uff0c</p> <p>\u5b9e\u9645\u4e0a\u4e00\u4e2a\u5217\u7c07\u7684\u4f5c\u7528\u4e5f\u662f\u7528\u6765\u7ba1\u7406\u82e5\u5e72\u4e2a\u5217\uff0c\u4f18\u5316\u67e5\u8be2\u901f\u5ea6\u3002\u6240\u4ee5\u5217\u7c07\u7684\u540d\u5b57\u8981\u5c3d\u91cf\u77ed\uff0c\u540c\u65f6\u5bf9\u4e8e\u7ecf\u5e38\u9700\u8981\u4e00\u8d77\u67e5\u8be2\u7684\u5217\u653e\u5728\u4e00\u4e2a\u5217\u7c07\u4e0b\u9762</p> <p>HBase\u8868\u4e2d\u7684\u5217\u7c07\u9700\u8981\u9884\u5148\u5b9a\u4e49\uff0c\u800c\u5217\u4e0d\u9700\u8981\uff0c\u5982\u679c\u8981\u65b0\u589e\u5217\u7c07\u5c31\u8981\u5148\u505c\u7528\u8fd9\u4e2a\u8868\u3002</p> <p>\u5355\u5143\uff08Cell\uff09</p> <p>\u6307\u7684\u662f\u4e00\u4e2a\u786e\u5b9a\u7684\u5b58\u50a8\u5355\u5143\u3002\u901a\u8fc7 Row\u00a0Key\u3001\u5217\u7c07 \u3001\u5217\u540d\u4ee5\u53ca\u7248\u672c\u53f7\u6765\u786e\u5b9a\u3002</p> <p>\u65f6\u95f4\u6233\uff08Timestamp\uff09</p> <p>\u7528\u6765\u6807\u8bb0\u524d\u9762\u8bf4\u7684\u4e00\u4efd\u6570\u636e\u7684\u4e0d\u540c\u7248\u672c\u3002</p> <p>\u533a\u57df\uff08Region\uff09</p> <p>\u4e00\u4e2a Region \u53ef\u4ee5\u770b\u4f5c\u662f\u591a\u884c\u6570\u636e\u7684\u96c6\u5408\u3002\u5f53\u4e00\u4e2a\u8868\u7684\u6570\u636e\u9010\u6e10\u589e\u591a\uff0c\u9700\u8981\u8fdb\u884c\u5206\u5e03\u5f0f\u5b58\u50a8\uff0c\u90a3\u4e48\u8fd9\u4e2a\u8868\u5c31\u4f1a\u81ea\u52a8\u5206\u88c2\u6210\u591a\u4e2a Region\uff0c\u7136\u540e\u5206\u914d\u5230\u4e0d\u540c\u7684 RegionServer \u4e0a\u9762\u53bb\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#5hbase","title":"5\u3001HBase \u7684\u4f18\u7f3a\u70b9","text":"<p>HBase \u7684\u4f18\u52bf\u5728\u4e8e\u5b9e\u65f6\u8ba1\u7b97\uff0c\u6240\u6709\u5b9e\u65f6\u6570\u636e\u90fd\u76f4\u63a5\u5b58\u5165 HBase \u4e2d\uff0c\u5ba2\u6237\u7aef\u901a\u8fc7 API \u76f4\u63a5\u8bbf\u95ee HBase\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8ba1\u7b97\u3002</p> <p>\u7531\u4e8e\u5b83\u4f7f\u7528\u7684\u662fNoSQL\uff0c\u6216\u8005\u8bf4\u662f\u5217\u5f0f\u7ed3\u6784\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u67e5\u627e\u6027\u80fd\uff0c\u4f7f\u5176\u80fd\u8fd0\u7528\u4e8e\u5927\u6570\u636e\u573a\u666f\uff0c\u8fd9\u662f\u5b83\u8ddf MapReduce \u7684\u533a\u522b\u3002</p> <p>\u9664\u6b64\u4e4b\u5916\uff0c\u5b83\u8fd8\u6709\u5176\u4ed6\u4f18\u70b9\u3002</p> <ul> <li>\u5bb9\u91cf\u5927\u6027\u80fd\u9ad8\u3002\u4e00\u5f20 HBase \u8868\u53ef\u4ee5\u652f\u6301\u767e\u4ebf\u884c\u3001\u6570\u5343\u5217\u7684\u5b58\u50a8\uff0c\u800c\u67e5\u8be2\u6548\u7387\u4e0d\u4f1a\u6709\u660e\u663e\u7684\u53d8\u5316\u3002\u540c\u65f6 HBase \u8fd8\u53ef\u4ee5\u652f\u6301\u9ad8\u5e76\u53d1\u7684\u8bfb\u5199\u64cd\u4f5c\u3002</li> <li>\u5217\u5b58\u50a8\uff0c\u65e0\u987b\u8bbe\u5b9a\u8868\u7ed3\u6784\u3002\u5bf9\u4e8e\u4f20\u7edf\u6570\u636e\u5e93\uff0c\u6bd4\u5982 MySQL \u662f\u6309\u884c\u6765\u5b58\u50a8\u7684\uff0c\u68c0\u7d22\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e8b\u524d\u5efa\u7acb\u7684\u7d22\u5f15\uff0c\u5728\u6570\u636e\u91cf\u5f88\u5927\u7684\u65f6\u5019\u589e\u52a0\u5217\u6216\u8005\u66f4\u65b0\u7d22\u5f15\u90fd\u662f\u975e\u5e38\u7f13\u6162\u7684\uff0c\u800c HBase \u6bcf\u4e00\u5217\u90fd\u662f\u5355\u72ec\u5b58\u50a8\u7684\uff0c\u6bcf\u4e00\u884c\u6bcf\u4e00\u5217\u7684\u90a3\u4e00\u4e2a\u5355\u5143\u90fd\u662f\u72ec\u7acb\u7684\u5b58\u50a8\uff0c\u4e5f\u5c31\u662f\u6570\u636e\u672c\u8eab\u5373\u662f\u7d22\u5f15\u3002</li> </ul> <p>\u800c HBase \u4e0d\u80fd\u652f\u6301\u6761\u4ef6\u67e5\u8be2\uff0c\u4e5f\u4e0d\u80fd\u7528 SQL \u8bed\u53e5\u8fdb\u884c\u67e5\u8be2\u3002\u5728\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u4e00\u822c\u53ea\u80fd\u4f7f\u7528Row\u00a0Key \u6765\u8fdb\u884c\u67e5\u8be2\u3002</p>"},{"location":"chap11/chap11_5bigdata_hive_hbase/#6hbase-hive","title":"6\u3001HBase \u4e0e Hive \u7684\u4f7f\u7528","text":"<p>\u7531\u4e8e HBase \u652f\u6301\u5b9e\u65f6\u968f\u673a\u67e5\u8be2\u7684\u7279\u6027\uff0c\u4e3b\u8981\u4f7f\u7528 HBase \u8fdb\u884c\u5927\u91cf\u7684\u660e\u7ec6\u6570\u636e\u7684\u968f\u673a\u5b9e\u65f6\u67e5\u8be2\u3002</p> <p>\u6bd4\u5982\u8bf4\u4ee5\u7528\u6237 ID \u4e3a Key \u7684\u7528\u6237\u4fe1\u606f\uff0c\u4ee5 Itemid \u4e3a Key \u7684\u5546\u54c1\u4fe1\u606f\u3001\u5404\u79cd\u4ea4\u6613\u660e\u7ec6\u7b49\u7b49\u3002\u5728\u6570\u636e\u6536\u96c6\u4e0a\u6765\u4e4b\u540e\u901a\u8fc7\u89e3\u6790\u5b9e\u65f6\u6d41\u7136\u540e\u5b58\u50a8\u5230 HBase \u4e2d\uff0c\u4ee5\u5907\u67e5\u8be2\u3002\u800c\u5728\u67e5\u8be2 HBase \u7684\u65f6\u5019\u4e00\u822c\u4e5f\u662f\u5bf9\u6574\u6761\u6570\u636e\u8fdb\u884c\u67e5\u8be2\u3002</p> <p>Hive \u672c\u8eab\u5e76\u4e0d\u89e3\u51b3\u5b58\u50a8\u7684\u95ee\u9898\uff0c\u5b83\u53ea\u662f\u628a HDFS \u4e2d\u7684\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u4e86\u5c55\u793a\uff0c\u800c\u6700\u6838\u5fc3\u7684\u529f\u80fd\u662f\u5b9e\u73b0\u4e86\u5bf9\u8fd9\u4e9b\u7ed3\u6784\u5316\u6587\u4ef6\u7684\u67e5\u8be2\u3002</p> <p>\u5728\u65e5\u5e38\u7684\u5de5\u4f5c\u4e2d\uff0c\u901a\u5e38\u4f7f\u7528 Hive\u5206\u533a\u8868\u6765\u8bb0\u5f55\u4e00\u4e2a\u65f6\u95f4\u6bb5\u5185\u7684\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u79bb\u7ebf\u7684\u6279\u91cf\u6570\u636e\u8ba1\u7b97\uff0c\u6bd4\u5982\u7edf\u8ba1\u5206\u6790\u5404\u79cd\u6570\u636e\u6307\u6807\u3002</p> <p>\u540c\u4e3a Hadoop \u4f53\u7cfb\u7684\u91cd\u8981\u5de5\u5177\uff0cHive \u4e0e HBase \u4e5f\u63d0\u4f9b\u4e86\u4e00\u4e9b\u8bbf\u95ee\u673a\u5236\u3002</p> <p>\u6709\u65f6\u5019\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u5728 Hive \u4e2d\u67e5\u8be2 HBase \u7684\u6570\u636e\uff0c\u53ef\u4ee5\u901a\u8fc7\u5173\u8054\u5916\u8868\u7684\u5f62\u5f0f\uff0c\u5728 Hive \u4e0a\u521b\u5efa\u4e00\u4e2a\u6307\u5411\u5bf9\u5e94Hbase \u8868\u7684\u5916\u90e8\u8868\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/","title":"\u7b2c\u516d\u8282 \u6d88\u606f\u7cfb\u7edf Kafka\u4e0eFlume","text":""},{"location":"chap11/chap11_6bigdtat_kafka_flume/#1-kafka","title":"1\u3001\u4ec0\u4e48\u662f Kafka","text":"<p>\u5728\u5927\u6570\u636e\u7684\u67b6\u6784\u4e2d\uff0c\u6570\u636e\u7684\u91c7\u96c6\u548c\u4f20\u8f93\u662f\u4e00\u4e2a\u975e\u5e38\u91cd\u8981\u7684\u73af\u8282\uff0c</p> <p>\u5982\u4f55\u4fdd\u969c\u5982\u6b64\u5927\u6279\u91cf\u7684\u6570\u636e\u80fd\u591f\u4e0d\u91cd\u4e0d\u6f0f\u7684\u4f20\u8f93\uff0c</p> <ul> <li>\u5f53\u53d1\u751f\u6545\u969c\u65f6\u5982\u4f55\u4fdd\u969c\u6570\u636e\u7684\u6709\u6548\u6027\uff0c</li> <li>\u5f53\u7f51\u7edc\u5835\u585e\u65f6\u5982\u4f55\u8fdb\u884c\u7f13\u5b58\uff0c\u8fd9\u9700\u8981\u76f8\u5e94\u7684\u57fa\u7840\u8bbe\u65bd\u5bf9\u5176\u63d0\u4f9b\u652f\u6301</li> </ul> <p>Kafka \u4e5f\u662f\u4e00\u4e2a\u6d88\u606f\u7cfb\u7edf\u3002\u6240\u8c13\u7684\u6d88\u606f\u7cfb\u7edf\u5176\u5b9e\u5f88\u7b80\u5355\uff0c\u5c31\u662f\u628a\u6570\u636e\u4ece\u4e00\u4e2a\u5730\u65b9\u53d1\u5f80\u53e6\u5916\u4e00\u4e2a\u5730\u65b9\u7684\u5de5\u5177</p> <p>Kafka \u4e5f\u6709\u5176\u81ea\u5df1\u7684\u7279\u8272\uff0c\u5b83\u662f\u4e00\u4e2a\u9ad8\u541e\u5410\u91cf\u3001\u5206\u5e03\u5f0f\u7684\u53d1\u5e03 / \u8ba2\u9605\u6d88\u606f\u7cfb\u7edf\uff0c\u7136\u800c\u6700\u6838\u5fc3\u7684\u662f\u201c\u524a\u5cf0\u586b\u8c37\u201d</p> <ul> <li>Kafka \u652f\u6301\u591a\u79cd\u5f00\u53d1\u8bed\u8a00\uff0c\u6bd4\u5982 Java\u3001C/C++\u3001Python\u3001Go\u3001Erlang\u3001Node.js \u7b49\u3002\u73b0\u5728\u5f88\u591a\u4e3b\u6d41\u7684\u5206\u5e03\u5f0f\u5904\u7406\u7cfb\u7edf\u90fd\u652f\u6301\u4e0e Kafka \u7684\u96c6\u6210\uff0c\u6bd4\u5982 Spark\u3001Flink \u7b49\u3002</li> <li>\u540c\u65f6\uff0cKafka \u4e5f\u662f\u57fa\u4e8e ZooKeeper \u534f\u8c03\u7ba1\u7406\u7684\u7cfb\u7edf\uff0c</li> </ul>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2kafka","title":"2\u3001Kafka \u7684\u7ed3\u6784\u4e0e\u6982\u5ff5","text":"<p>\u5728 Kafka \u7684\u57fa\u672c\u7ed3\u6784\u4e2d\uff0c\u6709\u4e24\u4e2a\u91cd\u8981\u7684\u53c2\u4e0e\u8005\uff1a</p> <ul> <li>\u6d88\u606f\u7684\u751f\u4ea7\u8005\uff08Producer\uff09\uff1b</li> <li>\u6d88\u606f\u7684\u6d88\u8d39\u8005\uff08Consumer\uff09\u3002</li> </ul> <p></p> <p>\u5982\u4e0b\u56fe\u6240\u793a\uff0cKafka \u96c6\u7fa4\u5728\u6d88\u606f\u7684\u751f\u4ea7\u8005\u548c\u6d88\u8d39\u8005\u4e4b\u95f4\u5efa\u7acb\u8d77\u4e86\u8054\u7cfb\u7684\u673a\u5236\uff0c\u6765\u4fdd\u969c\u6d88\u606f\u7684\u8fd0\u8f93\u3002</p> <ul> <li>\u751f\u4ea7\u8005\u8d1f\u8d23\u751f\u4ea7\u6d88\u606f\uff0c\u5c06\u6d88\u606f\u5199\u5165 Kafka \u96c6\u7fa4\uff0c</li> <li>\u800c\u6d88\u8d39\u8005\u4ece Kafka \u96c6\u7fa4\u4e2d\u62c9\u53d6\u6d88\u606f\uff0c\u4e5f\u53ef\u4ee5\u79f0\u4e3a\u6d88\u8d39\u6d88\u606f\u3002</li> </ul> <p>Kafka \u6240\u8981\u89e3\u51b3\u7684\u5c31\u662f\u5982\u4f55\u6765\u5b58\u50a8\u8fd9\u4e9b\u6d88\u606f\uff0c\u5982\u4f55\u8fdb\u884c\u96c6\u7fa4\u8c03\u5ea6\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\uff0c\u5982\u4f55\u4fdd\u969c\u901a\u4fe1\u7b49\u7b49\u95ee\u9898\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2-1","title":"2-1  \u751f\u4ea7\u8005\u4e0e\u6d88\u8d39\u8005","text":"<ul> <li>\u751f\u4ea7\u8005\u8d1f\u8d23\u5c06\u6d88\u606f\u53d1\u9001\u7ed9 Kafka\uff0c\u5b83\u53ef\u4ee5\u662f App\uff0c\u53ef\u4ee5\u662f\u670d\u52a1\uff0c\u4e5f\u53ef\u4ee5\u662f\u5404\u79cd SDK\u3002</li> <li> <p>\u6d88\u8d39\u8005\u5219\u4f7f\u7528\u62c9\u53d6\u7684\u65b9\u5f0f\u4ece Kafka \u4e2d\u83b7\u53d6\u6570\u636e\u3002</p> </li> <li> <p>\u6bcf\u4e00\u4e2a\u6d88\u8d39\u8005\u90fd\u5c5e\u4e8e\u4e00\u4e2a\u7279\u5b9a\u7684\u5c0f\u7ec4\uff08Group\uff09</p> </li> <li>\u540c\u4e00\u4e2a\u4e3b\u9898\uff08Topic\uff09\u7684\u4e00\u6761\u6d88\u606f\u53ea\u80fd\u88ab\u540c\u4e00\u4e2a\u6d88\u8d39\u7ec4\u4e0b\u67d0\u4e00\u4e2a\u6d88\u8d39\u8005\u6d88\u8d39\uff0c</li> <li>\u4f46\u4e0d\u540c\u6d88\u8d39\u7ec4\u7684\u6d88\u8d39\u8005\u53ef\u540c\u65f6\u6d88\u8d39\u8be5\u6d88\u606f\u3002</li> </ul> <p>\u4f9d\u8d56\u8fd9\u4e2a\u6d88\u8d39\u5c0f\u7ec4\u7684\u7406\u5ff5\uff0c\u53ef\u4ee5\u5bf9 Kafka \u4e2d\u7684\u6d88\u606f\u8fdb\u884c\u63a7\u5236\uff0c\u5982\u679c\u9700\u8981\u5bf9\u6d88\u606f\u8fdb\u884c\u591a\u4e2a\u6d88\u8d39\u8005\u91cd\u590d\u6d88\u8d39\uff0c\u90a3\u4e48\u5c31\u914d\u7f6e\u6210\u591a\u4e2a\u6d88\u8d39\u7ec4\uff0c</p> <p>\u800c\u5982\u679c\u5e0c\u671b\u591a\u4e2a\u6d88\u8d39\u8005\u5171\u540c\u5904\u7406\u4e00\u4e2a\u6d88\u606f\u6e90\uff0c\u90a3\u4e48\u5c31\u628a\u8fd9\u4e9b\u6d88\u8d39\u8005\u914d\u7f6e\u5728\u4e00\u4e2a\u6d88\u8d39\u7ec4\u5c31\u53ef\u4ee5\u4e86</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2-2","title":"2-2 \u6d88\u606f","text":"<p>\u6d88\u606f\u5c31\u662f Kafka \u4e2d\u4f20\u8f93\u7684\u6700\u57fa\u672c\u7684\u5355\u4f4d\uff0c\u9664\u53bb\u6211\u4eec\u9700\u8981\u4f20\u8f93\u7684\u6570\u636e\uff0cKafka \u8fd8\u4f1a\u7ed9\u6bcf\u6761\u6d88\u606f\u589e\u52a0\u4e00\u4e2a\u5934\u90e8\u4fe1\u606f\u4ee5\u5bf9\u6bcf\u4e00\u6761\u6d88\u606f\u8fdb\u884c\u6807\u8bb0\uff0c\u65b9\u4fbf\u5728 Kafka \u4e2d\u7684\u5904\u7406\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2-3-topic","title":"2-3 \u4e3b\u9898\uff08Topic\uff09","text":"<p>\u5728 Kafka \u4e2d\uff0c\u4e00\u4e2a\u4e3b\u9898\u5176\u5b9e\u5c31\u662f\u4e00\u7ec4\u6d88\u606f\u3002\u5728\u914d\u7f6e\u7684\u65f6\u5019\u4e00\u65e6\u786e\u5b9a\u4e3b\u9898\u540d\u79f0\uff0c\u751f\u4ea7\u8005\u5c31\u53ef\u4ee5\u628a\u6d88\u606f\u53d1\u9001\u5230\u67d0\u4e2a\u4e3b\u9898\u4e2d\uff0c\u6d88\u8d39\u8005\u8ba2\u9605\u8fd9\u4e2a\u4e3b\u9898\uff0c\u4e00\u65e6\u4e3b\u9898\u4e2d\u6709\u6570\u636e\u5c31\u53ef\u4ee5\u8fdb\u884c\u6d88\u8d39\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2-4-partition","title":"2-4 \u5206\u533a\uff08Partition\uff09\u548c\u526f\u672c","text":"<p>\u5728 Kafka \u4e2d\uff0c\u6bcf\u4e2a\u4e3b\u9898\u4f1a\u88ab\u5206\u6210\u82e5\u5e72\u4e2a\u5206\u533a\u3002</p> <p>\u6bcf\u4e2a\u5206\u533a\u662f\u4e00\u4e2a\u6709\u5e8f\u7684\u961f\u5217\uff0c\u662f\u5728\u7269\u7406\u4e0a\u8fdb\u884c\u5b58\u50a8\u7684\u4e00\u7ec4\u6d88\u606f\uff0c\u800c\u4e00\u4e2a\u5206\u533a\u4f1a\u6709\u82e5\u5e72\u4e2a\u526f\u672c\u4fdd\u969c\u6570\u636e\u7684\u53ef\u7528\u6027\u3002</p> <p>\u4ece\u7406\u8bba\u4e0a\u6765\u8bf4\uff0c\u5206\u533a\u6570\u8d8a\u591a\u7cfb\u7edf\u7684\u541e\u5410\u91cf\u8d8a\u9ad8\uff0c\u4f46\u662f\u8fd9\u9700\u8981\u6839\u636e\u96c6\u7fa4\u7684\u5b9e\u9645\u60c5\u51b5\u8fdb\u884c\u914d\u7f6e\uff0c\u770b\u670d\u52a1\u5668\u662f\u5426\u80fd\u591f\u652f\u6491\u3002</p> <p>\u4e0e\u6b64\u540c\u65f6\uff0cKafka \u5bf9\u6d88\u606f\u7684\u7f13\u5b58\u4e5f\u53d7\u5230\u5206\u533a\u548c\u526f\u672c\u6570\u91cf\u7684\u9650\u5236\u3002\u5728 Kafka \u7684\u7f13\u5b58\u7b56\u7565\u4e0a\uff0c\u4e00\u822c\u662f\u6309\u65f6\u957f\u8fdb\u884c\u7f13\u5b58\uff0c\u6bd4\u5982\u8bf4\u5b58\u50a8\u4e00\u4e2a\u661f\u671f\u7684\u6570\u636e\uff0c\u6216\u8005\u6309\u5206\u533a\u7684\u5927\u5c0f\u8fdb\u884c\u7f13\u5b58\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#2-5","title":"2-5 \u504f\u79fb\u91cf","text":"<p>\u504f\u79fb\u91cf\u662f\u4e00\u79cd\u6d88\u606f\u7684\u7d22\u5f15\u3002</p> <p>\u56e0\u4e3a Kafka \u662f\u4e00\u4e2a\u6d88\u606f\u961f\u5217\u7684\u670d\u52a1\uff0c\u6211\u4eec\u4e0d\u80fd\u5bf9\u6570\u636e\u8fdb\u884c\u968f\u673a\u8bfb\u5199\uff0c\u800c\u662f\u8981\u6309\u7167\u987a\u5e8f\u8fdb\u884c\uff0c\u6240\u4ee5\u9700\u8981\u7ed9\u6bcf\u6761\u6d88\u606f\u90fd\u5206\u914d\u4e00\u4e2a\u6309\u987a\u5e8f\u9012\u589e\u7684\u504f\u79fb\u91cf\u3002\u8fd9\u6837\u6d88\u8d39\u8005\u5728\u6d88\u8d39\u6570\u636e\u7684\u65f6\u5019\u5c31\u53ef\u4ee5\u901a\u8fc7\u5236\u5b9a\u504f\u79fb\u91cf\u6765\u9009\u62e9\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\u7684\u4f4d\u7f6e</p> <p></p> <p>\u5927\u81f4\u7684\u6d41\u7a0b\u4e3a\uff0c\u751f\u4ea7\u8005\u751f\u4ea7\u6570\u636e\uff0c\u7136\u540e\u628a\u6570\u636e\u63a8\u9001\u5230 Kafka \u96c6\u7fa4\u4e2d\uff0c\u5e76\u786e\u5b9a\u6570\u636e\u6d41\u7684\u4e3b\u9898\u3002</p> <p>Kafka \u96c6\u7fa4\u914d\u5408 ZooKeeper \u96c6\u7fa4\u5b8c\u6210\u8c03\u5ea6\u3001\u8d1f\u8f7d\u5747\u8861\u3001\u7f13\u5b58\u7b49\u7b49\u529f\u80fd\uff0c\u7b49\u5f85\u6d88\u8d39\u8005\u6d88\u8d39\u6570\u636e\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3kafka","title":"3\u3001Kafka \u7684\u7279\u70b9","text":"<p>\u7ecf\u8fc7\u4e0d\u65ad\u53d1\u5c55\uff0cKafka \u5df2\u7ecf\u6210\u4e3a\u4e3b\u6d41\u7684\u6d88\u606f\u961f\u5217\u5de5\u5177\uff0c\u7c7b\u4f3c\u7684\u5de5\u5177\u8fd8\u6709 RabbitMQ\u3001Redis \u6d88\u606f\u961f\u5217\u3001ZeroMQ\u3001RocketMQ \u7b49\u7b49\u3002</p> <p>Kafka \u6700\u5927\u7684\u7279\u8272\u5c31\u662f\u201c\u524a\u5cf0\u586b\u8c37\u201d\uff0c\u8fd9\u662f\u5b83\u5728\u5e94\u7528\u4e0a\u7684\u7279\u70b9\uff0c\u8fd9\u91cc\u7684\u8c37\u548c\u5cf0\u6307\u7684\u662f\u6570\u636e\u6d41\u91cf\u7684\u8c37\u548c\u5cf0\uff0c\u524a\u5cf0\u586b\u8c37\u7684\u542b\u4e49\u5373\u5728\u6570\u636e\u751f\u4ea7\u65b9 A \u548c\u6570\u636e\u6d88\u8d39\u65b9 B \u5bf9\u6570\u636e\u6d41\u91cf\u7684\u5904\u7406\u80fd\u529b\u4e0d\u540c\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u4f7f\u7528 Kafka \u4f5c\u4e3a\u4e2d\u95f4\u4f20\u8f93\u7684\u7ba1\u9053\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3-1","title":"3-1 \u6d88\u606f\u6301\u4e45\u5316","text":"<p>Kafka \u9009\u62e9\u4ee5\u6587\u4ef6\u7cfb\u7edf\u6765\u5b58\u50a8\u6570\u636e\u3002</p> <p>\u800c Kafka \u4f1a\u628a\u6570\u636e\u5b58\u5728\u78c1\u76d8\u4e0a</p> <ul> <li>\u78c1\u76d8\u7684\u5b58\u50a8\u5bb9\u91cf\u5927</li> <li>\u7ecf\u8fc7\u6301\u4e45\u5316\u7684\u6570\u636e\u53ef\u4ee5\u652f\u6301\u66f4\u591a\u7684\u5e94\u7528</li> </ul>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3-2","title":"3-2 \u5904\u7406\u901f\u5ea6\u5feb","text":"<p>\u786c\u76d8\u662f\u4f7f\u7528\u7269\u7406\u78c1\u5934\u6765\u8fdb\u884c\u6570\u636e\u8bfb\u5199\u7684\uff0c\u901a\u5e38\u78c1\u76d8\u7684\u901f\u5ea6\u90fd\u4ee5\u8f6c\u6570\u6765\u63cf\u8ff0\uff0c\u6bd4\u5982 5400 \u8f6c\u30017200 \u8f6c</p> <ul> <li>\u56e0\u4e3a\u968f\u673a\u5bfb\u5740\u7684\u8bdd\uff0c\u9700\u8981\u901a\u8fc7\u8f6c\u52a8\u79fb\u52a8\u5230\u4e0b\u4e00\u4e2a\u5730\u5740\u3002</li> <li>\u4f46\u662f\u7531\u4e8e Kafka \u662f\u961f\u5217\u7684\u5f62\u5f0f\uff0c\u521b\u9020\u6027\u5730\u5bf9\u78c1\u76d8\u987a\u5e8f\u8bfb\u5199\uff0c\u5927\u5927\u589e\u52a0\u4e86\u78c1\u76d8\u7684\u4f7f\u7528\u6548\u7387\uff0c\u65e2\u83b7\u5f97\u4e86\u5927\u5b58\u50a8\u91cf\uff0c\u53c8\u63d0\u9ad8\u4e86\u901f\u5ea6\u3002</li> <li>\u540c\u65f6 Kafka \u4e2d\u8fd8\u52a0\u5165\u4e86\u5f88\u591a\u5176\u4ed6\u65b9\u9762\u7684\u4f18\u5316\uff0c\u6bd4\u5982\u901a\u8fc7\u6570\u636e\u538b\u7f29\u6765\u589e\u52a0\u541e\u5410\u91cf\u3001\u652f\u6301\u6bcf\u79d2\u6570\u767e\u4e07\u7ea7\u522b\u7684\u6d88\u606f\u3002</li> </ul>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3-3","title":"3-3 \u6269\u5c55\u6027","text":"<p>\u4e0e\u5927\u6570\u636e\u4f53\u7cfb\u4e2d\u7684\u5176\u4ed6\u7ec4\u4ef6\u4e00\u6837\uff0cKafka \u4e5f\u540c\u6837\u652f\u6301\u4f7f\u7528\u591a\u53f0\u5ec9\u4ef7\u670d\u52a1\u5668\u6765\u7ec4\u5efa\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u6d88\u606f\u7cfb\u7edf\uff0c\u901a\u8fc7 ZooKeeper \u7684\u5173\u8054\uff0cKafka \u4e5f\u975e\u5e38\u6613\u4e8e\u8fdb\u884c\u6c34\u5e73\u6269\u5c55\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3-4","title":"3-4 \u591a\u5ba2\u6237\u7aef\u652f\u6301","text":"<p>\u524d\u9762\u6211\u4eec\u4e5f\u63d0\u5230\u4e86\uff0cKafka \u652f\u6301\u975e\u5e38\u591a\u7684\u5f00\u53d1\u8bed\u8a00\uff0c\u6bd4\u5982 Java\u3001C/C++\u3001Python\u3001Go\u3001Erlang\u3001Node.js \u7b49\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#3-5-kafka-streams","title":"3-5 Kafka Streams","text":"<p>Kafka \u5728 0.10 \u4e4b\u540e\u7248\u672c\u4e2d\u5f15\u5165 Kafka Streams\uff0c\u80fd\u591f\u975e\u5e38\u597d\u5730\u8fdb\u884c\u6d41\u5904\u7406\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#4-flume","title":"4\u3001\u4ec0\u4e48\u662f Flume","text":""},{"location":"chap11/chap11_6bigdtat_kafka_flume/#4-1","title":"4-1 \u6570\u636e\u91c7\u96c6","text":"<p>\u4e3a\u524d\u7aef\u7528\u6237\u4f7f\u7528\u7684\u5ba2\u6237\u7aef\uff0c\u4e0d\u7ba1\u662f App\u3001\u7f51\u9875\u8fd8\u662f\u5c0f\u7a0b\u5e8f\uff0c\u5728\u7528\u6237\u4f7f\u7528\u7684\u65f6\u5019\uff0c\u4f1a\u901a\u8fc7 HTTP \u94fe\u63a5\u628a\u7528\u6237\u7684\u4f7f\u7528\u6570\u636e\u4f20\u8f93\u5230\u540e\u7aef\u670d\u52a1\u5668\u4e0a\uff0c</p> <p>\u670d\u52a1\u5668\u4e0a\u8fd0\u884c\u7684\u670d\u52a1\u628a\u8fd9\u4e9b\u56de\u4f20\u7684\u6570\u636e\u901a\u8fc7\u65e5\u5fd7\u7684\u5f62\u5f0f\u4fdd\u5b58\u5728\u670d\u52a1\u5668\u4e0a\uff0c</p> <p>\u800c\u4ece\u65e5\u5fd7\u5230\u6211\u4eec\u5c06\u6570\u636e\u6700\u7ec8\u843d\u5165 HDFS \u6216\u8005\u8fdb\u5165\u5b9e\u65f6\u8ba1\u7b97\u670d\u52a1\u4e2d\u95f4\u8fd8\u9700\u8981\u4e00\u4e9b\u4f20\u8f93\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#4-2","title":"4-2 \u5b9e\u73b0\u65b9\u6cd5","text":"<ul> <li>\u6bd4\u5982\u8bf4\u5728 Java \u5f00\u53d1\u4e2d\uff0c</li> <li>\u53ef\u4ee5\u501f\u52a9 <code>kafka-log4j-appender</code>\u7c7b\u5e93\u628a log4j\uff08\u65e5\u5fd7\u8bb0\u5f55\u7c7b\u5e93\uff09</li> <li>\u8bb0\u5f55\u7684\u65e5\u5fd7\u540c\u6b65\u5230 Kafka \u6d88\u606f\u961f\u5217\uff0c\u7531 Kafka \u4f20\u8f93\u7ed9\u4e0b\u6e38\u4efb\u52a1\u3002</li> <li>\u7136\u800c\u8fd9\u79cd\u65b9\u5f0f\u6bd4\u8f83\u7b80\u964b\uff0c\u5e76\u4e0d\u592a\u9002\u5408\u5927\u89c4\u6a21\u96c6\u7fa4\u7684\u5904\u7406\uff0c\u56e0\u6b64\uff0c\u8fd9\u91cc\u5c31\u6709\u4e00\u4e2a\u65e5\u5fd7\u91c7\u96c6\u5de5\u5177\uff0c\u90a3\u5c31\u662f Flume\u3002</li> </ul>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#4-3-flume","title":"4-3 Flume \u662f\u4e00\u4e2a\u9ad8\u53ef\u7528\u3001\u5206\u5e03\u5f0f\u7684\u65e5\u5fd7\u6536\u96c6\u548c\u4f20\u8f93\u7684\u7cfb\u7edf","text":"<p>Flume \u6709\u6e90\uff08Source\uff09\u3001\u901a\u9053\uff08Channel\uff09\u548c\u63a5\u6536\u5668\uff08Sink\uff09\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\u6784\u6210\u3002</p> <p>\u8fd9\u4e09\u4e2a\u90e8\u5206\u7ec4\u6210\u4e00\u4e2a Agent\uff0c\u6bcf\u4e2a Agent\u90fd\u662f\u72ec\u7acb\u8fd0\u884c\u7684\u5355\u4f4d\uff0c\u800c Source\u3001Channel\u3001Sink \u6709\u5404\u79cd\u4e0d\u540c\u7684\u7c7b\u578b\uff0c\u53ef\u4ee5\u6839\u636e\u9700\u8981\u8fdb\u884c\u9009\u62e9\uff1a</p> <ul> <li>Channel \u53ef\u4ee5\u628a\u6570\u636e\u7f13\u5b58\u5728\u5185\u5b58\u4e2d\uff0c\u4e5f\u53ef\u4ee5\u5199\u5165\u78c1\u76d8\uff1b</li> <li>Sink \u53ef\u4ee5\u628a\u6570\u636e\u5199\u5165 HBase\uff1b</li> <li>HDFS \u4e5f\u53ef\u4ee5\u4f20\u8f93\u7ed9 Kafka \u751a\u81f3\u662f\u53e6\u5916\u4e00\u4e2a Agent \u7684 Source\u3002</li> </ul> <p></p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5flume","title":"5\u3001Flume \u4e2d\u7684\u6982\u5ff5","text":""},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5-1-source","title":"5-1 \u6e90\uff08Source\uff09","text":"<p>Source \u662f\u8d1f\u8d23\u63a5\u6536\u8f93\u5165\u6570\u636e\u7684\u90e8\u5206\uff0cSource \u6709\u4e24\u79cd\u5de5\u4f5c\u6a21\u5f0f\uff1a</p> <ul> <li>\u4e3b\u52a8\u53bb\u62c9\u53d6\u6570\u636e\uff1b</li> <li>\u7b49\u5f85\u6570\u636e\u4f20\u8f93\u8fc7\u6765\u3002</li> </ul> <p>\u5728\u83b7\u53d6\u5230\u6570\u636e\u4e4b\u540e\uff0cSource \u628a\u6570\u636e\u4f20\u8f93\u7ed9 Channel\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5-2-channel","title":"5-2 \u901a\u9053\uff08Channel\uff09","text":"<p>Channel \u662f\u4e00\u4e2a\u4e2d\u95f4\u73af\u8282\uff0c\u662f\u4e34\u65f6\u5b58\u50a8\u6570\u636e\u7684\u90e8\u5206\uff0cChannel \u4e5f\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u914d\u7f6e\uff0c\u6bd4\u5982\u4f7f\u7528\u5185\u5b58\u3001\u6587\u4ef6\u751a\u81f3\u662f\u6570\u636e\u5e93\u6765\u4f5c\u4e3a Channel\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5-3-sink","title":"5-3 \u63a5\u6536\u5668\uff08Sink\uff09","text":"<p>Sink \u5219\u662f\u5c01\u88c5\u597d\u7684\u8f93\u51fa\u90e8\u5206\uff0c\u9009\u62e9\u4e0d\u540c\u7c7b\u578b\u7684 Sink\uff0c\u5c06\u4f1a\u4ece Channel \u4e2d\u83b7\u53d6\u6570\u636e\u5e76\u8f93\u51fa\u5230\u4e0d\u540c\u7684\u5730\u65b9\uff0c\u6bd4\u5982\u5411 HDFS \u8f93\u51fa\u65f6\u5c31\u4f7f\u7528 HDFS\u00a0Sink\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5-4-event","title":"5-4. \u4ef6\uff08Event\uff09","text":"<p>Flume \u4e2d\u4f20\u9012\u7684\u4e00\u4e2a\u6570\u636e\u5355\u5143\u5373\u79f0\u4e3a\u4e8b\u4ef6\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#5-5-agent","title":"5-5 \u4ee3\u7406\uff08Agent\uff09","text":"<p>\u6b63\u5982\u6211\u4eec\u524d\u9762\u4ecb\u7ecd\u7684\uff0c\u4e00\u4e2a\u4ee3\u7406\u5c31\u662f\u4e00\u4e2a\u72ec\u7acb\u7684\u8fd0\u884c\u5355\u5143\uff0c\u7531 Source\u3001Channel \u548c Sink \u7ec4\u6210\uff0c\u4e00\u4e2a Agent \u4e2d\u53ef\u80fd\u6709\u591a\u4e2a\u7ec4\u4ef6\u3002</p>"},{"location":"chap11/chap11_6bigdtat_kafka_flume/#6kafka-flume","title":"6\u3001Kafka \u4e0e Flume \u7684\u6bd4\u8f83","text":"<p>\u5728\u6570\u636e\u4f20\u8f93\u65b9\u9762\uff0cFlume \u548c Kafka \u7684\u5b9e\u73b0\u539f\u7406\u6bd4\u8f83\u76f8\u4f3c\uff0c\u4f46\u662f\u8fd9\u4e24\u4e2a\u5de5\u5177\u6709\u7740\u5404\u81ea\u7684\u4fa7\u91cd\u70b9\u3002</p> <ul> <li>Kafka \u66f4\u4fa7\u91cd\u4e8e\u6570\u636e\u7684\u5b58\u50a8\u4ee5\u53ca\u6d41\u6570\u636e\u7684\u5b9e\u65f6\u5904\u7406\uff0c\u662f\u4e00\u4e2a\u8ffd\u6c42\u9ad8\u541e\u5410\u91cf\u3001\u9ad8\u8d1f\u8f7d\u7684\u6d88\u606f\u961f\u5217\u3002</li> <li>\u800c Flume \u5219\u662f\u4fa7\u91cd\u4e8e\u6570\u636e\u7684\u91c7\u96c6\u548c\u4f20\u8f93\uff0c\u63d0\u4f9b\u4e86\u5f88\u591a\u79cd\u63a5\u53e3\u652f\u6301\u591a\u79cd\u6570\u636e\u6e90\u7684\u91c7\u96c6\uff0c\u4f46\u662f Flume \u5e76\u4e0d\u76f4\u63a5\u63d0\u4f9b\u6570\u636e\u7684\u6301\u4e45\u5316\u3002</li> </ul> <p>\u5c31\u541e\u5410\u91cf\u548c\u7a33\u5b9a\u6027\u6765\u8bf4\uff0cFlume \u4e0d\u5982 Kafka\u3002</p> <p>\u800c\u5bf9\u4e8eFlume \u5219\u662f\u63d0\u4f9b\u4e86\u66f4\u591a\u5c01\u88c5\u597d\u7684\u7ec4\u4ef6\uff0c\u4e5f\u66f4\u52a0\u8f7b\u91cf\u7ea7\uff0c\u6700\u5e38\u7528\u4e8e\u65e5\u5fd7\u7684\u91c7\u96c6\uff0c\u7701\u53bb\u4e86\u5f88\u591a\u81ea\u5df1\u7f16\u5199\u4ee3\u7801\u7684\u5de5\u4f5c\u3002</p> <p>\u7531\u4e8e Kafka \u548c Flume \u5404\u81ea\u7684\u7279\u70b9\uff0c\u5728\u5b9e\u9645\u7684\u5de5\u4f5c\u4e2d\u6709\u5f88\u591a\u662f\u628aKafka \u548c Flume \u642d\u914d\u8fdb\u884c\u4f7f\u7528\uff0c\u6bd4\u5982\u7ebf\u4e0a\u6570\u636e\u843d\u5230\u65e5\u5fd7\u4e4b\u540e\uff0c\u4f7f\u7528 Flume \u8fdb\u884c\u91c7\u96c6\uff0c\u7136\u540e\u4f20\u8f93\u7ed9 Kafka\uff0c\u518d\u7531 Kafka \u4f20\u8f93\u7ed9\u8ba1\u7b97\u6846\u67b6 MapReduce\u3001Spark\u3001Flink \u7b49\uff0c\u6216\u8005\u6301\u4e45\u5316\u5b58\u50a8\u5230 HDFS \u6587\u4ef6\u7cfb\u7edf\u4e2d\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/","title":"\u7b2c\u4e03\u8282 MapReduce \u5904\u7406\u5927\u6570\u636e","text":""},{"location":"chap11/chap11_7bigdata_mapreduce/#1mapreduce","title":"1\u3001MapReduce \u7684\u67b6\u6784","text":"<p>MapReduce \u5373\u662f\u91c7\u7528\u4e86\u8fd9\u79cd\u5206\u800c\u6cbb\u4e4b\u7684\u5904\u7406\u6570\u636e\u6a21\u5f0f\uff0c\u5c06\u8981\u8fdb\u884c\u7684\u6570\u636e\u5904\u7406\u4efb\u52a1\u5206\u6210 Map\uff08\u6620\u5c04\uff09\u548c Reduce\uff08\u5316\u7b80\uff09\u8fd9\u4e24\u4e2a\u5904\u7406\u8fc7\u7a0b\u3002</p> <p>\u8fd9\u6837\u505a\u6700\u5927\u7684\u597d\u5904\u5c31\u662f\u53ef\u4ee5\u628a\u5927\u89c4\u6a21\u6570\u636e\u5206\u5e03\u5230\u666e\u901a\u6027\u80fd\u7684\u670d\u52a1\u5668\u4e2d\u8fdb\u884c\u9884\u5904\u7406\uff0c\u7136\u540e\u5c06\u5904\u7406\u540e\u7684\u7ed3\u679c\u91cd\u65b0\u8fdb\u884c\u6574\u5408\uff0c\u4ece\u800c\u5f97\u5230\u9700\u8981\u7684\u7ed3\u679c\u3002</p> <p>\u9664\u4e86\u8ba1\u7b97\u672c\u8eab\uff0cMapReduce \u8fd8\u89e3\u51b3\u4e86\u534f\u8c03\u8fd9\u4e9b\u96c6\u7fa4\u4e2d\u7684\u670d\u52a1\u5668\u7684\u95ee\u9898\uff0c</p> <ul> <li>\u6bd4\u5982\u5728\u82e5\u5e72\u53f0\u673a\u5668\u4e2d\u6267\u884c\u8fd0\u7b97\u7684\u987a\u5e8f\u3001</li> <li>\u8ba1\u7b97\u538b\u529b\u7684\u5206\u914d\u3001</li> <li>\u64cd\u4f5c\u7684\u539f\u5b50\u6027\u7b49\u7b49</li> </ul> <p>\u8ddf HDFS \u4e00\u6837\u7684\uff0cMapReduce \u4e5f\u662f\u91c7\u7528\u4e3b\u4ece\u7ed3\u6784\u7684\u67b6\u6784</p> <p></p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#1-1-job","title":"1-1 Job","text":"<p>Job \u5373\u662f\u4f5c\u4e1a\uff0c\u4e00\u4e2a MapReduce \u4f5c\u4e1a\u662f\u7528\u6237\u63d0\u4ea4\u7684\u6700\u5c0f\u5355\u4f4d\uff0c\u6bd4\u5982\u8bf4\u6211\u4eec\u5728\u4e0b\u9762\u5373\u5c06\u52a8\u624b\u8fd0\u884c\u7684 WordCount \u8fd0\u7b97\u5c31\u53ef\u4ee5\u79f0\u4e3a\u4e00\u4e2a\u4f5c\u4e1a\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-2-client","title":"2-2 Client","text":"<p>Client \u5c31\u662f\u5ba2\u6237\u7aef\uff0c\u662f\u7528\u6237\u8bbf\u95ee MapReduce \u7684\u63a5\u53e3\uff0c\u901a\u8fc7 Client \u628a\u7f16\u5199\u597d\u7684 MapReduce \u7a0b\u5e8f\u63d0\u4ea4\u5230 JobTracker \u4e0a\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-3-jobtracker","title":"2-3 JobTracker","text":"<p>\u5728 MapReduce \u4e2d\uff0c\u4e3a\u4e86\u5b9e\u73b0\u5206\u5e03\u5f0f\u7684\u7ba1\u7406\u67b6\u6784\uff0c\u4f7f\u7528\u4e86\u9886\u5bfc\u548c\u968f\u4ece\u7684\u6a21\u5f0f\u3002</p> <p>\u800c JobTracker \u5c31\u662f\u8fd9\u4e2a\u4f53\u7cfb\u4e2d\u7684\u9886\u5bfc\u3002\u4e00\u4e2a MapReduce \u96c6\u7fa4\u53ea\u6709\u4e00\u4e2aJobTracker\uff0c\u8fd9\u4e2a\u8282\u70b9\u8d1f\u8d23\u4e0b\u53d1\u4f5c\u4e1a\uff0c\u540c\u65f6\uff0c\u5b83\u8981\u6536\u542c\u6765\u81ea\u5f88\u591a TaskTracker \u7684\u72b6\u6001\u4fe1\u606f\uff0c\u4ece\u800c\u51b3\u5b9a\u5982\u4f55\u5206\u914d\u5de5\u4f5c\u3002\u5728\u8fd9\u4e2a\u96c6\u7fa4\u4e2d\uff0cJobTracker\u201c\u65e2\u5f53\u7239\u53c8\u5f53\u5988\u201d\uff0c\u800c\u4e14\u53ea\u6709\u4e00\u4e2a\uff0c\u5b58\u5728\u5355\u70b9\u6545\u969c\u7684\u53ef\u80fd\uff0c\u5fc5\u987b\u7ed9\u5b83\u5b89\u6392\u4e00\u4e2a\u597d\u70b9\u3001\u7a33\u5b9a\u70b9\u7684\u673a\u5668\uff0c\u4e0d\u7136\u5982\u679c\u5b83\u7f62\u5de5\u4e86\uff0c\u5c06\u5bfc\u81f4\u96c6\u7fa4\u6240\u6709\u6b63\u5728\u8fd0\u884c\u7684\u4efb\u52a1\u5168\u90e8\u5931\u8d25\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-4-tasktracker","title":"2-4 TaskTracker","text":"<p>TaskTracker \u5728\u96c6\u7fa4\u4e2d\u5219\u626e\u6f14\u4e86\u968f\u4ece\u7684\u89d2\u8272\uff0c\u4e3b\u8981\u8d1f\u8d23\u6267\u884c JopTracker \u5206\u914d\u7684\u4efb\u52a1\uff0c\u540c\u65f6 TaskTracker \u901a\u8fc7 Heartbeat\uff08\u5fc3\u8df3\u4fe1\u606f\uff09\u6c47\u62a5\u5f53\u524d\u7684\u72b6\u6001\uff0cJobTracker \u6839\u636e\u8fd9\u4e9b\u72b6\u6001\u518d\u8fdb\u884c\u4efb\u52a1\u7684\u5206\u914d\u3002</p> <p>\u968f\u4ece\u662f\u5177\u4f53\u8d1f\u8d23\u5de5\u4f5c\u7684\uff0c\u4eba\u591a\u529b\u91cf\u5927\uff0c\u4e00\u4e2a\u96c6\u7fa4\u81ea\u7136\u53ef\u4ee5\u6709\u591a\u4e2a TaskTracker\u3002</p> <p>\u5728\u4e00\u4e2a\u5b9e\u9645\u7684\u8282\u70b9\u4e0a\uff0c\u4f1a\u6709\u4e00\u4e2a TaskTracker \uff0c\u8fd8\u6709\u6211\u4eec\u5728 HDFS \u73af\u8282\u4ecb\u7ecd\u7684 DataNode\uff0c\u8fd9\u6837\uff0c\u4e00\u4e2a\u8282\u70b9\u65e2\u662f\u8ba1\u7b97\u90e8\u5206\u53c8\u662f\u5b58\u50a8\u90e8\u5206\uff0c\u5728\u8fdb\u884c\u8fd0\u7b97\u65f6\uff0c\u53ef\u4ee5\u4f18\u5148\u8fdb\u884c\u672c\u673a\u6570\u636e\u672c\u673a\u8ba1\u7b97\uff0c\u4ece\u800c\u63d0\u5347\u6548\u7387\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-5-task","title":"2-5 Task","text":"<p>Task \u79f0\u4e3a\u4efb\u52a1\uff0c\u662f\u5728 MapReduce \u5b9e\u9645\u8ba1\u7b97\u65f6\u7684\u6700\u5c0f\u5355\u4f4d\uff0cTask \u6709\u4e24\u79cd\uff1aMapTask \u548cReduceTask\uff0c\u7531 TaskTracker \u8fdb\u884c\u542f\u52a8\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-6-split","title":"2-6 Split","text":"<p>\u9664\u4e86\u5728\u56fe\u4e2d\u51fa\u73b0\u7684\u6982\u5ff5\uff0c\u8fd8\u6709\u4e00\u4e2a Split\uff0c\u79f0\u4e3a\u4e00\u4e2a\u5212\u5206\uff0c\u8fd9\u662f MapReduce \u5904\u7406\u7684\u5143\u6570\u636e\u4fe1\u606f\uff0cSplit \u4f1a\u8bb0\u5f55\u5b9e\u9645\u8981\u5904\u7406\u7684\u6570\u636e\u6240\u5728\u7684\u4f4d\u7f6e\u3001\u5927\u5c0f\u7b49\u7b49\u3002\u5728\u300a07 | \u4e13\u4e3a\u89e3\u51b3\u5927\u6570\u636e\u5b58\u50a8\u95ee\u9898\u800c\u4ea7\u751f\u7684 HDFS\u300b\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u6570\u636e\u5757\u7684\u6982\u5ff5\uff0cSplit \u5b9e\u9645\u7684\u6570\u636e\u5c31\u5b58\u50a8\u5728 HDFS \u7684\u6570\u636e\u5757\u4e2d\uff0c\u901a\u5e38\u6211\u4eec\u4f1a\u628a Split \u7684\u5927\u5c0f\u8bbe\u7f6e\u6210\u4e0e\u6570\u636e\u5757\u5927\u5c0f\u4e00\u81f4\uff0c\u6bcf\u6b21\u9700\u8981\u5904\u7406\u7684\u6570\u636e\u5b58\u653e\u5728\u4e00\u4e2a\u4f4d\u7f6e\uff0c\u8fd9\u6837\u53ef\u4ee5\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u7f51\u7edc\u4f20\u8f93\uff0c\u8282\u7ea6\u8d44\u6e90\uff0c\u63d0\u5347\u8ba1\u7b97\u901f\u5ea6\u3002</p> <p>\u4e86\u89e3\u5b8c\u8fd9\u4e48\u591a\u6982\u5ff5\uff0c\u6211\u4eec\u518d\u56de\u987e\u4e00\u4e0b\u6574\u4e2a\u5904\u7406\u6d41\u7a0b\uff1a</p> <ul> <li>\u6211\u4eec\u7f16\u5199\u4e00\u4e2a MapReduce \u7a0b\u5e8f\uff0c\u8fd9\u53ef\u4ee5\u79f0\u4e3a\u4e00\u4e2a Job\uff0c\u5728\u8fd9\u4e2a\u7a0b\u5e8f\u4e2d\u5f80\u5f80\u5305\u542b\u8f83\u591a\u7684 Map \u64cd\u4f5c\uff0c\u548c\u8f83\u5c11\u7684 Reduce \u64cd\u4f5c\uff1b</li> <li>\u901a\u8fc7 Client \u628a Job \u63d0\u4ea4\u5230 JobTracker \u4e0a\uff0cJobTracker \u4f1a\u6839\u636e\u5f53\u524d\u96c6\u7fa4\u4e2d TaskTracker \u7684\u72b6\u6001\uff0c\u5206\u914d\u8fd9\u4e9b\u64cd\u4f5c\u5230\u5177\u4f53\u7684 TaskTracker\u4e0a\uff1b</li> <li>TaskTracker \u542f\u52a8\u76f8\u5e94\u7684 MapTask \u6216\u8005 ReduceTask \u6765\u6267\u884c\u8fd0\u7b97\u3002</li> </ul>"},{"location":"chap11/chap11_7bigdata_mapreduce/#2-7-mapreduce","title":"2-7 MapReduce\u5177\u4f53\u7684\u8fd0\u7b97","text":"<p>MapTask \u8bfb\u53d6 Split \u7684\u6570\u636e\uff0c\u6839\u636e\u4e8b\u5148\u5199\u597d\u7684\u7a0b\u5e8f\u5bf9\u5176\u4e2d\u7684\u6bcf\u4e00\u6761\u6570\u636e\u6267\u884c\u8fd0\u7b97\uff0c\u6bd4\u5982\u8bf4\u540e\u9762\u7684\u5355\u8bcd\u8ba1\u6570\u4ee3\u7801\uff0c\u6211\u4eec\u8f93\u5165\u7684\u662f\u82e5\u5e72\u6587\u672c\u6587\u4ef6\uff0cMap \u64cd\u4f5c\u5904\u7406\u6bcf\u4e00\u884c\u6587\u672c\uff0c\u5e76\u4e3a\u4e00\u884c\u4e2d\u7684\u5355\u8bcd\u8fdb\u884c\u8ba1\u6570\uff0c\u7136\u540e\u628a\u7ed3\u679c\u4fdd\u5b58\u4e0b\u6765\u3002</p> <p>\u800c\u5728 ReduceTask \u4e2d\uff0c\u83b7\u53d6\u4e4b\u524d Map \u7684\u9884\u5904\u7406\u7ed3\u679c\uff0c\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u6bd4\u5982\u8bf4\u76f8\u540c\u5355\u8bcd\u5206\u4e3a\u4e00\u7ec4\uff0c\u7136\u540e\u8fdb\u884c\u52a0\u548c\u8fd0\u7b97\u3002\u5bf9\u4e8e Reduce \u7684\u8f93\u51fa\u7ed3\u679c\uff0c\u4f1a\u5b58\u50a8\u4e09\u4e2a\u526f\u672c\u3002</p>"},{"location":"chap11/chap11_7bigdata_mapreduce/#3mapreduce","title":"3\u3001MapReduce \u7684\u7279\u70b9","text":"<ol> <li>\u7b80\u5316\u4e86\u5206\u5e03\u5f0f\u7a0b\u5e8f\u7684\u7f16\u5199</li> <li>\u53ef\u6269\u5c55\u6027\u5f3a</li> <li>\u5bb9\u9519\u6027\u5f3a</li> </ol>"},{"location":"chap11/chap11_7bigdata_mapreduce/#4mapreduce","title":"4\u3001MapReduce \u7684\u786c\u4f24","text":"<ol> <li>\u5b66\u4e60\u6210\u672c\u9ad8</li> <li>\u65f6\u95f4\u6210\u672c\u8fc7\u9ad8</li> </ol> <p>MapReduce \u662f\u7eaf\u7cb9\u7684\u6279\u5904\u7406\u6a21\u5f0f\uff0c\u4e5f\u5c31\u662f\u8bf4\u6240\u6709\u7684\u6570\u636e\u90fd\u662f\u4e8b\u5148\u5df2\u7ecf\u5b58\u50a8\u597d\u7684\uff0cMapReduce \u53ea\u662f\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u6279\u91cf\u7684\u5904\u7406\uff0c\u8fd9\u5bf9\u4e8e\u4e92\u8054\u7f51\u4e2d\u5927\u91cf\u7684\u6d41\u5f0f\u6570\u636e\u65e0\u6cd5\u7ed9\u5230\u5f88\u597d\u7684\u652f\u6301\uff0c\u5982\u679c\u6211\u4eec\u60f3\u8981\u5904\u7406\u4eca\u5929\u7684\u6570\u636e\uff0c\u8981\u7b49\u5230\u4eca\u5929\u7684\u6570\u636e\u90fd\u5df2\u7ecf\u5b58\u50a8\u597d\u518d\u8fdb\u884c\u8ba1\u7b97\uff0c\u800c\u4e0d\u80fd\u968f\u6765\u968f\u7b97\u3002</p>"},{"location":"chap11/chap11_8bigdata_spark/","title":"\u7b2c\u516b\u8282 Spark \u4e0e Flink \u7684\u7231\u6068\u60c5\u4ec7 (Spark)","text":"<p>MapReduce \u7684\u4e3b\u8981\u529f\u80fd\u5c31\u662f\u5e76\u884c\u8ba1\u7b97\uff0c\u4f46\u662f\u5b83\u4e5f\u4e0d\u662f\u5341\u5168\u5341\u7f8e\u7684\uff0cMapReduce \u9ad8\u6210\u672c\u7684\u786c\u4f24\u4f7f\u5f97\u5b83\u5df2\u7ecf\u4e0d\u80fd\u5f88\u597d\u5730\u89e3\u51b3\u65b0\u65f6\u4ee3\u7684\u95ee\u9898</p>"},{"location":"chap11/chap11_8bigdata_spark/#1-spark","title":"1\u3001\u4ec0\u4e48\u662f Spark","text":"<p>Spark \u662f\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u5904\u7406\u7684\u901a\u7528\u5206\u6790\u5f15\u64ce\u3002 Spark \u7684\u529f\u80fd\uff0c</p> <ul> <li>\u4e00\u4e2a\u662f\u9488\u5bf9\u5927\u89c4\u6a21\u6570\u636e</li> <li>\u4e00\u4e2a\u662f\u901a\u7528\u5206\u6790\u5f15\u64ce</li> </ul>"},{"location":"chap11/chap11_8bigdata_spark/#1-1-spark","title":"1-1 Spark \u7684\u53d1\u5c55\u5386\u7a0b","text":"<p>\u5728 2009 \u5e74\uff0c\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u7684 RAD \u5b9e\u9a8c\u5ba4\uff08AMP \u5b9e\u9a8c\u5ba4\u524d\u8eab\uff09\u63a8\u51fa\u4e86 Spark \u6846\u67b6\uff0c\u5e76\u8868\u660e Spark \u662f\u4e00\u4e2a\u7c7b\u4f3c MapReduce \u7684\u901a\u7528\u5e76\u884c\u6846\u67b6\uff0c\u53ef\u7528\u6765\u6784\u5efa\u5927\u578b\u7684\u3001\u4f4e\u5ef6\u8fdf\u7684\u6570\u636e\u5206\u6790\u5e94\u7528\u7a0b\u5e8f\u3002\u5b9e\u9a8c\u5ba4\u7684\u7814\u7a76\u4eba\u5458\u5728\u4f7f\u7528 MapReduce \u65f6\u53d1\u73b0\u5b83\u5728\u8fed\u4ee3\u8ba1\u7b97\u548c\u4ea4\u4e92\u8ba1\u7b97\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u4e8e\u662f\u5f00\u59cb\u8bbe\u8ba1 Spark\u3002\u5f88\u5feb\uff0cSpark \u5728\u4e00\u4e9b\u4efb\u52a1\u4e0a\u7684\u6548\u7387\u5c31\u5df2\u7ecf\u6bd4 MapReduce \u63d0\u5347\u4e86 10 \u500d\u4ee5\u4e0a\u3002</p> <p>Spark \u5728\u4e92\u8054\u7f51\u516c\u53f8\u7684\u5927\u6570\u636e\u67b6\u6784\u4e2d\u9010\u6e10\u6210\u4e3a\u4e3b\u6d41\u8ba1\u7b97\u6846\u67b6\u3002</p>"},{"location":"chap11/chap11_8bigdata_spark/#1-2-spark","title":"1-2 Spark \u7684\u7279\u8272","text":"<ul> <li>\u9ad8\u901f</li> </ul> <p>Spark \u4f7f\u7528\u4e86\u6700\u65b0\u7684 DAG \u8c03\u5ea6\u65b9\u6848\uff0c\u67e5\u8be2\u3001\u4f18\u5316\u548c\u7269\u7406\u6267\u884c\u5f15\u64ce\uff0c\u5728\u6279\u5904\u7406\u548c\u201c\u6d41\u201d\u5904\u7406\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u3002</p> <ul> <li>\u6613\u7528</li> </ul> <p>Spark \u63d0\u4f9b\u4e86 80 \u591a\u79cd\u9ad8\u9636\u64cd\u4f5c\uff0c\u6784\u5efa\u5e94\u7528\u66f4\u52a0\u65b9\u4fbf\u3002Spark \u8fd8\u63d0\u4f9b\u4e86\u591a\u79cd\u8bed\u8a00\u652f\u6301\uff0c\u4f7f\u7528 Java\u3001Scala\u3001Python\u3001R \u751a\u81f3\u662f SQL \u90fd\u53ef\u4ee5\u975e\u5e38\u5bb9\u6613\u5730\u7f16\u5199 Spark \u7a0b\u5e8f\u3002</p> <ul> <li>\u901a\u7528</li> </ul> <p>\u5982\u4e0b\u56fe\u6240\u793a\uff0cSpark \u9664\u4e86\u63d0\u4f9b\u8ba1\u7b97\u6846\u67b6\u4ee5\u5916\u8fd8\u6574\u5408\u4e86 SQL\u3001\u6d41\u5f0f\u5904\u7406\uff0c\u4ee5\u53ca\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5e93\u548c\u56fe\u64cd\u4f5c\u7b97\u6cd5\u5e93\u3002\u5176\u4e2d Spark\u00a0SQL \u652f\u6301\u4f7f\u7528 HiveQL \u548c Spark \u8fdb\u884c\u4ea4\u4e92\u3002</p> <p></p> <ul> <li> <p>\u591a\u5e73\u53f0\u652f\u6301</p> <ul> <li>Spark \u672c\u8eab\u662f\u53ef\u4ee5\u72ec\u7acb\u8fd0\u884c\u7684\uff0c\u5f53\u7136\uff0c\u5b83\u4e5f\u53ef\u4ee5\u8fd0\u884c\u5728 Hadoop\u3001Mesos\u3001Kubernetes\uff0c\u751a\u81f3\u662f\u4e91\u5e73\u53f0\u4e0a\u3002</li> <li>\u652f\u6301\u8bbf\u95ee\u5404\u79cd\u4e0d\u540c\u7684\u6570\u636e\u6e90\uff0c\u6bd4\u5982 HDFS\u3001HBase\u3001Hive\u3001Cassandra \u90fd\u662f\u53ef\u4ee5\u7684\u3002</li> </ul> </li> <li> <p>\u5185\u5b58\u5316</p> </li> </ul> <p>\u5728\u8fd0\u7b97\u6d41\u7a0b\u4e0a\uff0cSpark \u548c MapReduce \u57fa\u672c\u4e0a\u662f\u4e00\u81f4\u7684\uff0c\u4f46\u662f\u6709\u4e00\u4e2a\u5f88\u5927\u7684\u4e0d\u540c\u5c31\u662f\u4e2d\u95f4\u7ed3\u679c\u7684\u5b58\u50a8\uff1a</p> <ol> <li>MapReduce \u6240\u6709\u7684\u4e2d\u95f4\u7ed3\u679c\u90fd\u662f\u4fdd\u5b58\u5728\u78c1\u76d8\u4e0a\uff1b</li> <li>\u800c Spark \u7684\u4e2d\u95f4\u7ed3\u679c\u662f\u4fdd\u5b58\u5728\u5185\u5b58\u4e2d\u7684\u3002</li> </ol>"},{"location":"chap11/chap11_8bigdata_spark/#2-spark","title":"2 Spark \u57fa\u7840","text":""},{"location":"chap11/chap11_8bigdata_spark/#2-1-rdd-resillient-distributed-dataset","title":"2-1 RDD Resillient Distributed Dataset\uff08\u5f39\u6027\u5206\u5e03\u5f0f\u6570\u636e\u96c6)","text":"<p>\u5b83\u662f Spark \u7684\u4e00\u4e2a\u57fa\u672c\u6570\u636e\u7ed3\u6784\uff0c\u4e5f\u662fSpark \u6700\u6838\u5fc3\u7684\u6570\u636e\u7ed3\u6784\u3002</p> <ul> <li>Spark \u5728\u8fd0\u884c\u65f6\uff0c\u4f1a\u5c06 RDD \u5206\u5272\u6210\u4e0d\u540c\u7684 Partition\uff08\u5206\u533a\uff09\uff0c\u5e76\u628a\u8fd9\u4e9b\u5206\u533a\u6295\u653e\u5230\u4e0d\u540c\u7684\u8ba1\u7b97\u8282\u70b9\u4e0b\u9762\uff0c\u8fdb\u884c\u5e76\u884c\u8fd0\u7b97</li> <li>Spark \u7a0b\u5e8f\u7684\u6574\u4e2a\u751f\u547d\u6d41\u7a0b\uff0c\u5c31\u662f\u5bf9\u8fd9\u4e9b\u6570\u636e\u7684\u5904\u7406\uff0c\u521b\u5efa RDD\u3001\u8f6c\u6362 RDD\u3001\u8c03\u7528 RDD \u64cd\u4f5c\u8ba1\u7b97\u5404\u79cd\u7ed3\u679c\u7b49</li> </ul>"},{"location":"chap11/chap11_8bigdata_spark/#2-2","title":"2-2 \u4e24\u79cd\u64cd\u4f5c","text":"<p>\u5728\u6211\u4eec\u7684\u8fd0\u7b97\u4e2d\uff0c\u901a\u5e38\u5305\u542b\u4e24\u79cd\u64cd\u4f5c\uff0c\u4e00\u4e2a\u662fTransformation\uff08\u8f6c\u6362\u64cd\u4f5c\uff09\uff0c\u4e00\u4e2a\u662fAction\uff08\u884c\u52a8\u64cd\u4f5c\uff09\u3002\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u6700\u5927\u7684\u533a\u522b\u662f Spark \u5bf9\u5b83\u4eec\u7684\u5904\u7406\u903b\u8f91\u662f\u4e0d\u4e00\u6837\u7684\u3002</p> <ul> <li>\u5982\u8bf4 Filter\uff08\u8fc7\u6ee4\uff09\uff0c\u8fd9\u4e9b\u64cd\u4f5c\u662f\u5bf9 RDD \u672c\u8eab\u7684\u4e00\u4e9b\u64cd\u4f5c,<ul> <li>\u5176\u7ed3\u679c\u662f\u6570\u636e\u7684\u89c4\u6a21\u53d1\u751f\u53d8\u5316\uff0c\u800c\u6570\u636e\u7684\u7c7b\u578b\u6216\u8005\u8bf4\u5185\u5bb9\u4e0d\u4f1a\u53d1\u751f\u53d8\u5316 </li> </ul> </li> <li>Spark \u662f\u8fdb\u884c\u60f0\u6027\u8fd0\u7b97<ul> <li>Spark \u53ea\u662f\u8bb0\u5f55\u4e0b\u8fd9\u4e2a\u64cd\u4f5c\uff0c\u800c\u4e0d\u4f1a\u771f\u7684\u53bb\u6267\u884c\u5b83\u3002</li> <li>\u53ea\u6709\u5f53 Spark \u9047\u5230\u4e86\u884c\u52a8\u64cd\u4f5c\uff0c\u624d\u4f1a\u628a\u4e4b\u524d\u7684\u8f6c\u6362\u64cd\u4f5c\u8fdb\u884c\u7edf\u4e00\u7684\u5904\u7406\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba4\u4e3a\u884c\u52a8\u64cd\u4f5c\u662f\u4e00\u4e9b\u4ea7\u751f\u7ed3\u679c\u7684\u64cd\u4f5c\uff0c\u5b83\u7684\u8f93\u51fa\u662f\u975e RDD \u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p></p> <pre><code>val RDD1 = sc.textFile(\"data.txt\")\nval RDD2 = RDD1.map(x =&gt; x+1)\nval RDD3 = RDD2.filter(lambda x: \"Python\" in x)\nval RDD4 = RDD3.reduceByKey((x,y) =&gt; x + y)\n\nval RDD5 = RDD2.filter(lambda x: \"Java\" in x)\nRDD5.count\n</code></pre> <p></p> <ul> <li>\u9996\u5148\uff0c\u6211\u4eec\u4ece\u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\uff0c\u8fd9\u65f6\u5019\u5f62\u6210 RDD1\u3002</li> <li>\u540e\u9762\u4e24\u6b65\u6267\u884c\u4e86 map\u3001filter \u548c reduceByKey \u64cd\u4f5c\uff0cmap \u64cd\u4f5c\u7ed9\u6240\u6709\u503c\u52a0\u4e86 1\uff0c\u800c filter \u64cd\u4f5c\u8fc7\u6ee4\u51fa\u5e26\u6709 Python \u7684\u6570\u636e\uff0creduceByKey \u5bf9 x \u548c y \u8fdb\u884c\u76f8\u52a0\u3002\u8fd9\u51e0\u4e2a\u64cd\u4f5c\u90fd\u5c5e\u4e8e Transformation \u64cd\u4f5c\uff0c\u8f93\u51fa\u7684\u7ed3\u679c\u90fd\u4ecd\u7136\u662f RDD\u3002</li> <li> <p>\u800c\u6700\u540e\u4e00\u884c\u6267\u884c\u4e86 count \u64cd\u4f5c\uff0ccount \u5c31\u662f\u4e00\u4e2a Action \u64cd\u4f5c\uff0c\u5b83\u8fd4\u56de\u7684\u662f RDD5 \u4e2d\u7684\u6570\u636e\u5143\u7d20\u4e2a\u6570\u3002</p> </li> <li> <p>\u5982\u679c Spark \u5bf9\u6bcf\u4e00\u6b65\u90fd\u8ba4\u771f\u6267\u884c\uff0c\u90a3\u4e48\u7b2c\u4e00\u6b65\u8bfb\u53d6\u6587\u4ef6\u540e\uff0c\u5c31\u5df2\u7ecf\u628a\u5168\u91cf\u7684\u6570\u636e\u5b58\u50a8\u5728\u4e86\u5185\u5b58\u4e2d</p> </li> <li>\u4f46\u5b9e\u9645\u8fd9\u5e76\u6ca1\u6709\u4ec0\u4e48\u7528\uff0c\u5f53 Spark \u6839\u636e\u4e0a\u9762\u7684\u6267\u884c\u903b\u8f91\u5206\u6790\u4e86\u8fd0\u7b97\u6d41\u7a0b\u4e4b\u540e\uff0c</li> <li>\u4f1a\u5bf9 Transformation \u64cd\u4f5c\u8fdb\u884c\u6574\u5408\uff0c</li> <li>\u76f4\u5230\u9047\u5230 Action \u64cd\u4f5c\u624d\u771f\u6b63\u53bb\u8fdb\u884c\u8fd0\u7b97\u3002</li> </ul>"},{"location":"chap11/chap11_8bigdata_spark/#3","title":"3\u3001\u4e24\u79cd\u4f9d\u8d56\u5173\u7cfb","text":"<p>\u7531\u4e8e\u5728 Spark \u4e2d\u6d41\u8f6c\u7684\u6570\u636e\u901a\u5e38\u90fd\u662fRDD \u683c\u5f0f\uff0c\u4ece\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u4ee5\u770b\u51fa\uff0c\u6bcf\u4e00\u6b65\u751f\u6210\u7684 RDD \u90fd\u4f1a\u4f9d\u8d56\u4e8e\u4e0a\u4e00\u6b65\u7684 RDD\uff0c\u6240\u4ee5\uff0c\u5177\u5907\u4e0a\u4e0b\u8054\u7cfb\u7684 RDD \u4ea7\u751f\u7684\u5173\u7cfb\u88ab\u79f0\u4e3a\u4f9d\u8d56\u5173\u7cfb</p> <p>\u6839\u636e\u4e0d\u540c\u60c5\u51b5\u53c8\u5206\u6210\u7a84\u4f9d\u8d56\u5173\u7cfb\u548c\u5bbd\u4f9d\u8d56\u5173\u7cfb\u4e24\u79cd\uff1a</p> <ul> <li>\u7a84\u4f9d\u8d56\u5173\u7cfb\u6307\u7684\u662f\u751f\u6210\u4e0b\u7ea7 RDD \u4e0d\u4f1a\u5f15\u8d77\u6570\u636e\u5728\u4e0d\u540c\u7684\u5206\u533a\uff08Partition\uff09\u4e4b\u95f4\u8fdb\u884c\u8fc1\u79fb\uff08Shuffle\uff09\uff1b</li> <li>\u5bbd\u4f9d\u8d56\u6307\u7684\u662f\u8981\u751f\u6210\u7684 RDD \u4f9d\u8d56\u4e8e\u591a\u4e2a\u5206\u533a\u7684\u6570\u636e\uff0c\u5f88\u660e\u663e\u8fd9\u4f1a\u5bfc\u81f4\u5904\u7406\u901f\u5ea6\u7684\u4e0b\u964d\u3002</li> </ul> <p></p> <p>\u5f53\u6211\u4eec\u7f16\u5199\u4e86\u4e00\u4e2a Spark \u7a0b\u5e8f\uff0c\u4e5f\u5c31\u662f\u4e00\u4e2a Application \u65f6\uff1a</p> <ul> <li>\u8fd9\u4e2a Application \u4ee5 Action \u64cd\u4f5c\u4e3a\u754c\u9650\uff0c\u88ab\u5212\u5206\u6210\u591a\u4e2a Job\uff1b</li> <li>\u4e00\u4e2a Job \u4ee5 Shuffle \u4e3a\u754c\u9650\u88ab\u5212\u5206\u6210\u591a\u4e2a Stage\uff1b</li> <li>\u800c\u4e00\u4e2a Stage \u53c8\u4f1a\u5206\u6210\u591a\u4e2a Task\uff0cStage \u7684\u5212\u5206\u548c\u8c03\u5ea6\u662f\u7531 DAGScheduler \u6765\u8d1f\u8d23\u7684\uff0c\u800c Task \u7531 TASKScheduler \u6765\u8fdb\u884c\u8c03\u5ea6\u3002</li> </ul> <p>\u8fd9\u4e9b\u8c03\u5ea6\u7684\u7ec8\u6781\u76ee\u6807\u5c31\u662f\u6839\u636e\u4f9d\u8d56\u7684\u5173\u7cfb\u627e\u51fa\u5f00\u9500\u6700\u5c0f\u7684\u8c03\u5ea6\u65b9\u6cd5</p> <p>\u6700\u7ec8\uff0c\u8fd9\u4e9b\u4efb\u52a1\u88ab\u5206\u6d3e\u5230\u4e0d\u540c\u7684 Worker \u4e0a\u8fdb\u884c\u8fd0\u7b97\u3002</p> <p></p> <p>\u5982\u4e0a\u56fe\u6240\u793a\uff0c\u8fd9\u91cc\u7684 Driver \u4e5f\u5c31\u662f\u6211\u4eec\u5728\u4ee3\u7801\u4e2d\u5e38\u8bf4\u7684 main \u51fd\u6570\uff0c\u5f53\u5b83\u88ab\u6267\u884c\u65f6\u4f1a\u521b\u5efa\u4e00\u4e2a SparkContext \u5bf9\u8c61\uff0c\u8fd9\u4e2a\u5bf9\u8c61\u4f1a\u4e0e\u670d\u52a1\u5668\u4e2d\u7684 Cluster\u00a0Manager \u8fdb\u884c\u901a\u4fe1\uff0c\u4ece\u800c\u7533\u8bf7\u4efb\u52a1\u6240\u9700\u8981\u7684\u8d44\u6e90\u3002\u5f53\u6210\u529f\u83b7\u5f97\u8d44\u6e90\u4e4b\u540e\uff0c\u5b83\u7684 Task \u4f1a\u88ab\u5206\u914d\u5230 Worker \u7684\u6267\u884c\u5668\u4e2d\uff0c\u4ece\u800c\u5904\u7406\u5bf9\u5e94\u7684\u8fd0\u7b97\u3002</p>"},{"location":"chap11/chap11_8bigdata_spark/#4","title":"4\u3001\u5f00\u53d1\u65f6\u9700\u8981\u6ce8\u610f\u7684\u95ee\u9898","text":""},{"location":"chap11/chap11_8bigdata_spark/#4-1","title":"4-1 \u6570\u636e\u503e\u659c","text":"<p>\u7531\u4e8e RDD \u6570\u636e\u4f1a\u88ab\u5206\u914d\u5230\u4e0d\u540c\u7684\u5206\u533a\uff0c\u5b58\u5728\u5e38\u89c1\u7684\u95ee\u9898\u5c31\u662f\u6570\u636e\u503e\u659c\uff0c\u67d0\u4e9b\u5206\u533a\u5206\u914d\u4e86\u8fc7\u591a\u7684\u6570\u636e\uff0c\u800c\u53e6\u5916\u7684\u4e00\u4e9b\u5206\u533a\u5219\u5206\u914d\u4e86\u5f88\u5c11\u7684\u6570\u636e\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u4e9b\u8282\u70b9\u7684\u8fd0\u7b97\u8fc7\u4e8e\u7f13\u6162\u3002</p>"},{"location":"chap11/chap11_8bigdata_spark/#4-2-action","title":"4-2 \u8fc7\u591a\u5730\u4f7f\u7528 Action \u64cd\u4f5c","text":"<p>\u7531\u4e8e Action \u64cd\u4f5c\u4f1a\u5f15\u53d1\u771f\u6b63\u7684\u8fd0\u7b97\uff0c\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u7f13\u5b58\uff0c\u6240\u4ee5\uff0c\u5982\u679c Action \u64cd\u4f5c\u592a\u591a\u4f1a\u9020\u6210\u5185\u5b58\u7684\u5927\u91cf\u6d88\u8017\uff0c\u4ece\u800c\u5360\u7528\u8fc7\u591a\u7684\u8d44\u6e90\u3002</p>"},{"location":"chap11/chap11_8bigdata_spark/#4-3","title":"4-3 \u5bbd\u4f9d\u8d56\u8fc7\u591a","text":"<p>\u5bbd\u4f9d\u8d56\u4f1a\u5f15\u53d1 Shuffle\uff0c\u5c06\u4e0d\u540c Partition \u7684\u6570\u636e\u8fc1\u79fb\u5230\u540c\u4e00\u4e2a Partition \u4e2d\u53bb\uff0c\u6240\u4ee5\u8fd9\u4e2a\u64cd\u4f5c\u4e5f\u4f1a\u6d88\u8017\u5f88\u591a\u65f6\u95f4\u3002</p> <p></p>"},{"location":"chap11/chap11_9bigdata_flink/","title":"\u7b2c\u4e5d\u8282 Spark \u4e0e Flink \u7684\u7231\u6068\u60c5\u4ec7 (Flink)","text":"<p>\u5728\u4ecb\u7ecd Flink \u4e4b\u524d\uff0c\u6211\u60f3\u5148\u4ecb\u7ecd\u4e24\u4e2a\u6982\u5ff5\uff1a\u6279\u5904\u7406\u4e0e\u6d41\u5904\u7406\u3002</p>"},{"location":"chap11/chap11_9bigdata_flink/#1","title":"1\u3001\u6279\u5904\u7406\u4e0e\u6d41\u5904\u7406","text":""},{"location":"chap11/chap11_9bigdata_flink/#1-1","title":"1-1 \u6279\u5904\u7406","text":"<p>\u6240\u8c13\u7684\u6279\u5904\u7406\uff0c\u5c31\u662f\u628a\u4e00\u6574\u5757\u6570\u636e\u5207\u5206\u6210\u4e00\u5c0f\u5757\u4e00\u5c0f\u5757\uff0c\u6bcf\u4e00\u4e2a\u5c0f\u5757\u79f0\u4e3a\u4e00\u6279\u3002</p> <p>\u628a\u4e00\u4e2a\u5c0f\u5757\u6570\u636e\u5206\u914d\u7ed9\u4e00\u4e2a\u8ba1\u7b97\u8282\u70b9\u8fdb\u884c\u8fd0\u7b97\uff0c\u8fd9\u79cd\u60c5\u51b5\u79f0\u4e3a\u6279\u5904\u7406\u3002</p> <p>\u6279\u5904\u7406\u9488\u5bf9\u7684\u6570\u636e\u662f\u4e00\u4e2a\u6709\u9650\u96c6\u5408\uff0c\u4e5f\u5c31\u662f\u6709\u754c\u6570\u636e</p> <p>\u8fd9\u4e9b\u6570\u636e\u5728\u5904\u7406\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u50a8\u5728\u6211\u4eec\u7684\u6e90\u6570\u636e\u5730\u5740\uff0c\u5f53\u6211\u4eec\u8981\u8fdb\u884c\u5904\u7406\u7684\u65f6\u5019\u76f4\u63a5\u4ece\u8fd9\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bfb\u53d6\u5c31\u53ef\u4ee5\u4e86</p>"},{"location":"chap11/chap11_9bigdata_flink/#1-2","title":"1-2 \u6d41\u5904\u7406","text":"<p>\u4e0e\u6279\u5904\u7406\u76f8\u5bf9\u7684\uff0c\u6d41\u5904\u7406\u7684\u6570\u636e\u662f\u65e0\u754c\u7684\uff0c\u6570\u636e\u5c31\u50cf\u4e00\u6761\u6cb3\u91cc\u7684\u6c34\u6e90\u6e90\u4e0d\u65ad\u5730\u4ece\u4e0a\u6e38\u6d41\u5230\u8ba1\u7b97\u6846\u67b6\u4e2d\uff0c\u6211\u4eec\u4e0d\u77e5\u9053\u6570\u636e\u7684\u603b\u91cf\u662f\u591a\u5c11\uff0c\u4e5f\u4e0d\u77e5\u9053\u4ec0\u4e48\u65f6\u5019\u7ed3\u675f</p>"},{"location":"chap11/chap11_9bigdata_flink/#2-flink","title":"2\u3001\u4ec0\u4e48\u662f Flink","text":"<p>Apache Flink \u662f\u4e00\u4e2a\u6846\u67b6\u548c\u5206\u5e03\u5f0f\u5904\u7406\u5f15\u64ce\uff0c\u7528\u4e8e\u5728\u65e0\u8fb9\u754c\u548c\u6709\u8fb9\u754c\u6570\u636e\u6d41\u4e0a\u8fdb\u884c\u6709\u72b6\u6001\u7684\u8ba1\u7b97\uff0cFlink \u80fd\u5728\u6240\u6709\u5e38\u89c1\u96c6\u7fa4\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u5e76\u80fd\u4ee5\u5185\u5b58\u901f\u5ea6\u548c\u4efb\u610f\u89c4\u6a21\u8fdb\u884c\u8ba1\u7b97\u3002</p> <p>Flink \u7684\u529f\u80fd\u4e0e Spark \u4e5f\u57fa\u672c\u4e00\u81f4\uff0c\u90fd\u5c5e\u4e8e\u5927\u6570\u636e\u8ba1\u7b97\u6846\u67b6\u3002</p>"},{"location":"chap11/chap11_9bigdata_flink/#3flink","title":"3\u3001Flink \u7684\u7279\u8272","text":""},{"location":"chap11/chap11_9bigdata_flink/#3-1","title":"3-1 \u6570\u636e\u7686\u6d41","text":"<p>\u5728 Flink \u7684\u6784\u5efa\u601d\u60f3\u4e0a\uff0c\u628a\u6240\u6709\u7684\u6570\u636e\u90fd\u770b\u4f5c\u662f\u6d41\u5f0f\u6570\u636e\uff0c\u6240\u6709\u7684\u5904\u7406\u65b9\u5f0f\u90fd\u662f\u6d41\u5904\u7406</p> <p>\u5bf9\u4e8e\u4e8b\u5b9e\u4e0a\u7684\u6279\u6570\u636e\uff0c\u53ea\u4e0d\u8fc7\u5f53\u6210\u4e00\u79cd\u7279\u6b8a\u7684\u6570\u636e\u6d41\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u6709\u754c\u6d41\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fd9\u4e2a\u6d41\u6570\u636e\u6709\u5f00\u59cb\u6709\u7ed3\u675f\uff0c\u6211\u4eec\u53ef\u4ee5\u7b49\u7740\u8fd9\u4e2a\u6d41\u83b7\u53d6\u5b8c\u5168\u540e\u7edf\u4e00\u8fdb\u884c\u8ba1\u7b97\u3002</p> <p>\u5bf9\u4e8e\u5728\u6211\u4eec\u516c\u53f8\u4e2d\u771f\u6b63\u7684\u6d41\u6570\u636e\uff0c\u6211\u4eec\u5c06\u5176\u79f0\u4e3a\u65e0\u754c\u6d41\uff0c\u8fd9\u4e2a\u6570\u636e\u53ea\u6709\u5f00\u59cb\uff0c\u6ca1\u6709\u7ed3\u675f\u3002\u53ea\u8981\u6211\u4eec\u7684\u4e1a\u52a1\u8fd8\u5728\u8fd0\u8f6c\uff0c\u7528\u6237\u8fd8\u5728\u6d4f\u89c8\u6211\u4eec\u7684 App\uff0c\u67e5\u770b\u3001\u4e0b\u5355\u3001\u652f\u4ed8\u6570\u636e\u5c31\u4f1a\u6e90\u6e90\u4e0d\u65ad\u5730\u4f20\u9001\u8fc7\u6765</p> <p>\u5904\u7406\u8fd9\u79cd\u6570\u636e\uff0c\u4e0d\u5149\u662f\u6c47\u603b\u8d77\u6765\u5c31\u5b8c\u4e8b\u4e86\uff0c\u5f88\u591a\u65f6\u5019\u8fd8\u9700\u8981\u6ce8\u610f\u6570\u636e\u7684\u987a\u5e8f\uff0c</p> <p>\u6bd4\u5982\u8bf4\u6b63\u5e38\u60c5\u51b5\u4e0b\u80af\u5b9a\u662f\u5148\u70b9\u51fb\uff0c\u518d\u4e0b\u5355\uff0c\u6700\u540e\u652f\u4ed8\u3002\u5982\u679c\u6570\u636e\u7684\u987a\u5e8f\u641e\u9519\u4e86\uff0c\u5df2\u7ecf\u6709\u4e86\u652f\u4ed8\uff0c\u4f46\u662f\u6ca1\u6709\u70b9\u51fb\u548c\u4e0b\u5355\uff0c\u90a3\u8fd9\u6570\u636e\u8ba1\u7b97\u8d77\u6765\u5c31\u4e71\u4e86\u5957\u4e86\u3002</p> <ul> <li>\u5728\u6570\u636e\u63a5\u6536\u65b9\u9762\uff0cFlink \u4e0e Kafka \u6709\u5f02\u66f2\u540c\u5de5\u4e4b\u5999\uff0c\u90fd\u662f\u57fa\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u7684\uff0c\u4e5f\u5c31\u662f\u6570\u636e\u968f\u6765\u968f\u5904\u7406\uff0c</li> <li>\u800c Spark \u5b9e\u73b0\u7684\u6d41\u5904\u7406\u5b9e\u9645\u4e0a\u662f\u5fae\u6279\u5904\u7406\uff0c\u53ea\u662f\u628a\u6570\u636e\u5757\u5212\u5206\u7684\u66f4\u5c0f\u3002</li> <li>\u540c\u65f6\uff0cFlink \u8fd8\u6709\u7cbe\u786e\u7684\u65f6\u95f4\u63a7\u5236\u548c\u72b6\u6001\u4ee5\u4fdd\u969c\u4e00\u81f4\u6027\u3002</li> </ul>"},{"location":"chap11/chap11_9bigdata_flink/#3-2","title":"3-2 \u591a\u5e73\u53f0\u652f\u6301","text":"<p>\u540c Spark \u4e00\u6837\uff0cFlink \u53ef\u4ee5\u4f5c\u4e3a\u5355\u72ec\u7684\u670d\u52a1\u8fdb\u884c\u90e8\u7f72\u8fd0\u884c\uff0c\u4e5f\u53ef\u4ee5\u4e0e Hadoop\u3001Mesos\u3001Kubernetes \u96c6\u6210\u90e8\u7f72\u3002</p>"},{"location":"chap11/chap11_9bigdata_flink/#3-3","title":"3-3 \u9ad8\u901f","text":"<p>\u540c\u6837\u7684\uff0cFlink \u4e5f\u4f7f\u7528\u4e86\u5185\u5b58\u4f5c\u4e3a\u8ba1\u7b97\u7684\u4e2d\u95f4\u7f13\u5b58\u3002</p> <p>\u5728\u524d\u9762\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\uff0c\u6279\u5904\u7406\u7531\u4e8e\u662f\u5df2\u7ecf\u7d2f\u79ef\u4e0b\u6765\u7684\u6570\u636e\uff0c\u6240\u4ee5\u9700\u8981\u5927\u541e\u5410\u91cf\uff0c\u800c\u6d41\u5904\u7406\u662f\u6765\u5373\u5904\u7406\uff0c\u9700\u8981\u7684\u662f\u4f4e\u5ef6\u8fdf\u3002</p> <p>\u5728 Flink \u4e2d\uff0c\u4f7f\u7528\u4e86\u4e00\u79cd\u7f13\u5b58\u5757\u673a\u5236\u6765\u4fdd\u969c\u4e24\u79cd\u8ba1\u7b97\u7684\u901f\u5ea6\u3002\u5f53\u7f13\u5b58\u5757\u7684\u8d85\u65f6\u65f6\u95f4\u8bbe\u7f6e\u4e3a 0\uff0c\u90a3\u4e48\u53ea\u8981\u6709\u6570\u636e\u5c31\u7acb\u5373\u5904\u7406\uff0c\u9002\u5408\u5904\u7406\u65e0\u754c\u6570\u636e\uff0c\u800c\u5f53\u7f13\u5b58\u5757\u8d85\u65f6\u65f6\u95f4\u8bbe\u7f6e\u4e3a\u65e0\u9650\u5927\uff0c\u90a3\u4e48\u5c31\u8981\u7b49\u7740\u6570\u636e\u7ed3\u675f\u624d\u5904\u7406\uff0c\u8fd9\u6837\u66f4\u9002\u5408\u6709\u754c\u6570\u636e\u3002</p>"},{"location":"chap11/chap11_9bigdata_flink/#4flink","title":"4\u3001Flink \u7684\u7ec4\u4ef6\u67b6\u6784","text":"<p>\u4e0e Spark \u7c7b\u4f3c\uff0cFlink \u4e5f\u5b9e\u73b0\u4e86\u7528\u4e00\u6574\u5957\u7ec4\u4ef6\u6765\u652f\u6301\u6574\u4e2a\u4f53\u7cfb\u7684\u8fd0\u8f6c\uff0c\u5982\u4e0a\u56fe\u6240\u793a\u3002</p> <ul> <li> <p>\u6700\u5e95\u5c42\u662f\u90e8\u7f72\u76f8\u5173\u7684\u7ec4\u4ef6\uff0c\u5305\u62ec\u4e86\u652f\u6301\u672c\u5730\u5355\u673a\u90e8\u7f72\u3001\u96c6\u7fa4\u90e8\u7f72\uff0c\u4ee5\u53ca\u4e91\u4e0a\u90e8\u7f72\u7684\u7ec4\u4ef6\u3002</p> </li> <li> <p>Core \u6838\u5fc3\u5c42\uff0c\u662f Flink \u5b9e\u73b0\u7684\u6700\u5173\u952e\u7ec4\u4ef6\uff0c\u5305\u62ec\u652f\u6301\u5206\u5e03\u5f0f\u7684\u6d41\u5904\u7406\u8fd0\u7b97\uff0c\u5404\u79cd\u5206\u914d\u548c\u8c03\u5ea6\u7cfb\u7edf\u90fd\u5728\u8fd9\u4e00\u90e8\u5206\u5b9e\u73b0\uff0c\u4e3a\u66f4\u4e0a\u5c42\u7684 API \u63d0\u4f9b\u57fa\u7840\u670d\u52a1\uff0c\u8fd9\u4e5f\u4e3a\u7528\u6237\u7684\u65b9\u4fbf\u4f7f\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002</p> </li> <li> <p>API \u548c Lib \u5c42\uff0c\u63d0\u4f9b\u4e86\u6d41\u5904\u7406\u548c\u6279\u5904\u7406\u8ba1\u7b97\u7684\u5404\u79cd API\uff0c\u4ee5\u53ca\u9488\u5bf9\u7279\u5b9a\u7684\u8ba1\u7b97\u652f\u6301\u5e93\uff0c\u6bd4\u5982 FlinkML \u5c31\u662f\u548c SparkMlib \u7c7b\u4f3c\u7684\u673a\u5668\u5b66\u4e60\u5e93\uff0c\u800c Gelly \u662f\u548c GraphX \u7c7b\u4f3c\u7684\u56fe\u5904\u7406\u8ba1\u7b97\u5e93\u3002</p> </li> </ul>"},{"location":"chap11/chap11_9bigdata_flink/#5spark-vs-flink","title":"5\u3001Spark\u00a0VS\u00a0Flink","text":""},{"location":"chap11/chap11_9bigdata_flink/#5-1","title":"5-1 \u6838\u5fc3\u5b9e\u73b0","text":"<p>\u5728\u6838\u5fc3\u5b9e\u73b0\u65b9\u9762\uff1a</p> <ul> <li>Spark \u4e3b\u8981\u4f7f\u7528 Scala \u8bed\u8a00\u7f16\u5199\u800c\u6210\uff1b</li> <li>\u800c Flink \u65e9\u671f\u662f\u4f7f\u7528 Java \u8fdb\u884c\u7f16\u5199\u7684\uff0c\u4f46\u662f\u540e\u671f\u7684\u5f88\u591a\u66f4\u65b0\u4e5f\u4f7f\u7528\u4e86 Scala \u8bed\u8a00\u3002</li> </ul>"},{"location":"chap11/chap11_9bigdata_flink/#5-2","title":"5-2 \u7f16\u7a0b\u63a5\u53e3","text":"<p>\u5728\u7f16\u7a0b\u63a5\u53e3\u65b9\u9762\uff0cSpark \u548c Flink \u5c31\u66f4\u52a0\u76f8\u4f3c\u4e86\u3002\u4e8c\u8005\u90fd\u63d0\u4f9b\u4e86\u5bf9\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u652f\u6301\uff0c\u5305\u62ec Java\u3001Python\u3001Scala \u7b49\uff0c\u90fd\u53ef\u4ee5\u7528\u6765\u7f16\u5199 Spark \u6216\u8005 Flink \u7a0b\u5e8f\u3002</p>"},{"location":"chap11/chap11_9bigdata_flink/#5-3","title":"5-3 \u8ba1\u7b97\u6a21\u578b","text":"<p>\u8ba1\u7b97\u6a21\u578b\uff0c\u6216\u8005\u6211\u4eec\u4e5f\u53ef\u4ee5\u53eb\u4f5c\u8bbe\u8ba1\u7406\u5ff5</p> <p>Flink \u662f\u628a\u6240\u6709\u6570\u636e\u90fd\u770b\u4f5c\u6d41\u6765\u8fdb\u884c\u5904\u7406\uff0c\u6240\u4ee5\u5b83\u672c\u8eab\u5bf9\u6d41\u5f0f\u6570\u636e\u6709\u7740\u975e\u5e38\u4f18\u79c0\u7684\u8ba1\u7b97\u6027\u80fd\uff0c\u5728\u6d41\u8ba1\u7b97\u65b9\u9762\u505a\u4e86\u5927\u91cf\u7684\u4f18\u5316</p> <p>\u800c Spark \u867d\u7136\u4e5f\u662f\u6df7\u5408\u8ba1\u7b97\u6846\u67b6\uff0c\u4f46\u662f Spark \u7684\u8bbe\u8ba1\u7406\u5ff5\u662f\u6279\u5904\u7406\uff0c\u4e5f\u5c31\u662f\u6240\u6709\u6570\u636e\u90fd\u662f\u6279\u6570\u636e\u3002\u5728\u5904\u7406\u6d41\u6570\u636e\u7684\u65f6\u5019\u4f7f\u7528\u4e86\u6a21\u62df\u7684\u529e\u6cd5\uff0c\u628a\u6570\u636e\u5206\u5272\u6210\u66f4\u5c0f\u7684\u6279\u6765\u8fdb\u884c\u5904\u7406\uff0c\u4ece\u800c\u6a21\u62df\u6d41\u5f0f\u5904\u7406\uff0c\u6240\u4ee5\u5728 Spark \u4e2d\u7684\u6d41\u5904\u7406\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u79f0\u4e3a\u5fae\u6279\u5904\u7406\u3002</p> <p>Flink \u9009\u62e9\u4e86\u2018batch on streaming\u2019\u7684\u67b6\u6784\uff0c\u4e0d\u540c\u4e8e Spark \u9009\u62e9\u7684\u2018streaming on batch\u2019\u67b6\u6784\u201d\u3002</p> <p>\u65e9\u671f\u7684 Flink \u7531\u4e8e\u9488\u5bf9\u6d41\u5904\u7406\u8fdb\u884c\u7684\u4f18\u5316\uff0c\u4e5f\u4f7f\u5f97\u5b83\u5728\u6279\u5904\u7406\u65b9\u9762\u4ecd\u7136\u6ca1\u6709 Spark \u6027\u80fd\u826f\u597d</p>"},{"location":"chap11/chap11_9bigdata_flink/#5-4","title":"5-4 \u6d41\u6279\u4e00\u4f53","text":"<p>\u5728\u6700\u8fd1\u7684\u4e24\u5e74\u5185\uff0cFlink \u4e3b\u6253\u6d41\u6279\u4e00\u4f53\u7684\u5347\u7ea7\uff0c\u4ece\u4e0a\u9762\u7684\u67b6\u6784\u56fe\u53d8\u5316\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\u6765\uff0c\u5728\u6700\u65b0\u7684 1.11 \u7248\u672c\uff0c\u4e0d\u7ba1\u662f SQL \u8fd8\u662f DataStream\u00a0API\uff0c\u90fd\u5df2\u7ecf\u53ef\u4ee5\u4f7f\u7528\u540c\u4e00\u5957\u7f16\u5199\u89c4\u8303\uff0c\u800c\u53ea\u9700\u8981\u8fdb\u884c\u7b80\u5355\u7684\u9009\u62e9\u5c31\u53ef\u4ee5\u8fdb\u884c\u6279\u5904\u7406\u6216\u8005\u6d41\u5904\u7406\u3002</p> <p>\u968f\u7740\u6d41\u6279\u4e00\u4f53\u6280\u672f\u7684\u5b9e\u73b0\uff0c\u4f7f\u7528 Flink \u7684\u516c\u53f8\u4e0d\u518d\u9700\u8981\u7ef4\u62a4\u4e24\u5957\u67b6\u6784\uff0c\u90e8\u7f72\u4e24\u5957\u4ee3\u7801\uff0c\u7ef4\u62a4\u6210\u672c\u4f1a\u8fdb\u4e00\u6b65\u964d\u4f4e\uff0c\u89c9\u5f97 Flink \u4f1a\u53d8\u5f97\u66f4\u52a0\u666e\u53ca\uff0c\u751a\u81f3\u662f\u53d6\u4ee3 Spark \u6210\u4e3a\u65b0\u4e00\u4ee3\u4e3b\u6d41\u8ba1\u7b97\u6846\u67b6\u3002</p>"},{"location":"chap12/1aws_data_storage/","title":"\u6570\u636e\u5e93\u3001\u6570\u636e\u6e56\u3001\u6570\u636e\u4ed3\u5e93\u3001\u6e56\u4ed3\u4e00\u4f53\u3001\u667a\u80fd\u6e56\u4ed3","text":""},{"location":"chap12/1aws_data_storage/#1","title":"1\u3001\u6570\u636e\u4ed3\u5e93\u662f\u4e2a\u5565\uff1f\u548c\u6570\u636e\u5e93\u6709\u4ec0\u4e48\u4e0d\u540c\uff1f","text":"<p>\u6570\u636e\u5e93\u4e3b\u8981\u7528\u4e8e\u300c\u4e8b\u52a1\u5904\u7406\u300d\uff0c\u5b58\u53d6\u6b3e\u8fd9\u79cd\u7b97\u662f\u6700\u5178\u578b\u7684\uff0c\u7279\u522b\u5f3a\u8c03\u6bcf\u79d2\u80fd\u5e72\u591a\u5c11\u4e8b\u513f\uff1aQPS\uff08\u6bcf\u79d2\u67e5\u8be2\u6570\uff09\u3001TPS\uff08\u6bcf\u79d2\u4e8b\u52a1\u6570\uff09\u3001IOPS\uff08\u6bcf\u79d2\u8bfb\u5199\u6570\uff09\u7b49\u7b49\u3002</p> <p></p>"},{"location":"chap12/1aws_data_storage/#1-1","title":"1-1 \u6570\u636e\u4ed3\u5e93","text":"<p>\u901a\u5e38\u662f\u4e1a\u52a1\u53d1\u5c55\u5230\u4e00\u5b9a\u89c4\u6a21\u540e\uff0c\u4e1a\u52a1\u5206\u6790\u5e08\u3001CIO\u3001\u51b3\u7b56\u8005\u4eec\uff0c\u5e0c\u671b\u4ece\u5927\u91cf\u7684\u5e94\u7528\u7cfb\u7edf\u3001\u4e1a\u52a1\u6570\u636e\u4e2d\uff0c\u8fdb\u884c\u5173\u8054\u5206\u6790\uff0c\u6700\u7ec8\u6574\u70b9\u201c\u5e72\u8d27\u201d\u51fa\u6765\u3002</p> <p>\u53ef\u662f\uff0c\u6570\u636e\u5e93\u201c\u8111\u5bb9\u91cf\u4e0d\u8db3\u201d\uff0c\u64c5\u957f\u4e8b\u52a1\u6027\u5de5\u4f5c\uff0c\u4e0d\u64c5\u957f\u5206\u6790\u578b\u7684\u5de5\u4f5c\uff0c\u4e8e\u662f\u5c31\u4ea7\u751f\u4e86\u6570\u636e\u4ed3\u5e93\u3002</p> <p>\u867d\u7136\u73b0\u5728HTAP\u7684\u6982\u5ff5\u5f88\u76db\u884c\uff0c\u4e5f\u5c31\u662f\u6df7\u5408\u4e8b\u52a1/\u5206\u6790\u5904\u7406\uff0c\u7528\u4e00\u5957\u6570\u636e\u5e93\u67b6\u6784\u6765\u540c\u65f6\u652f\u6301\u4e8b\u52a1(OLTP)\u548c\u5206\u6790(OLAP)\u4e24\u79cd\u9700\u6c42\uff0c\u4f46\u771f\u6b63\u5927\u89c4\u6a21\u7684\u5206\u6790\u548c\u6d1e\u5bdf\uff0c\u8fd8\u662f\u79bb\u4e0d\u5f00\u6570\u636e\u4ed3\u5e93\u3002</p> <p>\u6570\u636e\u4ed3\u5e93\u76f8\u5f53\u4e8e\u4e00\u4e2a\u96c6\u6210\u5316\u6570\u636e\u7ba1\u7406\u7684\u5e73\u53f0\uff0c\u4ece\u591a\u4e2a\u6570\u636e\u6e90\u62bd\u53d6\u6709\u4ef7\u503c\u7684\u6570\u636e\uff0c\u5728\u4ed3\u5e93\u5185\u8f6c\u6362\u548c\u6d41\u52a8\uff0c\u5e76\u63d0\u4f9b\u7ed9BI\u7b49\u5206\u6790\u5de5\u5177\u6765\u8f93\u51fa\u5e72\u8d27\u3002</p> <p></p> <p>\u56e0\u4e3a\u5206\u6790\u578b\u4e1a\u52a1\u9700\u8981\u5927\u91cf\u7684\u201c\u8bfb\u201d\u64cd\u4f5c\uff0c\u6240\u4ee5\u6570\u636e\u4ed3\u5e93\u901a\u8fc7\u201cDenormalized\u201d\u5316\u7684\u65b9\u5f0f\u4f18\u5316\u8868\u7ed3\u6784\uff0c\u51cf\u5c11\u8868\u95f4\u8054\u63a5\uff0c\u727a\u7272\u7a7a\u95f4\u6765\u6362\u53d6\u8bfb\u6027\u80fd\u3002\uff08\u4e00\u5f20\u8868\u91cc\u7684\u5197\u4f59\u6570\u636e\u589e\u52a0\u4e86\uff0c\u4f46\u67e5\u8be2\u8d77\u6765\u5374\u66f4\u5feb\u4e86\uff09\uff0c\u5e76\u4f7f\u7528\u5217\u5f0f\u5b58\u50a8\u4f18\u5316\uff0c\u6765\u8fdb\u4e00\u6b65\u63d0\u9ad8\u67e5\u8be2\u901f\u5ea6\u3001\u964d\u4f4e\u5f00\u9500\u3002</p> <p>\u518d\u7ed3\u5408\u9762\u5411\u5206\u6790\u573a\u666f\u7684Schema\u8bbe\u8ba1\uff0c\u6570\u636e\u4ed3\u5e93\u5c31\u53ef\u4ee5\u9ad8\u6548\u7387\u3001\u5168\u65b9\u4f4d\u3001\u591a\u7ef4\u5ea6\u7684\u625b\u8d77\u201c\u8054\u673a\u5206\u6790\u201d\u91cd\u4efb\u4e86\u3002</p> <p></p>"},{"location":"chap12/1aws_data_storage/#2","title":"2\u3001\u6570\u636e\u6e56\u53c8\u662f\u4e2a\u5565\uff1f","text":"<p>\u6570\u636e\u5e93\u8d1f\u8d23\u5e72\u4e8b\u52a1\u5904\u7406\u76f8\u5173\u7684\u4e8b\uff0c\u6570\u636e\u4ed3\u5e93\u8d1f\u8d23\u5e72\u4e1a\u52a1\u5206\u6790\u76f8\u5173\u7684\u4e8b\uff0c\u8fd8\u6709\u65b0\u5174\u7684HTAP\u6570\u636e\u5e93\u65e2\u5e72\u4e8b\u52a1\u53c8\u5e72\u5206\u6790\uff0c\u90fd\u5df2\u7ecf\u8fd9\u4e48\u5185\u5377\u4e86\uff0c\u8fd8\u8981\u6570\u636e\u6e56\u6765\u5e72\u4e2a\u6bdb\u7ebf\uff1f</p> <p>\u4f01\u4e1a\u5e0c\u671b\u628a\u751f\u4ea7\u7ecf\u8425\u4e2d\u7684\u6240\u6709\u76f8\u5173\u6570\u636e\uff0c\u5386\u53f2\u7684\u3001\u5b9e\u65f6\u7684\uff0c\u5728\u7ebf\u7684\u3001\u79bb\u7ebf\u7684\uff0c\u5185\u90e8\u7684\u3001\u5916\u90e8\u7684\uff0c\u7ed3\u6784\u5316\u7684\u3001\u975e\u7ed3\u6784\u5316\u7684\uff0c\u90fd\u80fd\u5b8c\u6574\u4fdd\u5b58\u4e0b\u6765\uff0c\u65b9\u4fbf\u201c\u6c99\u4e2d\u6dd8\u91d1\u201d\u3002</p> <p>\u6570\u636e\u6e56\u7684\u672c\u8d28\uff0c\u662f\u7531\u201c\u278a\u6570\u636e\u5b58\u50a8\u67b6\u6784+\u278b\u6570\u636e\u5904\u7406\u5de5\u5177\u201d\u7ec4\u6210\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u4e0d\u662f\u67d0\u4e2a\u5355\u4e00\u72ec\u7acb\u4ea7\u54c1\u3002</p> <p></p> <ul> <li>\u6570\u636e\u5b58\u50a8\u67b6\u6784\uff0c\u8981\u6709\u8db3\u591f\u7684\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\uff0c\u8981\u6ee1\u8db3\u4f01\u4e1a\u80fd\u628a\u6240\u6709\u539f\u59cb\u6570\u636e\u90fd\u201c\u56e4\u201d\u8d77\u6765\uff0c\u5b58\u5f97\u4e0b\u3001\u5b58\u5f97\u4e45\u3002\u6bd4\u5982 Amazon Web Service\uff0c\u4fee\u5efa\u201c\u6e56\u5e95\u201d\u7528\u7684\u201c\u7816\u5934\u201d\uff0c\u5c31\u662fAmazon S3\u4e91\u5bf9\u8c61\u5b58\u50a8\u3002</li> <li>\u6570\u636e\u5904\u7406\u5de5\u5177\uff0c\u5219\u5206\u4e3a\u4e24\u5927\u7c7b\u2193<ul> <li>\u7b2c\u4e00\u7c7b\u5de5\u5177\uff0c\u89e3\u51b3\u7684\u95ee\u9898\u662f\u5982\u4f55\u628a\u6570\u636e\u201c\u642c\u5230\u201d\u6e56\u91cc\uff0c\u5305\u62ec\u5b9a\u4e49\u6570\u636e\u6e90\u3001\u5236\u5b9a\u6570\u636e\u8bbf\u95ee\u7b56\u7565\u548c\u5b89\u5168\u7b56\u7565\uff0c\u5e76\u79fb\u52a8\u6570\u636e\u3001\u7f16\u5236\u6570\u636e\u76ee\u5f55\u7b49\u7b49\u3002</li> </ul> </li> </ul> <p>\u5982\u679c\u6ca1\u6709\u8fd9\u4e9b\u6570\u636e\u7ba1\u7406/\u6cbb\u7406\u5de5\u5177\uff0c\u5143\u6570\u636e\u7f3a\u5931\uff0c\u6e56\u91cc\u7684\u6570\u636e\u8d28\u91cf\u5c31\u6ca1\u6cd5\u4fdd\u969c\uff0c\u201c\u6ce5\u77f3\u4ff1\u4e0b\u201d\uff0c\u5404\u79cd\u6570\u636e\u503e\u6cfb\u5806\u79ef\u5230\u6e56\u91cc\uff0c\u6700\u7ec8\u597d\u597d\u7684\u6570\u636e\u6e56\uff0c\u6162\u6162\u5c31\u53d8\u6210\u4e86\u6570\u636e\u6cbc\u6cfd\u3002</p> <p>Amazon Web Services\u63d0\u4f9b\u201cAmazon Lake Formation\u201d\u8fd9\u4e2a\u5de5\u5177\uff0c\u5e2e\u52a9\u5ba2\u6237\u81ea\u52a8\u5316\u5730\u628a\u5404\u79cd\u6570\u636e\u6e90\u4e2d\u7684\u6570\u636e\u79fb\u52a8\u5230\u6e56\u91cc\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u8c03\u7528Amazon Glue\u6765\u5bf9\u6570\u636e\u8fdb\u884cETL\uff0c\u7f16\u5236\u6570\u636e\u76ee\u5f55\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6e56\u91cc\u6570\u636e\u7684\u8d28\u91cf\u3002 </p> <p></p> <ul> <li>\u7b2c\u4e8c\u7c7b\u5de5\u5177\uff0c\u5c31\u662f\u8981\u4ece\u6e56\u91cc\u7684\u6d77\u91cf\u6570\u636e\u4e2d\u201c\u6dd8\u91d1\u201d\u3002</li> </ul> <p>\u6211\u4eec\u7ee7\u7eed\u62ffAmazon Web Services\u6765\u4e3e\u4f8b\u5b50\uff0c\u57fa\u4e8eAmazon Athena\u8fd9\u4e2a\u670d\u52a1\uff0c\u5c31\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7684SQL\u6765\u5bf9 Amazon S3\uff08\u6570\u636e\u6e56\uff09\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u4ea4\u4e92\u5f0f\u67e5\u8be2\u3002</p> <p>\u518d\u6bd4\u5982\u4f7f\u7528Amazon SageMaker\u673a\u5668\u5b66\u4e60\u670d\u52a1\uff0c\u5bfc\u5165\u6570\u636e\u6e56\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u8fd9\u4e9b\u90fd\u662f\u5e38\u89c4\u64cd\u4f5c\u3002</p>"},{"location":"chap12/1aws_data_storage/#3","title":"3\u3001\u6570\u636e\u6e56\u548c\u6570\u636e\u4ed3\u5e93\u533a\u522b","text":"<p>\u4ece\u6570\u636e\u542b\u91d1\u91cf\u6765\u6bd4\uff0c\u6570\u636e\u4ed3\u5e93\u91cc\u7684\u6570\u636e\u4ef7\u503c\u5bc6\u5ea6\u66f4\u9ad8\u4e00\u4e9b\uff0c\u6570\u636e\u7684\u62bd\u53d6\u548cSchema\u7684\u8bbe\u8ba1\uff0c\u90fd\u6709\u975e\u5e38\u5f3a\u7684\u9488\u5bf9\u6027\uff0c\u4fbf\u4e8e\u4e1a\u52a1\u5206\u6790\u5e08\u8fc5\u901f\u83b7\u53d6\u6d1e\u5bdf\u7ed3\u679c\uff0c\u7528\u4e8e\u51b3\u7b56\u652f\u6301\u3002</p> <p>\u800c\u4ece\u4ea7\u54c1\u5f62\u6001\u770b\uff0c\u6570\u636e\u4ed3\u5e93\u53ef\u4ee5\u662f\u72ec\u7acb\u7684\u6807\u51c6\u5316\u4ea7\u54c1\uff0c\u62ff\u4e91\u4e0a\u6570\u4ed3\u6765\u4e3e\u4f8b\uff0cAmazon Redshift\uff0c\u5c31\u662f\u4e00\u6b3e\u201c\u6570\u4ed3\u4ea7\u54c1\u201d\u3002</p> <p>\u6570\u636e\u6e56\u5219\u662f\u4e00\u79cd\u67b6\u6784\uff0c\u901a\u5e38\u662f\u56f4\u7ed5\u5bf9\u8c61\u5b58\u50a8\u4e3a\u201c\u6e56\u5e95\u5ea7\u201d\u7684\u5927\u6570\u636e\u7ba1\u7406\u65b9\u6848\u7ec4\u5408\u3002\u6bd4\u5982\uff0cAmazon Web Services\u5e76\u6ca1\u6709\u54ea\u4e2a\u4ea7\u54c1\u53eb\u201c\u6570\u636e\u6e56\u201d\uff0c\u800c\u662f\u4ee5 Amazon S3\u4e3a\u57fa\u7840\uff0c\u7ed3\u5408\u4e00\u7cfb\u5217\u6570\u636e\u7ba1\u7406\u5de5\u5177\uff0c\u5e2e\u52a9\u5ba2\u6237\u6784\u5efa\u4e91\u4e0a\u201c\u6570\u636e\u6e56\u201d</p> <p></p>"},{"location":"chap12/1aws_data_storage/#4","title":"4\u3001\u4e3a\u4ec0\u4e48\u8981\u628a\u201c\u6e56\u201d\u548c\u201c\u4ed3\u201d\u7cc5\u5230\u4e00\u8d77\uff1f","text":"<p>\u6570\u636e\u6e56\u8d77\u6b65\u6210\u672c\u5f88\u4f4e\uff0c\u4f46\u968f\u7740\u6570\u636e\u4f53\u91cf\u589e\u5927\uff0cTCO\u6210\u672c\u4f1a\u52a0\u901f\u98d9\u5347\uff0c\u6570\u4ed3\u5219\u6070\u6070\u76f8\u53cd\uff0c\u524d\u671f\u5efa\u8bbe\u5f00\u652f\u5f88\u5927\u3002</p> <p>\u603b\u4e4b\uff0c\u4e00\u4e2a\u540e\u671f\u6210\u672c\u9ad8\uff0c\u4e00\u4e2a\u524d\u671f\u6210\u672c\u9ad8\uff0c\u5bf9\u4e8e\u65e2\u60f3\u4fee\u6e56\u3001\u53c8\u60f3\u5efa\u4ed3\u7684\u7528\u6237\u6765\u8bf4\uff0c\u4eff\u4f5b\u73a9\u4e86\u4e00\u4e2a\u91d1\u94b1\u6e38\u620f\u3002</p> <p>\u6bd4\u5982\uff0c\u8ba9\u201c\u6570\u4ed3\u201d\u5728\u8fdb\u884c\u6570\u636e\u5206\u6790\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u76f4\u63a5\u8bbf\u95ee\u6570\u636e\u6e56\u91cc\u7684\u6570\u636e\uff08Amazon Redshift Spectrum\u662f\u8fd9\u4e48\u5e72\u7684\uff09\u3002\u518d\u6bd4\u5982\uff0c\u8ba9\u6570\u636e\u6e56\u5728\u67b6\u6784\u8bbe\u8ba1\u4e0a\uff0c\u5c31\u201c\u539f\u751f\u201d\u652f\u6301\u6570\u4ed3\u80fd\u529b\uff08DeltaLake\u662f\u8fd9\u4e48\u5e72\uff09\u3002</p> <p>\u6b63\u662f\u8fd9\u4e9b\u60f3\u6cd5\u548c\u9700\u6c42\uff0c\u63a8\u52a8\u4e86\u6570\u4ed3\u548c\u6570\u636e\u6e56\u7684\u6253\u901a\u548c\u878d\u5408\uff0c\u4e5f\u5c31\u662f\u5f53\u4e0b\u7099\u624b\u53ef\u70ed\u7684\u6982\u5ff5\uff1aLake House\u3002</p>"},{"location":"chap12/1aws_data_storage/#5lake-house","title":"5\u3001\u5230\u5e95\u4ec0\u4e48\u624d\u662f\u771f\u6b63\u7684Lake House\uff1f","text":"<p>Lake House\uff0c\u574a\u95f4\u901a\u5e38\u79f0\u4e4b\u4e3a\u201c\u6e56\u4ed3\u4e00\u4f53\u201d\uff0c\u800cAmazon Web Services\u5219\u53eb\u505a\u201c\u667a\u80fd\u6e56\u4ed3\u201d\u3002</p> <p>Lake House\u67b6\u6784\u6700\u91cd\u8981\u7684\u4e00\u70b9\uff0c\u662f\u5b9e\u73b0\u201c\u6e56\u91cc\u201d\u548c\u201c\u4ed3\u91cc\u201d\u7684\u6570\u636e/\u5143\u6570\u636e\u80fd\u591f\u65e0\u7f1d\u6253\u901a\uff0c\u5e76\u4e14\u201c\u81ea\u7531\u201d\u6d41\u52a8\u3002</p> <p></p> <p>\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e2a\u76ee\u6807\uff0cAmazon Web Services\u63a8\u51fa\u4e86 Amazon Redshift Spectrum\uff0c\u6253\u901a\u4e86\u6570\u4ed3\u5bf9\u6570\u636e\u6e56\u7684\u76f4\u63a5\u8bbf\u95ee\uff0c\u80fd\u591f\u9ad8\u6548\u67e5\u8be2 Amazon S3 \u6570\u636e\u6e56\u5f53\u4e2d\u7684EB\u7ea7\u6570\u636e\u3002</p> <p>\u201cSpectrum\u201d\u662f\u667a\u80fd\u6e56\u4ed3\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u88ab\u79f0\u4e3a\u201cLake House\u5f15\u64ce\u201d\uff0c\u5b83\u53ef\u4ee5\u5728\u6e56\u4e0e\u4ed3\u4e4b\u95f4\u67b6\u8d77\u6570\u636e\u6d41\u52a8\u7684\u7ba1\u9053</p> <ul> <li>\u53ef\u4ee5\u5c06\u6570\u636e\u6e56\u4e2d\u6700\u8fd1\u51e0\u4e2a\u6708\u7684\u201c\u70ed\u6570\u636e\u201d\u6444\u53d6\u5230\u6570\u4ed3\u4e2d\uff1b</li> <li>\u53cd\u8fc7\u6765\uff0c\u4e5f\u53ef\u4ee5\u8f7b\u677e\u5c06\u5927\u91cf\u51b7\u95e8\u5386\u53f2\u6570\u636e\u4ece\u6570\u4ed3\u8f6c\u79fb\u81f3\u6210\u672c\u66f4\u4f4e\u5ec9\u7684\u6570\u636e\u6e56\u5185\uff0c\u540c\u65f6\u8fd9\u4e9b\u79fb\u5230\u6e56\u91cc\u7684\u6570\u636e\uff0c\u4ecd\u7136\u53ef\u4ee5\u88ab Amazon Redshift \u6570\u4ed3\u67e5\u8be2\u4f7f\u7528;</li> <li>\u5904\u7406\u6570\u4ed3\u5185\u7684\u70ed\u6570\u636e\u4e0e\u6570\u636e\u6e56\u4e2d\u7684\u5386\u53f2\u6570\u636e\uff0c\u751f\u6210\u4e30\u5bcc\u7684\u6570\u636e\u96c6\uff0c\u5168\u7a0b\u65e0\u9700\u6267\u884c\u4efb\u4f55\u6570\u636e\u79fb\u52a8\u64cd\u4f5c\uff1b</li> <li>\u751f\u6210\u7684\u65b0\u6570\u636e\u96c6\u53ef\u4ee5\u63d2\u5165\u5230\u6570\u4ed3\u4e2d\u7684\u8868\u5185\uff0c\u6216\u8005\u76f4\u63a5\u63d2\u5165\u7531\u6570\u636e\u6e56\u6258\u7ba1\u7684\u5916\u90e8\u8868\u4e2d\u3002</li> </ul> <p></p> <p>\u628a\u6570\u636e\u6e56\u548c\u6570\u636e\u4ed3\u5e93\u96c6\u6210\u8d77\u6765\u53ea\u662f\u7b2c\u4e00\u6b65\uff0c\u8fd8\u8981\u628a\u6e56\u3001\u4ed3\u4ee5\u53ca\u6240\u6709\u5176\u4ed6\u6570\u636e\u5904\u7406\u670d\u52a1\u7ec4\u6210\u7edf\u4e00\u4e14\u8fde\u7eed\u7684\u6574\u4f53\uff0c\u8fd9\u5c31\u662fAmazon Web Services\u4e3a\u4f55\u628a\u81ea\u5bb6\u7684Lake House\u67b6\u6784\u79f0\u4e3a\u201c\u667a\u80fd\u6e56\u4ed3\u201d\uff0c\u800c\u975e\u201c\u6e56\u4ed3\u4e00\u4f53\u201d\u3002</p>"},{"location":"chap12/1aws_data_storage/#6","title":"6\u3001\u667a\u80fd\u6e56\u4ed3\u624d\u662f\u7ec8\u6781","text":"<p>\u667a\u80fd\u6e56\u4ed3\u5e76\u975e\u5355\u4e00\u4ea7\u54c1\uff0c\u5b83\u63cf\u8ff0\u7684\u662f\u4e00\u79cd\u67b6\u6784\u3002</p> <p>\u8fd9\u5957\u67b6\u6784\uff0c\u4ee5\u6570\u636e\u6e56\u4e3a\u4e2d\u5fc3\uff0c\u628a\u6570\u636e\u6e56\u4f5c\u4e3a\u4e2d\u592e\u5b58\u50a8\u5e93\uff0c\u518d\u56f4\u7ed5\u6570\u636e\u6e56\u5efa\u7acb\u4e13\u7528\u201c\u6570\u636e\u670d\u52a1\u73af\u201d\uff0c\u73af\u4e0a\u7684\u670d\u52a1\u5305\u62ec\u4e86\u6570\u4ed3\u3001\u673a\u5668\u5b66\u4e60\u3001\u5927\u6570\u636e\u5904\u7406\u3001\u65e5\u5fd7\u5206\u6790\uff0c\u751a\u81f3RDS\u548cNOSQL\u670d\u52a1\u7b49\u7b49\u3002</p> <p></p> <p></p> <p>\u4e2d\u95f4\u662f\u6e56\uff0c\u5468\u8fb9\u96c6\u6210\u4e86\u5168\u5957\u7684\u4e91\u4e0a\u6570\u636e\u670d\u52a1\uff0c\u7136\u540e\u8fd8\u6709 Amazon Lake Formation\u3001Amazon Glue\u3001Amazon Athena \u4ee5\u53ca\u524d\u9762\u91cd\u70b9\u63d0\u5230\u7684 Amazon Redshift Spectrum\u8fd9\u4e9b\u5de5\u5177\uff0c\u6765\u5b9e\u73b0\u6570\u636e\u6e56\u7684\u6784\u5efa\u3001\u6570\u636e\u7684\u7ba1\u7406\u3001\u5b89\u5168\u7b56\u7565\u4ee5\u53ca\u6570\u636e\u7684\u79fb\u52a8\u3002</p> <p></p>"},{"location":"chap12/2aws_emr_20230421/","title":"20230421-\u4e91\u539f\u751f\u5927\u6570\u636eEMR\u7814\u8ba8\u4f1a","text":"<p>\u4e0e\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u4e13\u5bb6\u4eec\u4e92\u52a8\u5e76\u4e00\u8d77\u53c2\u52a0\u4e91\u539f\u751f\u5927\u6570\u636e\u7814\u8ba8\u4f1a\uff0c\u4e86\u89e3\u4e0e\u81ea\u5efa\u5927\u6570\u636e\u5e73\u53f0\u76f8\u6bd4\uff0cAmazon EMR\u662f\u5982\u4f55\u5e2e\u60a8\u8282\u7701 56% \u7684\u8fd0\u8425\u6210\u672c\u7684\u3002\u501f\u52a9Amazon EMR\uff0c\u60a8\u53ef\u4ee5\u5728\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u5e76\u672b\u589e\u52a0\u751a\u81f3\u51cf\u5c11\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u4f7f\u7528EMR Serverless, EMR on EKS\u7b49\u6700\u65b0\u6258\u7ba1\u670d\u52a1\u6765\u652f\u6301\u4e0d\u65ad\u589e\u957f\u7684\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u9700\u6c42\uff0c\u4ece\u800c\u4f7f\u60a8\u7684\u4e1a\u52a1\u8131\u9896\u800c\u51fa\u3002</p> <ul> <li>\u4e86\u89e3Amazon EMR\u7684\u6700\u65b0\u4ea7\u54c1\u4fe1\u606f\uff0c\u5305\u62ec\u5982\u4f55\u5728Amazon Elastic Kubernetes Service(Amazon EKS)\u5bb9\u5668\u73af\u5883\u6216\u8005 Serverless\u5168\u6258\u7ba1\u73af\u5883\u4e2d\u4f7f\u7528Amazon EMR\u3002</li> <li>\u521d\u6b65\u4e86\u89e3Data on EKS, \u5305\u62ec\u5982\u4f55\u4f7f\u7528Terraform\u84dd\u56fe\u6a21\u677f\u6765\u7b80\u5316DevOps\u8fd0\u7ef4\u4efb\u52a1\u7b49\u3002</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#_1","title":"\u65b0\u8d8b\u52bf","text":"<ul> <li>Always share data</li> <li>Metadata-driven data fabric</li> <li>Data-centric AI</li> <li>Business-composedD&amp;A</li> <li>Context-enriched analysis</li> <li>Adaptive AI systems</li> <li>Connected governance</li> <li>Vendor and region ecosystems</li> <li>Decision-centricD&amp;ADecision-centricD&amp;A</li> <li>AI risk management</li> <li>Expansion to the edge</li> <li>Skills and literacy shortfall</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#_2","title":"\u4e0b\u4e00\u4ee3\u4ee3\u6570\u636e\u5206\u6790\u67b6\u6784","text":"<ul> <li> <p>\u6570\u636e\u670d\u52a1</p> <ul> <li>Augmented Analytics</li> <li>Continuous Intelligence</li> <li>Conversational Analytics</li> <li>Data Centric AI</li> </ul> </li> <li> <p>\u8ba1\u7b97</p> </li> </ul> <p></p> <ul> <li> <p>\u5b58\u50a8</p> <ul> <li>\u5bf9\u8c61\u5b58\u50a8 S3</li> </ul> </li> <li> <p>\u5206\u5e03\u5f0f\u8fb9\u7f18\u57fa\u7840\u8bbe\u65bd</p> <ul> <li></li> </ul> </li> <li> <p>\u589e\u5f3a\u6570\u6910\u6cbb\u7406</p> <ul> <li>\u6570\u636e\u76ee\u5f55\uff1a AWS Glue data catalog</li> <li>\u6570\u636e\u5b89\u5168: AWS Lake Formation</li> <li>\u6570\u636e\u4e3b\u6743: Amazon Data Zone</li> <li>\u6570\u636e\u8d28\u91cf: AWS Glue data Quality</li> </ul> </li> </ul> <p></p>"},{"location":"chap12/2aws_emr_20230421/#emr","title":"EMR \u90e8\u7f72\u6a21\u5f0f","text":"<p>\u81ea\u7531\u9009\u62e9\u6700\u4f73\u6027\u4ef7\u6bd4\u7684\u5b9e\u4f8b\u6765\u8fd0\u884c\u5de5\u4f5c\u8d1f\u6230</p> <p></p> <p>\u5728\u6258\u7ba1\u5bb9\u5668\u670d\u52a1 EKS \u5185\u81ea\u52a8\u5b8c\u6210\u96c6\u7fa4\u521b\u5efa\uff0c\u7ba1\u7406\uff0c\u6269\u7f29\u5bb9\u6267\u884cSpark\u4efb\u52a1</p> <p></p> <p>\u5728\u60a8\u81ea\u5df1\u7684\u6570\u636e\u4e2d\u5fc3\u90e8\u99a8\u3001\u7ba1\u7406\u3001\u8fd0\u7ef4EMR\u5982\u5728\u4e91\u4e0a\u4e00\u6837\u8f7b\u677e</p> <p></p> <p>\u65e0\u9700\u7ba1\u7406\u548c\u8fd0\u7ef4\uff0c\u5728\u4e91\u7aef\u4e5f\u80fd\u6267\u884cPB\u7ea7\u522b\u7684\u5927\u6578\u636e\u5206\u6790\u670d\u52a1</p> <p></p> <p>Spark\u529f\u80fd\u589e\u5f3a</p> <ul> <li>\u52a8\u6001Executor\u8d44\u6e90\u5206\u914d</li> <li>\u81ea\u9002\u5e94Join\u65b9\u5f0f\u9009\u62e9</li> <li>\u52a8\u6001\u88c1\u526a\u6570\u6398</li> <li>\u7b97\u5b50\u4f18\u5316</li> <li>\u63d0\u524d\u5206\u914d Worker \u8282\u70b9</li> <li>\u667a\u80fd\u8fc7\u6ffe</li> <li>\u4e95\u884c/ \u5f02\u6b65\u521d\u59cb\u5316</li> <li>\u904a\u514d\u91cd\u590d\u626b\u63cf\u6578\u636e</li> <li>\u9884\u5148\u83b7\u53d6\u6577\u636e</li> <li>\u667a\u80fd\u9009\u62e9 Broadcast Join</li> <li>\u7d71\u8ba1\u63a8\u65ad</li> <li>\u4f18\u5316\u5143\u6570\u62db\u53d6\u65b9\u5f0f</li> </ul> <p>Presto/Trino \u529f\u80fd\u589e\u5f3a</p> <ul> <li>Spot\u4e2d\u65ad\u5904\u7406(Presto)</li> <li>\u6539\u8fdb\u5173\u8054\u7684\u987a\u5e8f\u53ca\u65b9\u6cd5</li> <li>\u901a\u8fc7Lake Formation\u8fdb\u884c\u5b89\u5168\u8bbf\u95ee\u63a7\u5236(Presto)</li> <li>\u652f\u6301Iceberg\u53caDelta(Trino)</li> <li>\u5bb9\u9519\u6267\u884c(Trino)</li> <li>\u5229\u7528HDFS\u5b58\u50a8\u68c0\u67e5\u70b9\u6570\u636e (Trino)</li> </ul> <p>Hive \u529f\u80fd\u589e\u5f3a</p> <ul> <li>Zero-rename \u6570\u636e\u5199\u5165</li> <li>\u5143\u6570\u636e MSCK \u4f18\u5316</li> <li>Parquet \u6a21\u5757\u52a0\u5bc6</li> <li>\u901a\u8fc7Lake Formation\u8fdb\u884c\u6743\u9650\u7ba1\u7406</li> <li>\u5728Amazon EMR 6.9\u652f\u6301Iceberg</li> <li>\u96c6\u6210300\u591a\u4e2a\u5173\u952e Bug,\u65b0\u7279\u6027</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#managed-scaling","title":"Managed Scaling \u529f\u80fd\u6982\u8ff0","text":"<p>\u901a\u8fc7\u81ea\u52a8\u8c03\u6574\u96c6\u7fa4\u89c4\u6a21\u964d\u4f4e 60% \u7684\u6210\u672c</p> <ul> <li>\u6301\u7eed\u6539\u8fdb\u7684 EMR \u6258\u7ba1\u7b84\u6cd5\u4e3a\u60a8\u63d0\u4f9b\u5b8c\u6574\u7684\u6258\u7ba1\u4f53\u9a8c</li> <li>\u901a\u8fc7Managed scaling\u83b7\u5f97\u9ad8\u7cbe\u5ea6\u6307\u6807</li> <li>\u53ea\u9700\u914d\u9748\u6700\u5c0f/\u6700\u5927\u6210\u672c\u9650\u5236</li> <li>\u76f8\u6bd4 AutoScaling\u63d0\u4f9b\u66f4\u591a\u6578\u636e\u70b9\u548c\u66f4\u5feb\u901f\u7684\u54cd\u5e94</li> <li>\u89e3\u7ea620-60\u7684\u6210\u672c</li> </ul> <p>\u5168\u9762\u7684\u5b89\u5168\u529f\u80fd</p> <ul> <li>\u9694\u79bb<ul> <li>VPC</li> <li>\u79c1\u6709\u5b50\u7f51</li> <li>\u5b89\u5168\u7ec4</li> </ul> </li> <li>\u8eab\u4efd\u9a8c\u8bc1<ul> <li>LDAP</li> <li>Kerberos</li> <li>Amazon SSO (EMR Studio)</li> <li>Amazon IAM (EMR Studlo)</li> </ul> </li> <li>\u6388\u6743<ul> <li>\u96c6\u7fa4IAM\u89d2\u8272</li> <li>AM Execution Role</li> <li>FGAC \u4f7f\u7528 Apache Ranger</li> <li>FGAC \u4f7f\u7528 Amazon Lake Formation</li> </ul> </li> <li>\u52a0\u5bc6<ul> <li>\u5b58\u50a8\u540e\u52a0\u5bc6</li> <li>\u4f20\u8f93\u4e2d\u52a0\u5bc6</li> <li>\u79d8\u94a5\u7ba1\u7406</li> </ul> </li> <li>\u5ba1\u8ba1<ul> <li>\u4f7f\u7528 Ranger Amazon CloudWatch Logs\u8fdb\u884c\u5ba1\u8ba1</li> <li>\u4f7f\u7528 Amazon Lake Formation\u901a\u8fc7 Amazon Cloudtrail \u8fdb\u884c\u5ba1\u8ba1</li> </ul> </li> </ul>"},{"location":"chap12/2aws_emr_20230421/#_3","title":"\u591a\u79df\u6237\u5171\u4eab\u96c6\u7fa4","text":"<p>\u7528\u6237\u8fd0\u884c\u89d2\u8272: User1 \u53ef\u4ee5\u8bbf\u95ee Stream1, Bucket1 and Table1</p> <p></p> <p>Lake Formation\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6743\u9650\u7ba1\u63a7</p> <p></p>"},{"location":"chap12/2aws_emr_20230421/#_4","title":"\u6784\u5efa\u667a\u80fd\u6e56\u4ed3\u67b6\u6784","text":"<p>\u6570\u636e\u96c6\u6210</p> <ul> <li>\u57fa\u4e8eCDC\u6280\u672f\uff0c\u63d0\u4f9b\u4e0d\u4fbf\u5165\u4e1a\u52a1\u7cfb\u7edf\u7684\u4f01\u4e1a\u5438\u5b9e\u65f6\u6570\u636e \u540c\u6b65\u670d\u52a1\uff0c\u4fdd\u969c\u6570\u636e\u65f6\u996e\u6027\u3001\u53ef\u7528\u6027\uff1b</li> <li>\u57fa\u4e8eWAI\u67b6\u6784\u4e0b\u7684CKP\u5f02\u5e38\u81ea\u52a8\u4fdd\u5b58\u6280\u672f\uff0c\u5b9e\u73b0\u65ad\u70b9\u7eed \u4fbf\uff0c\u9762\u5bf9\u590d\u7684\u7f51\u7edc\u72b6\u51b5\uff0c\u4e5f\u80fd\u4fdd\u8bc1\u81f4\u636e\u4f20\u8f93\u5b9a\u6027\uff1a</li> <li>\u63d2\u4ef6\u5f0f\u80fd\u529b\u6269\u5c55\uff0c\u5feb\u901f\u9001\u4ee3\u6570\u77ed\u96c6\u6210\u9500\u529b\u548c\u6570\u8d77\u4e60\u9053\u9762 \u8303\u56f4</li> </ul> <p>\u6570\u636e\u5efa\u6a21</p> <ul> <li>\u652f\u6301\u903b\u8f91\u6a21\u578b\u3001\u7269\u7406\u6a21\u578b\u8bbe\u8ba1\u4fdd\u969c\u5efa\u6a21\u6d41\u7a0b\u89c4\u8303\u53ef\u63a7</li> <li>\u652f\u6301\u6a21\u578b\u9006\u884c\u5de5\u7a0b\uff0c\u5feb\u901f\u5bb9\u7eb3\u7ba1\u7406\u4f01\u4e1a\u5b58\u91cf\u6570\u636e\u6a21\u578b</li> <li>\u878d\u5408\u591a\u4e2a\u884c\u4e1a\u6700\u5065\u5b9e\u8df5\u65b9\u6cd5\u8bba\u63d0\u5347\u5efa\u6a21\u6548\u7387\uff1a</li> </ul> <p>\u6570\u636e\u5f00\u53d1</p> <ul> <li>\u4ea4\u6301WEB SQL\u7684\u53ef\u89c6\u5316\u79bb\u7ebf/\u5b9e\u65f6\u4efb\u52a1\u5f00\u53d1\uff0c\u964d\u4f4e\u7528\u6237\u5b66\u4e60\u6210\u672c\uff1a</li> <li>\u591a\u79cd\u4efb\u52a1DAG\u7ec4\u5c14\u5f62\u5f0f\uff0c\u5b9e\u73b0\u8de8\u6d41\u7a0b\uff0c\u8de8\u9879\u76ee\u4efb\u52a1\u4f9d\u8d56\uff0c\u65b9\u4fbf\u652f\u6301\u591a\u79cd\u4e1a\u52a1\u573a\u5177</li> <li>\u4e30\u5bcc\u7684\u5927\u81f4\u5927\u6570\u636e\u7ec4\u4ef6\uff0c\u6839\u8d28\u8d44\u6e90\u73b0\u72b6\u7075\u6d3b\u5b9e\u539f\u591a\u79cd\u4efb\u52a1\uff0c\u8d44\u6e90\u5229\u7528\u7387\u66f4</li> <li>\u652f\u6301\u6570\u636e\u7684\u5f00\u53d1\u4e0e\u751f\u4ea7\u73af\u5883\u9694\u79bb\u3001\u591a\u4eba\u534f\u540c\u5f00\u53d1\u3001\u66f4\u5b89\u5168\u3001\u66f4\u9ad8\u6548\uff1a</li> </ul> <p>\u6570\u636e\u8fd0\u7ef4</p> <ul> <li>\u6570\u636e\u5904\u7406\u4efb\u52a1\u4ee5DAG\u7ec4\u7ec7\u4e95\u76d1\u63a7\u3001\u4efb\u52a1\u4fee\u590d\u91cd\u8dd1\u3001\u6682\u505c\u3001Kill\u7b49\u64cd\u4f5c\u66f4\u4f18\u96c5</li> <li>\u5b8c\u5907\u7684\u544a\u8b66\u4f53\u7cfb\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u544a\u8b66\u89c4\u5219\u548c\u4e30\u5bcc\u7684\u65e5\u5fd7\u4fe1\u606f\uff0c\u63d0\u9ad8\u8fd0\u7ef4\u6548\u7387\uff1a</li> </ul> <p>\u6570\u636e\u670d\u52a1</p> <ul> <li>\u62d6\u62fd\u5f0f\u5de5\u4f5c\u6d41\u7f16\u6392\uff0c\u5b9e\u73b0\u590d\u6742\u7684API\u7684\u573a\u666f</li> <li>\u7edf\u4e00\u7684\u4f01\u4e1a\u6570\u636e\u5171\u4eab\u670d\u52a1\uff0c\u4e25\u683c\u7ba1\u63a7\u6570\u636e\u4f7f\u7528\u6743\u9650</li> <li>\u591a\u89c6\u89d2\u76d1\u63a7\u53ca\u5206\u6790\u670d\u52a1\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u9ad8\u6548\u8bc4\u4f30\u6570\u636e\u8be2\u4ea7\u7684\u4ef7\u503c\uff1b</li> </ul> <p>\u6570\u636e\u8d28\u91cf</p> <ul> <li>\u8986\u76d6\u6570\u636e\u8d44\u4ea7\u5316\u5168\u6d41\u7406\u8fdb\u884c\u8d28\u7f6e\u76d1\u7ba1\u548c\u68c0\u9a8c\uff0c\u4fdd\u969c\u6570\u636e\u5b8c\u6574\u6027\u3001\u6709\u6548\u6027\u3001\u53ca\u65f6\u6027\u3001\u4e00\u81f4\u6027\u3001\u51c6\u786e\u6027\u3001\u552f\u4e00\u6027\uff1b</li> <li>\u5185\u7f6e\u8d28\u91cf\u68c0\u6d4b\u89c4\u5219\u6a21\u677f\u4e95\u652f\u6301\u81ea\u5b9a\u4e49\u89c4\u5219\uff0c\u4f7f\u8d28\u91cf\u68c0\u67e5\u573a\u666f\u66f4\u4e30\u5bcc</li> <li>\u652f\u6301\u4e0eETL\u4efb\u52a1\u5173\u8054\u6267\u884c\u8d28\u91cf\u68c0\u67e5\uff0c\u53ca\u65f6\u53d1\u73b0\u95ee\u9898\u6570\u636e\uff0c\u51cf\u5c11\u6570\u636e\u6c61\u67d3\uff1a</li> </ul> <p>\u6570\u636e\u5b89\u5168</p> <p>\u8d2f\u7a7f\u6570\u636e\u8d44\u4ea7\u5316\u5168\u573a\uff0c\u63d0\u4f9b\u5bf9\u9690\u79c1\u6570\u636e\u7684\u8131\u654f\u6743\u9650\u7ba1\u7406\u548c\u5b89\u5168\u5ba1\u8ba1\u7b49\u591a\u79cd\u6570\u636e\u5b89\u5168\u7ba1\u7406\u5168\u65b9\u4f4d\u4fdd\u969c\u81f4\u636e\u7684\u5b89\u5168\u8fd0\u4f5c</p>"},{"location":"chap12/2aws_emr_20230421/#_5","title":"\u5ba2\u6237\u4e1a\u52a1\u8303\u56f4\u53ca\u6570\u636e\u5206\u6790\u573a\u666f","text":"<ul> <li>\u4e1a\u52a1\u8303\u56fd</li> </ul> <p>\u5bb9\u6237\u662f\u5e7f\u544a\u4e2d\u95f4\u73af\u8282\u670d\u52a1\u5546\uff0c\u5c06\u5e7f\u544a\u63a8\u9001\u5230\u7ec8\u7aef\u6295\u653e\u8bbe\u5907\u3002\u4e3b\u8981\u662f\u5bf9\u6309\u4e0a\u6e38\u5e7f\u544a\u63d0\u4f9b\u5546\uff0c\u548c\u4e0b\u6e38\u8bbe\u5907\u6295\u653e\u5546\u3002</p> <ul> <li>\u6280\u672f\u8bbe\u5907</li> </ul> <p>\u6355\u83b7\u5e7f\u544a\u63a5\u53d7\u548c\u63a8\u9001\u7684\u6570\u636e\uff0c\u5e76\u9488\u5bf9\u5e7f\u544a\u63a8\u9001\u6548\u7387\uff0c\u9891\u6b21\u7b49\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002\u4ee5\u53ca\u5404\u4e2a\u5e7f\u544a\u7ebf\u8def\u7684\u6210\u672c\u5206\u64d4\u3002</p> <p></p>"},{"location":"chap12/2aws_emr_20230421/#_6","title":"\u65b9\u6848\u4f18\u52bf&amp;\u5ba2\u6237\u6536\u76ca","text":"<ul> <li>\u5b66\u4e60\u6210\u672c\u4f4e\uff1a\u5728\u901a\u8fc7\u4e00\u6574\u5929\u7684hands on\u57f9\u8bad\uff0c\u5ba2\u6237\u7b2c\u4e8c\u5929\u5c31\u5f00\u59cb\u6d4b\u8bd5\uff0c\u7b2c\u4e8c\u5468\u5c31\u5b9e\u9645\u5728\u751f\u4ea7\u73af\u5883\u4e0a\u7ebf</li> <li>\u90fd\u7f72\u4fbf\u6377\uff1a\u5728\u591a\u73af\u5883\u4f7f\u7528\u4e2d\uff0c\u90fd\u7f72\u65f6\u95f4\u6210\u672c\u4f4e</li> <li>\u4f7f\u7528\u6210\u672c\u4f4e\uff1a\u9488\u5bf9\u4f4e\u9891\u7387\u7684ETL\u5de5\u4f5c\uff0cEMR serverless\u6709\u6548\u964d\u4f4e\u4f7f\u7528\u6210\u672c</li> <li>\u8d44\u6e90\u5f39\u6027\uff1a\u9488\u5bf9\u4e0d\u540cJob\uff0c\u8d44\u6e90\u5f39\u6027\u5206\u914d\uff0c\u5341\u5206\u4fbf\u6377\u3002\u964d\u4f4e\u5ba2\u6237\u9884\u4f30\u8d44\u6e90\u548c\u51c6\u5907\u8d44\u6e90\u7684\u65f6\u95f4</li> </ul> <ul> <li>\u6839\u672c\u4e0a\u89e3\u51b3\u5ba2\u6237\u6570\u636e\u9644\u9ad8\uff0c\u6210\u672c\u5206\u62c5\u7684\u9700\u6c42</li> <li>\u8fbe\u5230\u5ba2\u6237\u7684\u964d\u672c\u589e\u6548\u7684\u9884\u671f\uff0c\u964d\u672c70%\u4ee5\u4e0a</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#_7","title":"\u5ba2\u6237\u5f53\u524d\u67b6\u6784","text":"<ul> <li>\u4e3b\u4e1a\u52a1\uff0c\u4f9d\u7136\u4f7f\u7528EMR On EC2\u6267\u884clong running\u4efb\u52a1\u3002</li> <li>\u5b50\u4e1a\u52a1\uff0c\u4f7f\u7528EMR Serverless + Athena\u7684\u65b9\u6848</li> <li>\u4e34\u65f6\u6027\u4efb\u52a1\uff0c\u4f7f\u7528Athena\u5b8c\u6210\u67e5\u8be2</li> <li>\u5143\u6570\u636e\u901a\u8fc7glue catalog\u7ba1\u7406</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#amazon-emr-serverless","title":"Amazon EMR Serverless \u65e0\u9700\u7ba1\u7406\u8fd0\u7ef4\u96c6\u7fa4","text":"<ul> <li>\u6240\u9700\u7248\u672c\u53ef\u968f\u610f\u5207\u6362(EMR 6.6+)</li> <li>\u81ea\u52a8\u6269\u7f29\u65e0\u9700\u731c\u6d4b\u6240\u9700\u8d44\u6e90</li> <li>\u6210\u672c\u4f18\u5316\u66f4\u7ec6\u9897\u7c92\u5ea6\u6269\u7f29\u8d44\u6e90</li> <li>\u6027\u80fd\u4f18\u5316</li> <li>\u591a\u53ef\u7528\u533a\u57df(AZ)\u8bbe\u8ba1</li> <li>\u81ea\u52a8\u5f00\u59cb\u548c\u505c\u6b62\u4efb\u52a1</li> <li>\u96c6\u6210Cloudwatch\u76d1\u6d4b\u5e94\u7528</li> <li>\u96c6\u6210Apache Airflow</li> <li>\u81ea\u5b9a\u4e49\u955c\u50cf</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#emr-serverless","title":"EMR Serverless \u6838\u5fc3\u6982\u5ff5","text":"<p>\u4efb\u52a1</p> <ul> <li>\u4ee5Spark\u5e94\u7528\u4e3a\u5355\u4f4d</li> <li>\u591a\u4e2a\u4efb\u52a1\u53ef\u4ee5\u53d1\u5e03\u5230\u540c\u4e00\u4e2a\u5e94\u7528</li> <li>\u53ef\u4ee5\u5728\u4efb\u52a1\u5c42\u9762\u63a7\u5236\u6743\u9650</li> </ul> <p>\u5de5\u4f5c\u8282\u70b9</p> <ul> <li>\u5de5\u4f5c\u8282\u70b9\u662f\u6700\u5c0f\u5355\u4f4d\u7528\u4ee5\u6267\u884c\u60a8\u7684\u5de5\u4f5c\u8d1f\u8f7d</li> <li>\u5de5\u4f5c\u8282\u70b9\u8fd0\u884c\u9009\u62e9\u7684 Spark \u6216 Hive \u7248\u672c</li> <li>\u60a8\u53ef\u4ee5\u6539\u53d8\u5de5\u4f5c\u8282\u70b9\u7684\u914d\u7f6e(\u5185\u5b58\uff0cVCPU)\u6765\u63a7\u5236\u5176\u6027\u80fd</li> </ul> <p>\u9884\u521d\u59cb\u5316\u8282\u70b9</p> <ul> <li>\uff08\u53ef\u9009) \u8bbe\u7f6e\u9884\u521d\u59cb\u5316\u5de5\u4f5c\u8282\u70b9</li> <li>\u4f18\u70b9\uff1a\u4efb\u52a1\u53ef\u4ee5\u7acb\u5373\u542f\u52a8\u65e0\u9700\u7b49\u5f85</li> <li>\u5e2e\u52a9\u60a8\u7ef4\u62a4\u7ba1\u7406\u4e00\u4e2a\u9884\u70ed\u7684\u8d44\u6e90\u6c60\u968f\u65f6\u6267\u884c\u4efb\u52a1</li> <li>\u7f3a\u70b9\uff1a\u9700\u8981\u5bf9\u4e0e\u9884\u521d\u59cb\u5316\u8282\u70b9\u8d44\u6e90\u540c\u6837\u4ed8\u8d39</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#emr-serverless_1","title":"EMR Serverless \u5de5\u4f5c\u793a\u610f\u56fe","text":"<p>EMR\u90e8\u7f72\u6a21\u5f0f\u6210\u672c\u6bd4\u8f83</p> <p></p>"},{"location":"chap12/2aws_emr_20230421/#amazon-emr-on-eks","title":"Amazon EMR on EKS","text":"<p>Consolidate analytics workloads with other workloads on Amazon EKS</p> <ul> <li>Simplify infrastructure management</li> <li>Consolidate multiple versions of Spark on same EKS cluster and simplify Spark application upgrades</li> <li>Add Multi-AZ resiliency Choose serverless with AWS Fargate on Amazon EKS</li> <li>Start jobs quickly, no cluster provisioning delays</li> </ul> <p></p>"},{"location":"chap12/2aws_emr_20230421/#compute-cost-optimization","title":"Compute cost optimization","text":"<ul> <li>Amazon EC2 Spot\uff1a up to 90% off compared to on-demand pricing</li> <li>AWS Savings Plans\uff1a up to 72% for committed compute usage</li> <li>Auto Scaling\uff1a based on job-level usage/request</li> <li>Arm-based CPU\uff1a 19% performance boost &amp; 15% cost reduction running on Graviton3 vs. Graviton2</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#runtime-performance-impacts-costs","title":"Runtime performance impacts costs","text":"<p>Applications finish faster, resulting in lower TC as well as faster time to insights</p>"},{"location":"chap12/2aws_emr_20230421/#amazon-emr-on-amazon-eks","title":"Amazon EMR on Amazon EKS","text":"<p>Amazon EMR on Amazon EKS</p> <ul> <li>individual queries can run over 10x faster.</li> <li>Faster Application runtime reduces costs</li> <li>Default Spark configurations to optimize application performance based on 10 years' experience of running workloads at all scale factors automatically applied to your application</li> </ul> <p>Auto Pod Tuning</p> <p>Auto-tuning workloads to improve performance, save costs and increase resiliency</p> <ul> <li>Automatically adjust pod sizes based on real-time and historic CPU / Memory utilization</li> <li>Minimize out of memory exceptions and improve Spark job resiliencies</li> <li>Avoid the need to manually tune driver, executors resources</li> <li>Save costs without performance penalty</li> </ul>"},{"location":"chap12/2aws_emr_20230421/#managed-apache-flink","title":"Managed Apache Flink","text":"<p>Managing and Scaling your Apache Flink Applications become easier</p> <ul> <li>Consolidate your Flink applications under a single EKS infrastructure</li> <li>Autoscales based on SLAs on your upstream data source (eg. Kafka, Kinesis) and resource usage by your Flink application</li> <li>100% compatible with open source Apache Flink</li> <li>Open to customers to configure their Flink applications just like open source Flink</li> <li>Frequent updates of Flink version to support new feature</li> </ul> <p></p>"},{"location":"chap12/2aws_emr_20230421/#amazon-emr-on-amazon-eks_1","title":"Amazon EMR on Amazon EKS","text":"<ul> <li>Consolidate compute across the organization to optimize cost</li> <li>Allocate resources by team, application, or job to meet performance requirements</li> <li>Start jobs quickly by taking advantage of existing capacity or using AWS Fargate</li> <li>Run highly available data processing workloads across multiple availability zones</li> </ul> <p>Data on EKS Focus Areas</p> <ul> <li>Data Processing &amp; Analytics </li> <li>AI/ML</li> <li>Distributed Databases</li> <li>Streaming Platforms</li> <li>Distributed Query Engines</li> <li>Job &amp; Workflow Schedulers</li> </ul> <p></p> <p>Cluster add-ons</p> <p></p> <p>Multiple environments</p> <p></p> <p>Karpenter scale-up</p> <p>HPA/Application Pending pods</p> <p></p> <p>Provisioning and scheduling decisions</p> <ul> <li>Early binding to provisioned nodes vs. placeholder instances</li> <li>Remove scheduler version dependency</li> </ul>"},{"location":"chap2/2Kinesis_data_collection/","title":"L1 Collections - Kinesis DataStream Overview","text":""},{"location":"chap2/2Kinesis_data_collection/#1-collection-section-introduction-moving-data-into-aws","title":"1. Collection Section Introduction (Moving Data into AWS)","text":""},{"location":"chap2/2Kinesis_data_collection/#1-1-collection-introduction","title":"1-1 Collection Introduction","text":"<p>Real Time - Immediate actions</p> <ul> <li>Kinesis Data Streams (KDS)</li> <li>Simple Queue Service (SQS) </li> <li>Internet of Things (IoT)</li> </ul> <p>Near-real time - Reactive actions</p> <ul> <li>Kinesis Data Firehose (KDF) </li> <li>Database Migration Service (DMS) </li> </ul> <p>Batch - Historical Analysis </p> <ul> <li>Snowball </li> <li>Data Pipeline </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-2-aws-kinesis-overview","title":"1-2 AWS Kinesis Overview","text":"<ul> <li>Kinesis is a managed alternative to <code>Apache Kafka</code> </li> <li>Great for application logs, metrics, loT, clickstreams </li> <li>Great for \"real-time\" big data </li> <li>Great for streaming processing frameworks (Spark, NiFi, etc...) </li> <li>Data is automatically replicated synchronously to 3 AZ </li> </ul> <ul> <li>Kinesis Streams: low latency streamin ingest at Scale</li> <li>Kinesis Analytics: perform real-time analytics on streams using SQL SQL </li> <li>Kinesis Firehose: load streams into S3, Redshift  ElasticSearch &amp; Splunk</li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-3-kinesis","title":"1-3 Kinesis","text":"<p>What is the architecture surrounding Kinesis? </p> <p> </p> <ul> <li>The streams can take a lot of data from say click streams or IoT devices for example a connected bike or metrics and logs from your servers directly. So the streams will just ingest a lot of data </li> <li>You would like to analyze that there in real time maybe you're trying to compute a metric maybe build alerts for this you can use optionally the Amazon Kinesis Analytics service</li> <li>Kinesis Firehose can deliver your data to maybe an Amazon S3 bucket or an Amazon Redshift database, or Splunk, or ElasticSearch </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-4-kinesis-streams-overview","title":"1-4 Kinesis Streams Overview","text":"<ul> <li>Streams are divided in ordered Shards / Partitions </li> </ul> <ul> <li>Data retention is 24 hours by default, can go up to 7 days </li> <li>Ability to reprocess / replay data </li> <li>Multiple applications can consume the same stream </li> <li>Real-time processing with scale of throughput </li> <li>Once data is inserted in Kinesis, it can't be deleted (immutability) </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-5-kinesis-streams-shards","title":"1-5 Kinesis Streams Shards","text":"<ul> <li>One stream is made of many different shards </li> <li>Billing is per shard provisioned, can have as many shards as you want</li> <li>Batching available or per message calls. </li> <li>The number of shards can evolve over time (reshal / merge) \u2022</li> <li>Records are ordered per shard </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-6-kinesis-streams-records","title":"1-6 Kinesis Streams Records","text":"<ul> <li> <p>Data Blob: data being sent, serialized as bytes. Up to 1 MB. Can represent anything </p> </li> <li> <p>Record Key: </p> </li> <li> <p>sent alongside a record, helps to group records in Shards. <code>Same key = Same shard</code> </p> </li> <li>Use a highly distributed key to avoid the \"hot partition\" problem </li> <li>Sequence number: Unique identifer for each records put in shards. Added by Kinesis after ingestion</li> </ul> <p> </p>"},{"location":"chap2/2Kinesis_data_collection/#1-7-kinesis-data-streams-limits-to-know","title":"1-7 Kinesis Data Streams Limits to know","text":"<p>Producer</p> <ul> <li>1 MB/s or 1000 messages/s at write PER SHARD</li> <li>\"ProvisionedThroughputException\" otherwise </li> </ul> <p>Cosumer Classic:</p> <ul> <li>2MB/s at read <code>PER SHARD</code>, across all consumers</li> <li>5 API calls per second PER SHARD across all consumers</li> </ul> <p>Consumer ENHANCED Fan-Out </p> <ul> <li>2MB/s at read PER SHARD, PER ENHANCED CONSUMER </li> <li>No API calls needed (push model) </li> </ul> <p>Data Retention: </p> <ul> <li>24 hours data retention by default </li> <li>Can be extended to 7 days </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-8-kinesis-data-streams-handling-duplicates-for-producers","title":"1-8 Kinesis Data Streams \u2014 Handling Duplicates For Producers","text":"<ul> <li>Producer retries can create duplicates due to network timeouts </li> <li>Although the two records have identical data, they also have unique sequence numbers </li> <li>Fix: embed unique record ID in the data to de-duplicate on the consumer side </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-9-kinesis-data-streams-kinesis-data-streams-handling-duplicates-for-consumers","title":"1-9 Kinesis Data Streams \u2014 Kinesis Data Streams \u2014 Handling Duplicates For Consumers","text":"<ul> <li>Consumer retries can make your application read the same data twice </li> <li> <p>Consumer retries happen when record processors restart: </p> <ol> <li>A worker terminates unexpectedly </li> <li>Worker instances are added or removed </li> <li>Shards are merged or split </li> <li>The application is deployed </li> </ol> </li> <li> <p>Fixes: </p> <ul> <li>Make your consumer application idempotent </li> <li>If the final destination can handle duplicates, it's recommended to do it there </li> </ul> </li> </ul> <p>More info: </p> <p>https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html</p>"},{"location":"chap2/2Kinesis_data_collection/#1-10-cloudwatch-logs-subscriptions-filters-with-kinesis","title":"1-10 CloudWatch Logs Subscriptions Filters with Kinesis","text":"<ul> <li> <p>You can stream CloudWatch Logs into </p> <ul> <li>Kinesis Data Streams </li> <li>Kinesis Data Firehose </li> <li>AWS Lambda </li> </ul> </li> <li> <p>Using CloudWatch Logs Subscriptions Filters </p> </li> <li>You can enable them using the AWS CLI </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#1-11-cloudwatch-logs-subscription-filter-patterns-near-real-time-into-amazon-es","title":"1-11 CloudWatch Logs Subscription Filter Patterns Near Real Time into Amazon ES","text":"<p>CloudWatch Logs Subscriptions Filters Patterns Real Time Analytics</p> <p> </p>"},{"location":"chap2/2Kinesis_data_collection/#2kinesis-producers","title":"2\u3001Kinesis Producers","text":"<ul> <li> <p>Kinesis SDK</p> </li> <li> <p>SDK allows you to write code or use the CLI to directly send data into Amazon Kinesis streams</p> </li> <li> <p>Kinesis Producer Library (KPL) </p> <ul> <li>Better Code </li> </ul> </li> <li> <p>Kinesis Agent </p> </li> </ul> <p>The Kinesis agent is a linux program that runs on your server so remember that it's an agent that runs on servers and it basically allows you to get a log file for example and send that reliably into the Amazon Kinesis streams </p> <ul> <li>3rd party libraries: Spark, Log4J Appenders, Flume, Kafka Connect, NiFi...</li> </ul> <p> </p>"},{"location":"chap2/2Kinesis_data_collection/#2-1-kinesis-producer-sdk-putrecords","title":"2-1 Kinesis Producer SDK - PutRecord(s)","text":"<ul> <li>APIs that are used are PutRecord (one) and PutRecords (many records) </li> <li>PutRecords uses batching and increase throughput =&gt; less HTTP requests </li> <li>ProvisionedThroughputExceeded if we go over the limits </li> <li><code>+ AWS Mobile SDK</code>: Android, iOS, etc... </li> <li>Use case: low throughput, higher latency, API, AWS Lambda</li> </ul> <p>Managed AWS sources for Kinesis Data Streams: </p> <ul> <li>CloudWatch Logs </li> <li>AWS IoT </li> <li>Kinesis Data Analytics </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#2-2-aws-kinesis-api-exceptions","title":"2-2 AWS Kinesis API Exceptions","text":"<p><code>ProvisionedThroughputExceeded Exceptions</code></p> <ul> <li>Happens when sending more data (exceeding MB/s or TPS for any shard) </li> <li>Make sure you don't have a hot shard (such as your partition key is bad and too much data goes to that partition) </li> </ul> <p>Solution</p> <ul> <li> <p>Retries with backoff: </p> <ul> <li>That means that you will retry after maybe 2s and if it doesn't work you will try to 4s and then after 8s </li> </ul> </li> <li> <p>Increase shards (scaling) </p> <ul> <li>It might be good to increase the much the amount of scaling you can do </li> </ul> </li> <li> <p>Ensure your partition key is a good one </p> </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#2-3-kinesis-producer-library-kpl-aggrengation","title":"2-3 Kinesis Producer Library (KPL) Aggrengation","text":"<ul> <li>Easy to use and highly configurable C++ / Java library </li> <li>Used for building high performance, long-running producers </li> <li>Automated and configurable retry mechanism </li> <li>Synchronous or Asynchronous API (better performance for async) </li> <li>Submits metrics to CloudWatch for monitoring </li> <li> <p>Batching (both turned on by default) increase throughput, decrease cost: </p> <ul> <li>Collect Records and Write to multiple shards in the same PutRecords API call </li> <li>Aggregate increased latency <ul> <li>Capability to store multiple records in one record (go over 1000 records per second limit) </li> <li>Increase payload size and improve throughput (maximize 1 MB/s limit) \u2022 </li> </ul> </li> </ul> </li> <li> <p>Compression must be implemented the user </p> </li> <li>KPL Records must be de-coded with KCL or special helper library </li> </ul> <p> </p> <ul> <li>We can influence the bat Sy by introducing some delay with RecordMaxBufferedTime (default 100ms)</li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#2-4-kinesis-agent","title":"2-4 Kinesis Agent","text":"<ul> <li>Monitor Log files and sends them to Kinesis Data Streams</li> <li>Java-based agent, built on top of KPL</li> <li>Install in Linux-based server environments </li> </ul> <p>Features: </p> <ul> <li>Write from multiple directories and write to multiple streams </li> <li>Routing feature based on directory / log file </li> <li>Pre-process data before sending to streams  (single line, csv to json, log to jsOn\u2022\u2022\u2022) \u2022</li> <li>he agent handles file rotatiRp, checkpointing, and retry upon failures </li> <li>Emits metrics to CloudWatch for monitoring</li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#3kinesis-consumers","title":"3\u3001Kinesis Consumers","text":""},{"location":"chap2/2Kinesis_data_collection/#3-1-kinesis-consumers-classic","title":"3-1 Kinesis Consumers - Classic","text":"<ul> <li>Kinesis SDK </li> <li>Kinesis Client Library (KCL) </li> <li>Kinesis Connector Library </li> <li>3rd party libraries: Spark, Log4J Appenders, Flume, Kafka Connect...</li> <li>Kinesis Firehose </li> <li>AWS Lambda </li> <li>(Kinesis Consumer Enhanced Fan-Out discussed in the next lecture) </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#3-2-kinesis-consumer-sdk-getrecords","title":"3-2 Kinesis Consumer SDK - GetRecords","text":"<ul> <li>Classic Kinesis - Records are polled by consumers from a shard </li> <li>Each shard has 2 MB total aggregate throughput </li> <li>GetRecords returns up to 10MB of data (then throttle for 5 seconds) or up to 10000 records </li> <li>Maximum of 5 GetRecords API calls per shard per second = 200ms latency </li> <li>If 5 consumers application consume from the same shard,  means every consumer can  poll once a second and receive less than 400 KB/s </li> </ul> <p><code>More consumers =&gt; less throughput you will have per consumer</code></p> <p>So if we had consumer B and consumers C they will all share that limit of 2MB/s per shard and they will all share that limit of 5 get records API call per second. </p> <p>So it's really important to understand that and we'll see how Kinesis Enhance FanOut for consumers will solve that problem. </p> <p> </p>"},{"location":"chap2/2Kinesis_data_collection/#3-3-kinesis-client-library-kcl-de-aggregation","title":"3-3 Kinesis Client Library (KCL) &gt; de-aggregation","text":"<ul> <li>Java-first library but exists for other lanuages too (Golang, Python, Ruby, Node,.NET...) </li> <li>Read records from Kinesis produced with the KPL (de-aggregation) </li> <li>Share mutiple shards with multiple consumers in one \"group\", shard discovery \u2022</li> <li>Checpointing feature to resume progress </li> <li>Leverages DynamoDB for coordination and checkpointing (one row per shard) <ul> <li>Make sure you provision enough <code>WCU / RCU</code> (Write Capacit Unit/Read Capacity Unit) </li> <li>Or use On-Demand for DynamoDB </li> <li>Otherwise DynamoDBmay slow down KCL </li> <li>API of Record processors will Process the data </li> </ul> </li> </ul> <p>So how does checkpointing works and all the shard discovery? Well it basically uses an Amazon dynamoDB table to check point the progress over time and synchronize to see who is going to read which shard </p> <p>Exam Question: My KCL library is not reading fast enough even though there isn't a throughput in my Kinesis data stream what's the problem? </p> <p>Answer: the problem is that you probably have undellorovisioned your dynamodb table and therefore it cannot checkpoint fast enough and therefore it cannot consume fast enough.</p>"},{"location":"chap2/2Kinesis_data_collection/#3-4-kinesis-connector-library","title":"3-4 Kinesis Connector Library","text":"<ul> <li>Older Java library (2016), leverages the KCL library </li> <li>Write data to: <ul> <li>Amazon S3 </li> <li>DynamoDB </li> <li>Redshift </li> <li>ElasticSearch </li> </ul> </li> </ul> <p>Kinesis Firehose replaces the Connector Library for a few of these targets, Lambda for the others </p> <p> </p> <p>Connector library must be running on an EC2 instance for example for it to happen since an application whose sole purpose is to take data from Kinesis data streams and send it to all these destinations. </p>"},{"location":"chap2/2Kinesis_data_collection/#3-5aws-lambda-sourcing-from-kinesis","title":"3-5AWS Lambda sourcing from Kinesis","text":"<ul> <li>AWS Lambda can source records from Kinesis Data Streams </li> <li>Lambda consumer has a library to de-aggregate record from the KPL </li> <li> <p>Lambda can be used to run lightweight ETL to: </p> <ul> <li>Amazon S3 </li> <li>DynamoDB </li> <li>Redshift </li> <li>ElasticSearch </li> <li>Anywhere you want </li> </ul> </li> <li> <p>Lambda can be used to trigger notifications I send emails in real time</p> </li> <li>Lambda has a configurable batch size (more in Lambda section) </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#4kinesis-enhanced-fan-out","title":"4\u3001Kinesis Enhanced Fan Out","text":""},{"location":"chap2/2Kinesis_data_collection/#4-1-kinesis-enhanced-fan-out","title":"4-1 Kinesis Enhanced Fan Out","text":"<ul> <li>New game-changing feature from August 2018.</li> <li>Works with <code>KCL 2.0</code> and AWS Lambda (Nov 2018) </li> <li>Each Consumer get 2 ms/s of provisioned throughput per shard </li> <li>That means 20 consumers will get <code>40MB/s</code> per shard aggregated </li> <li>No more 2 MB/s limit </li> <li>Enhanced Fan Out: Kinesis pushes data to consumers over HTTP/2 </li> <li>Reduce latency (~70 ms) </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#4-2-enhanced-fan-out-vs-standard-consumers","title":"4-2 Enhanced Fan Out vs Standard Consumers","text":"<p>Standard consumers:</p> <ul> <li>Low number of consuming applications (1,2,3...) </li> <li>Can tolerate <code>~200</code> ms latency </li> <li>Minimize cost </li> </ul> <p>Enhanced Fan Out Consumers:</p> <ul> <li>Multiple Consumer applications for the same Stream </li> <li>Low Latency requirements <code>~70ms</code></li> <li>Higher costs (see Kinesis pricing page) </li> <li>Default limit of 5 consumers using enhanced fan-out per data stream </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#5kinesis-scaling","title":"5\u3001Kinesis Scaling","text":""},{"location":"chap2/2Kinesis_data_collection/#5-1-kinesis-operations-adding-shards","title":"5-1 Kinesis Operations \u2014 Adding Shards","text":"<ul> <li>Also called \"Shard Splitting\" </li> <li>Can be used to increase the Stream capacity (1 MB/s data in per shard) </li> <li>Can be used to divide a \"hot shard\" </li> <li>The old shard is closed and will be deleted once the data is expired </li> </ul> <ol> <li>We have shard 1, 2, and 3 in this example and they occupy the same space. </li> <li>Now shard 2 is very hot and we want to split it to increase throughput on this key space of shard </li> <li>So we're going to do a split operation what's going to happen is that there's gonna be shard 4 that has been created and shard 5 that're being created. </li> <li>And as you can see they're occupying the same space as shard 2 </li> <li>Because we have two shards we have two <code>2MB/s</code> on this space instead of 1MB/s then the other shard </li> <li>1 and 3 there remain the same. </li> <li>So shard 2 will be available as long as the data in it is not expired but when it's expired it will be gone. </li> </ol> <p>You can split as many shards as you want over time and increase your throughput this way. </p>"},{"location":"chap2/2Kinesis_data_collection/#5-2-kinesis-operations-merging-shards","title":"5-2 Kinesis Operations Merging Shards","text":"<ul> <li>Decrease the Stream capacity and save costs </li> <li>Can be used to group two shards with low traffic </li> <li>Old shards are closed and deleted based on data expiration </li> </ul> <ol> <li>Maybe shard 1 and 4 didn't get much traffic so we can merge them together and save some cost. </li> <li>So we're going to merge them together and it's becoming shard 6 </li> <li>Then shard 5 and 3 while they remain on the same the same the same as before. </li> </ol>"},{"location":"chap2/2Kinesis_data_collection/#5-3-kinesis-operations-auto-scaling","title":"5-3 Kinesis Operations Auto Scaling","text":"<ul> <li>Auto Scaling is not a native feature of Kinesis</li> <li>The API call to Change the number of shards is UpdateShardCount </li> <li>We can implement Auto Scaling with AWS Lambda </li> </ul> <p>https://aws.amazon.com/blogs/big-data/scaling-amazon-kinesis-data-streams-with-aws-application-auto-scaling/ </p> <p> </p>"},{"location":"chap2/2Kinesis_data_collection/#5-4-kinesis-scaling-limitations","title":"5-4 Kinesis Scaling Limitations","text":"<ul> <li>Resharding cannot be done in parallel. Plan capacity in advance </li> <li>You can only perform one esharding operation at a time and it takes a few seconds </li> <li>For 1000 shards, it takes 30K seconds(8.3 hours) to double the shards to 2000 </li> </ul> <p>You can't do the following</p> <ul> <li>Scale more than twice for each rolling 24-hour period for each stream </li> <li>Scale up to more than double your current shard count for a stream </li> <li>Scale down below half your current shard count for a stream </li> <li>Scale up to more than 500 shards in a stream </li> <li>Scale a stream with more than 500 shards down unless the result is fewer than 500 shards </li> <li>scale up to more than the shard limit for your account </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#6kinesis-security","title":"6\u3001Kinesis Security","text":"<ul> <li>Control access / authorization using IAM policies </li> <li>Encryption in flight using HTTPS endpoints </li> <li>Encryption at rest using KMS </li> <li>Client side encryption must be manually implemented (harder) </li> <li>VPC Endpoints available for Kinesis to access within VPC</li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#7aws-kinesis-data-firehose","title":"7\u3001AWS kinesis Data Firehose","text":"<ul> <li>Fully Managed Service, no administration </li> <li>Near Real Time (60 seconds latency minimum for non full batches) </li> <li>Load data into Redshift Ama2on S3 / ElasticSearch / Splunk </li> <li>Automatic scaling </li> <li>Supports many data formats </li> <li>Data Conversions from JSON to Parquet / ORC onl for S3) </li> <li>Data Transformation through AWS Lambda (ex: CSV =&gt; JSON) </li> <li>Supports compression when target is Amazon S3 (GZIP, ZIP and SNAPPY) </li> <li>Only GZIP is the data is further loaded into Redshift </li> <li>Pay for the amount of data going through Firehose </li> <li>Spark/KCL do not read from KDF </li> </ul> <p>Exam will trick you into thinking that Spark or the KCL can read from KDF(Kinesis data firehose) </p> <p>This is not the case. Spark streaming and Kinesis client library from fire hose they only read it from Kinesis data stream. </p>"},{"location":"chap2/2Kinesis_data_collection/#7-1-kinesis-data-firehose-diagram","title":"7-1 kinesis Data Firehose Diagram","text":""},{"location":"chap2/2Kinesis_data_collection/#7-2-kinesis-data-firehose-deliver-diagram","title":"7-2 Kinesis Data Firehose Deliver Diagram","text":"<p>Actually it goes through S3 and then there will be a copy command issued to put that data into Redshift. </p> <p>Exam asks you \"How do we get all the source data into an Amazon S3 bucket through consider a firehose?\" </p> <p>This is directly a feature from firehose. </p>"},{"location":"chap2/2Kinesis_data_collection/#7-3-firehose-buffer-sizing","title":"7-3 Firehose Buffer Sizing","text":"<ul> <li>Firehose accumulates records in a buffer </li> <li> <p>The buffer is flushed based on time and size rules </p> </li> <li> <p>Buffer Size (ex: 32MB): if that buffer size is reached, its flushed</p> </li> <li>BufferTime (ex: 2 minutes): if that time is reached, it's flushed </li> <li> <p>Firehose can automatically increase the buffer size to increase throughput </p> </li> <li> <p>High throughput \u2014&gt; Buffer Size will be hit </p> </li> <li>Low throughput =&gt; BufferTime will be hit </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#8kinesis-data-streams-vs-firehose","title":"8\u3001Kinesis Data Streams vs Firehose","text":""},{"location":"chap2/2Kinesis_data_collection/#8-1-streams","title":"8-1 Streams","text":"<ul> <li>Going to write custom code (producer / consumer)</li> <li>Real time (-200 ms latency for classic, \u201470 ms latency for enhanced fan-out) </li> <li>Must manage scaling (shard splitting / merging)</li> <li>Data Storage for 1 to 7 da s, replay capability, multi consumers </li> <li>Use with Lambda to insert data in real-time to ElasticSearch (for example) </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#8-2-firehose","title":"8-2 Firehose","text":"<ul> <li>Fully managed, send to S3, Splunk, Redshift, ElasticSearch </li> <li>Serverless data transformations with Lambda </li> <li>Near real time (lowest buffer time is 1 minute) </li> <li>Automated Scaling </li> <li>No data storage </li> </ul>"},{"location":"chap2/2Kinesis_data_collection/#9kinesis-data-streams-vs-firehose","title":"9\u3001Kinesis Data Streams vs Firehose","text":""},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/","title":"L2 [Exercise] Kinesis Firehose (PurchaseLogs/OrderLogs)","text":""},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#1part-one-create-kinesis-firehose-delivery-streams","title":"1\u3001Part One [Create Kinesis Firehose delivery streams]","text":"<p>Continously collect, transform, and load streaming data into destinations such as Amazon S3 and Amazon Redshift.</p> <p> </p> <ul> <li>Delivery stream name: PurchaseLogs</li> <li>Source: Direct PUT or other sources</li> </ul> <p>Choose this option to send records directly to the delivery stream, or to send records from AWS IoT, CloudWatch Logs, or CloudWatch Events.</p> <p> </p> <p> </p>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#1-1-choose-a-destination","title":"1-1 Choose a destination","text":"<ul> <li>S3 name: <code>kin-orderlogs</code></li> <li>Region: US-EAST-1</li> </ul>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#1-2-configure-settings","title":"1-2 Configure settings","text":"<p>Configure buffer, compression, logging, and IAM role settings for your delivery stream</p> <p>S3 buffer conditions:</p> <p>Firehose buffers incoming records before delivering them to your S3 bucket. Record delivery will be triggered once either of these conditions has been satisfied</p> <p> </p> <ul> <li>Enter a buffer size between 1-128 MB:  5</li> <li>Enter a buffer interval between 60-900 seconds: 60S (NEAR REAL TIME)</li> </ul> <p>Permissions IAM role:</p> <p>Default IAM role name with default policy: <code>firehose_delivery_role</code></p> <p> </p>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2part-two-create-ec2-and-attach-policy","title":"2\u3001Part two [Create EC2 and attach policy]","text":""},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2-1-step-1-choose-an-amazon-machine-image-ami","title":"2-1 Step 1: Choose an Amazon Machine Image (AMI)","text":"<p>Launch Amazon Linux AMI not the Linux 2 AMI because this comes with more AWS tools pre installed for us it makes life a little bit easier.</p> <p> </p> <p>Type: T2 micro</p>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2-2-step-2-configure-network-and-auto-assign-public-ip-for-it","title":"2-2 Step 2: Configure Network and Auto assign public ip for it","text":""},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2-3-step-3-create-new-key-pair-and-download","title":"2-3 Step 3: Create New key pair and download","text":"<p>Keypair Name:  JamData </p> <p> </p>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2-4-step-4-connect-to-your-linux-instance-using-an-ssh-client","title":"2-4 Step 4: Connect to Your Linux Instance using an SSH Client","text":"<pre><code>$ chmod 400 JamData.pem\n$ ssh -i \"JamData.pem\" ec2-user@100.26.107.74\nThe authenticity of host '100.26.107.74 (100.26.107.74)' can't be established.\nECDSA key fingerprint is SHA256:4DO4XuWMGeQKE4n7svfHr2T1wpGBQZu3DVurDchYPC8.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added '100.26.107.74' (ECDSA) to the list of known hosts.\n\n       __|  __|_  )\n       _|  (     /   Amazon Linux AMI\n      ___|\\___|___|\n\nhttps://aws.amazon.com/amazon-linux-ami/2018.03-release-notes/\n16 package(s) needed for security, out of 32 available\nRun \"sudo yum update\" to apply all updates.\n-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory\n[ec2-user@ip-172-16-1-121 ~]$\n</code></pre>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#2-5-step-5-assign-iam-role-for-it","title":"2-5 Step 5: Assign IAM role for it","text":"<ul> <li>Create new role attach to to instance EC2AdminAccess with full adminpolicy</li> </ul> <ul> <li>rolename\uff1a EC2AdminAccess</li> <li>Attach iam role to the EC2 instance</li> </ul>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3part-three-enable-kinesis-on-ec2-instance","title":"3\u3001Part Three [Enable Kinesis on EC2 instance]","text":""},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-1-step-1-install-aws-kinesis-agent","title":"3-1 Step 1: Install <code>aws-kinesis-agent</code>","text":"<pre><code>$ sudo yum install -y aws-kinesis-agent\n</code></pre>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-2-step-2-make-use-of-loggenerator","title":"3-2 Step 2: Make use of <code>LogGenerator</code>","text":"<pre><code>wget http://media.sundog-soft.com/AWSBigData/LogGenerator.zip\nunzip LogGenerator.zip\nchmod a+x LogGenerator.py\n</code></pre> <p><code>/var/log/cadabra/</code> The log will locate in this place from the code</p> <pre><code>sudo mkdir /var/log/cadabra/\n</code></pre>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-3-step-3-change-agentjson-for-aws-kinesis-agent","title":"3-3 Step 3: Change <code>agent.json</code> for <code>aws-kinesis-agent</code>","text":"<pre><code>$ cd /etc/aws-kinesis\n$ sudo vi agent.json\n\n{\n  \"cloudwatch.emitMetrics\": true,\n  \"kinesis.endpoint\": \"\",\n  \"firehose.endpoint\": \"firehose.us-east-1.amazonaws.com\",\n\n  \"flows\": [\n    {\n      \"filePattern\": \"/var/log/cadabra/*.log\",\n      \"deliveryStream\": \"PurchaseLogs\"\n    }\n  ]\n}\n</code></pre> <ul> <li><code>firehose.endpoint</code>: <code>\"firehose:us-east-1.amazonaws.com\"</code></li> <li>filePattern: <code>\"/var/log/cadabra/*.log\"</code></li> <li>deliveryStream:<code>\"PurchaseLogs\"</code></li> </ul>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-4-step-4-start-aws-kinesis-agent","title":"3-4 Step 4: Start <code>aws-kinesis-agent</code>","text":"<pre><code>$ sudo service aws-kinesis-agent start\naws-kinesis-agent startup                                  [  OK  ]\n$ sudo chkconfig aws-kinesis-agent on\n</code></pre>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-5-step-5-run-the-code-and-generate-logs","title":"3-5 Step 5: Run the code and generate logs","text":"<pre><code>$ cd\n$ sudo ./LogGenerator.py 500000\nWriting 500000 lines starting at line 0\n\nWrote 500000 lines.\n\n# check logs\n$ cd /var/log/cadabra/\n$ ls\n20200111-101057.log\n\n$ tail -f /var/log/aws-kinesis-agent/aws-kinesis-agent.log\n2020-01-11 10:11:17.036+0000 localhost (Agent.MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 152501 records parsed (16777082 bytes), and 50056 records sent successfully to destinations. Uptime: 120032ms\n2020-01-11 10:11:17.036+0000 localhost (Agent.MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Tailing is 27.924805 MB (29281475 bytes) behind.\n2020-01-11 10:12:17.036+0000 localhost (Agent.MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 304001 records parsed (29359855 bytes), and 218094 records sent successfully to destinations. Uptime: 180032ms\n...\n2020-01-11 10:16:17.035+0000 localhost (FileTailer[fh:PurchaseLogs:/var/log/cadabra/*.log].MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.tailing.FileTailer [INFO] FileTailer[fh:PurchaseLogs:/var/log/cadabra/*.log]: Tailer Progress: Tailer has parsed 500000 records (42036691 bytes), transformed 0 records, skipped 0 records, and has successfully sent 499500 records to destination.\n2020-01-11 10:16:17.035+0000 localhost (Agent.MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 500000 records parsed (42036691 bytes), and 499500 records sent successfully to destinations. Uptime: 420032ms\n</code></pre>"},{"location":"chap2/3Coll_Kinesis_Firehose_Exer/#3-6-step-6-check-s3-and-kinese-firehose-delivery-streams","title":"3-6 Step 6: Check S3 and Kinese Firehose delivery streams","text":"<p>S3 logs pushed in</p> <p> </p> <p>Firehose delivery streams cloudwatch</p> <p> </p>"},{"location":"chap2/4Coll_Kinesis_DS_Exer/","title":"L3 [Exercise] Kinesis Data Streams","text":""},{"location":"chap2/4Coll_Kinesis_DS_Exer/#1create-kinesis-stream","title":"1\u3001Create Kinesis stream","text":"<p>Kinesis stream name: CadabraOrders</p>"},{"location":"chap2/4Coll_Kinesis_DS_Exer/#1-1-shards","title":"1-1 Shards","text":"<p>A shard is a unit of throughput capacity. Each shard ingests up to <code>1MB/sec</code> and <code>1000 records/sec</code>, and emits up to <code>2MB/sec</code>. </p> <p>To accommodate for higher or lower throughput, the number of shards can be modified after the Kinesis stream is created using the API</p> <p> </p> <p>Number of shards: 1</p> <p>on the exam however how you would figure out how many shards you might need for a given application and it has a little reminder here that one shard only gives you <code>1MB/sec</code> of write capacity. <code>2MB/sec</code> of read capacity and up to  <code>1000 records/sec</code>.</p> <p> </p> <p> </p>"},{"location":"chap2/4Coll_Kinesis_DS_Exer/#2change-aws-kinesis-agent-config-file","title":"2\u3001Change <code>aws-kinesis-agent</code> config file","text":"<pre><code>$ cd /etc/aws-kinesis\n$ sudo vi agent.json\n\n{\n  \"cloudwatch.emitMetrics\": true,\n  \"kinesis.endpoint\": \"kinesis.us-east-1.amazonaws.com\",\n  \"firehose.endpoint\": \"firehose.us-east-1.amazonaws.com\",\n\n // \"awsAccessKeyId\": \"\",\n // \"awsAccessAccessKey\": \"\"\n\n  \"flows\": [\n    {\n      \"filePattern\": \"/var/log/cadabra/*.log\",\n      \"kinesisStream\": \"CadabraOrders\",\n      \"partitionKeyOption\": \"RANDOM\",\n      \"dataProcessingOptions\": [\n         {\n            \"optionName\": \"CSVTOJSON\",\n            \"customFieldNames\": [\"InvoiceNo\", \"StockCode\", \"Description\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\", \"Customer\", \"Country\"]\n         }\n      ]\n    },\n    {\n      \"filePattern\": \"/var/log/cadabra/*.log\",\n      \"deliveryStream\": \"PurchaseLogs\"\n    }\n  ]\n}\n</code></pre> <pre><code>$ sudo service aws-kinesis-agent restart\naws-kinesis-agent shutdown                                 [  OK  ]\naws-kinesis-agent startup                                  [  OK  ]\n</code></pre>"},{"location":"chap2/4Coll_Kinesis_DS_Exer/#3run-the-code-and-generate-logs","title":"3\u3001Run the code and generate logs","text":"<pre><code>$ cd\n\n#default 100\n$ sudo ./LogGenerator.py\nWriting 100 lines starting at line 500100\n\nWrote 100 lines.\n</code></pre> <pre><code>tail -f /var/log/aws-kinesis-agent/aws-kinesis-agent.log\n2020-01-11 11:45:00.499+0000 localhost (Agent.MetricsEmitter RUNNING) com.amazon.kinesis.streaming.agent.Agent [INFO] Agent: Progress: 300 records parsed (34824 bytes), and 100 records sent successfully to destinations. Uptime: 120081ms\n</code></pre>"},{"location":"chap2/4Coll_Kinesis_DS_Exer/#4check-kinesis-stream-monitoring","title":"4\u3001Check Kinesis stream Monitoring","text":"<p>There is <code>Put Records Success (Percent) \u2014 Average</code> data</p> <p> </p>"},{"location":"chap2/5Coll_SQS_Kinesis/","title":"L4 SQS vs. Kinesis Data Stream","text":""},{"location":"chap2/5Coll_SQS_Kinesis/#1sqs-overview","title":"1\u3001SQS Overview","text":""},{"location":"chap2/5Coll_SQS_Kinesis/#1-1-aws-sqs","title":"1-1 AWS SQS","text":"<p>What's a queue</p> <p> </p> <p>SQS Queue and producers or producer or producers will send a message to the SQS Queue and a consumer or consumers will pull messages from that Queue.</p>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-2-aws-sqs-standard-queue","title":"1-2 AWS SQS Standard Queue","text":"<ul> <li>Oldest offering (over 10 years old) </li> <li>Fully managed </li> <li>Scales from 1 message per second to 10,000s per second </li> <li>Default retention of messages: 4 days, maximum of 14 days</li> <li>No limit to how many messages can be in the queue </li> <li>Low latency (&lt; 10 ms on publish and receive) </li> <li>Horizontal scaling in terms of number of consumers </li> <li>Can have duplicate messages (at least once delivery, occasionally) </li> <li>Can have out of order messages (best effort ordering) </li> <li>Limitation of 256KB per message sent </li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-3-sqs-producing-message","title":"1-3 SQS Producing Message","text":"<ul> <li>Define Body </li> <li>Add message attributes (metadata \u2014 optional) </li> <li>Provide Delay Delivery (optional) </li> <li>Get back <ul> <li>Message identifier </li> <li>MD5 hash of the body </li> </ul> </li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-4-sqs-consuming-messages","title":"1-4 SQS - Consuming Messages","text":"<ul> <li>Consumers... </li> <li>Poll SQS for messages (receive up to 10 messages at a time) </li> <li>Process the message within the visibility timeout </li> <li>Delete the message using the message ID &amp; receipt handle</li> </ul> <p>That means that basically when you have SQS your consumers will poll messages and you consumers will process these messages and then delete them from the SQS Queue so the messages cannot be processed by multiple different consumer applications.</p> <p>That's a very big difference versus Kinesis.</p> <p> </p>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-5-aws-sqs-fifo-queue","title":"1-5 AWS SQS \u2014 FIFO Queue","text":"<ul> <li>Newer offering (First In - First out) \u2014 not available in all regions! </li> <li>Name of the queue must end in <code>.fifo</code> </li> <li>Lower throughput (up to 3,000 per second with batching, 300/s without) </li> <li>Messages are processed in order by the consumer </li> <li>Messages are sent exactly once </li> <li>5-minute interval de-duplication using \"Duplication ID\"</li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-6-sqs-extended-client","title":"1-6 SQS Extended Client","text":"<ul> <li>Message size limit is <code>256KB</code>, how to send large messages? </li> <li>Using the SQS Extended Client (Java Library)</li> <li>Need use S3 as companion</li> </ul> <p>Send very large payload maybe like 10gb or fight with you know 5mb to 10mb to S3 and it will send a message metadata in the SQS Queue and then the extended client on the consumer side will receive the smaller metadata message saying where the file is in S3 and the consumer will be able to read the large message directly from S3.</p>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-7-aws-sqs-use-cases","title":"1-7 AWS SQS Use Cases","text":"<ul> <li>Decouple applications <ul> <li>(for example to handle payments asynchronously) </li> </ul> </li> <li>Buffer writes to a database <ul> <li>(for example a voting application) </li> </ul> </li> <li>Handle large loads of messages coming in <ul> <li>(for example an email sender) </li> </ul> </li> <li>SQS can be integrated with Auto Scaling through CloudWatch!</li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-8-sqs-limits","title":"1-8 SQS Limits","text":"<ul> <li>Maximum of 120,000 in-flight messages being processed by consumers</li> <li>Batch Request has a maximum of 10 messages \u2014 max 256KB</li> <li>Message content is XML, JSON, Unformatted text </li> <li>Standard queues have an unlimited TPS </li> <li>FIFO queues support up to 3,000 messages per second (using batching) </li> <li>Max message size is 256KB (or use Extended Client) </li> <li>Data retention from 1 minute to 14 days </li> </ul> <p>Once the messages are read they are deleted from the SQS queue</p> <ul> <li>Pricing: <ul> <li>Pay per API Request </li> <li>Pay per network usage </li> </ul> </li> </ul> <p>Pricing is very different from Kinesis</p>"},{"location":"chap2/5Coll_SQS_Kinesis/#1-9-aws-sqs-security","title":"1-9 AWS SQS Security","text":"<ul> <li>Encryption in flight using the HTTPS endpoint </li> <li>Can enable SSE (Server Side Encryption) using KMS <ul> <li>Can set the CMK (Customer Master Key) we want to use </li> <li>SSE only encrypts the body, not the metadata (message ID, timestamp, attributes) </li> </ul> </li> <li>IAM policy must allow usage of SQS </li> <li>SQS queue access policy <ul> <li>Finer grained control over IP </li> <li>Control over the time the requests come in </li> </ul> </li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#2kinesis-data-streams-vs-sqs","title":"2\u3001Kinesis Data Streams vs SQS","text":""},{"location":"chap2/5Coll_SQS_Kinesis/#2-1-kinesis-data-stream","title":"2-1 Kinesis Data Stream:","text":"<ul> <li>Data can be consumed many times </li> <li>Data is deleted after the retention period(24h-7days) </li> <li>Ordering of records is preserved(at the shard level) \u2014 even during replays </li> <li>Build multiple applications reading from the same stream incependently (Pub/Sub)</li> <li>\"Streaming Mapreduce\" querying capability </li> <li>Checkpointing needed to track progress of consumption (use with the KCL that interacts with DynamoDB)</li> <li>Shards (capacity) must be provided ahead of time </li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#2-2-sqs","title":"2-2 SQS:","text":"<ul> <li>Queue, decouple applications </li> <li>One application per queue </li> <li>Records are deleted after consumption (ack / fail) </li> <li>Messages are processed independently for standard queue </li> <li>Ordering for FIFO queues </li> <li>Capability to \"delay\" messages </li> <li>Dynamic scaling of load (no-ops) </li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#2-3-finally","title":"2-3 Finally","text":"<ul> <li>Kinesis data stream has a message payload size of maximum 1MB </li> <li>SQS is 256 kilobytes</li> </ul>"},{"location":"chap2/5Coll_SQS_Kinesis/#2-4-sqs-vs-kinesis-use-cases","title":"2-4 SQS vs Kinesis \u2014 Use cases","text":"<ul> <li> <p>SQS Use cases : </p> <ul> <li>Order processing </li> <li>Image Processing </li> <li>Auto scaling queues according to messages. </li> <li>Buffer and Batch messages for future processing. </li> <li>Request Offloading </li> </ul> </li> <li> <p>Amazon Kinesis Data Streams Use cases : </p> <ul> <li>Fast log and event data collection and processing </li> <li>RealTime metrics and reports </li> <li>Mobile data capture </li> <li>RealTime data analytics </li> <li>Gaming data feed </li> <li>Complex Stream Processing </li> <li>Data Feed from \"Internet of Things\" </li> </ul> </li> </ul>"},{"location":"chap2/6Coll_IOT/","title":"L5 IoT Overview and DeepDive","text":""},{"location":"chap2/6Coll_IOT/#1iot-overview","title":"1\u3001IoT Overview","text":"<ul> <li>We deploy IoT devices (\"Things\") </li> <li>We configure them and retrieve data from them </li> </ul>"},{"location":"chap2/6Coll_IOT/#1-1-overview","title":"1-1 Overview:","text":"<p>IoT things</p> <p>IoT things like here it's a thermostat but it could be a bike it could be a car it could be a light bulb. It could be anything you want really. So it's just going to be a connected device to your AWS infrastructure. </p> <p>Thing registry</p> <p>IoT thing is going to be registered with our IoT cloud in AWS so it's going to have a thing registry and a thing registry will be giving the device an ID, making sure it's weil authenticated. </p>"},{"location":"chap2/6Coll_IOT/#1-2-aws-iot-details","title":"1-2 AWS IoT Details","text":"<p>Device Gateway </p> <ul> <li>The AWS loT Device Gateway enables devices to seL_uelyeacI efficiently communicate with AWS IoT </li> <li>Things can communicate with each other via the Device Gateway, even if they are using different protocols. </li> </ul> <p> </p> <p> </p> <p>The example at the above illustrates two things -- a connected light bulb, and a control unit -- both connected to the Device Gateway. The control unit can publish commands into the Device Gateway, and the light bulb can subscribe and listen for relevant commands. </p> <p>Rules Engine</p> <p>The rules engine evaluates inbound messages published into AWS IoT, transforms and delivers them to another thing or a cloud based on business rules you define. Many targets like Kinesis, SQS, lambda or so many different other targets. </p> <p> </p> <p>The example at the above illustrates a rule that: </p> <p>Evaluates commands published by the control unit Determines whether the command is \"B\" If the command is \"Be, the rule transforms the message to \"G\" and relays \"G\" to the light bulb </p> <p> </p> <p>Rule actions</p> <p>The rules engine can also route messages to cloud endpoints such as AWS Lambda functions, or a DynamoDB table </p> <p> </p> <p>Evaluates commands publish by the control unit </p> <p>Determines whether the command is \"R\" </p> <p>If the command is \"R\", the rule delivers copies of the message to 3 endpoints -- a DynamoDB database table, a Lambda compute function, and Simple Notification Service (SNS) for push notifications to a mobile device. </p> <p> </p> <p> </p> <p>Device Shadows </p> <p>AWS loT includes Device Registry and Device Shadows, so you can register any thing wish to represent in the cloud with a name, some attributes, and a persistent virtual down. </p> <p> </p> <p>Try turning off the physical light bulb. You'll notice that the Device Shadow remembers the color the physical light bulb. </p> <p> </p> <p> </p> <p>Build solutions</p> <p>AWS IoT makes it easy to build companion applications that interact with your </p> <p> </p> <p>mobile application that reflects the color of your light bulb. The mobile app never communicates directly to the light bulb. Rather, the mobile app uses a REST API to read and set the state of the bulb's Device Shadow. </p>"},{"location":"chap2/6Coll_IOT/#2iot-components-deep-dive","title":"2\u3001IoT Components Deep Dive","text":""},{"location":"chap2/6Coll_IOT/#2-1-iot-device-gateway","title":"2-1 IoT Device Gateway","text":"<ul> <li>Service as the entry point for IoT devices connecting to AWS </li> <li>Allows devices to securely and efficiently communicate with AWS IoT</li> <li>Supports the MQTT WebSockets and HTTP 1.1 protocols</li> <li>Fully managed and scales automatic to support over a billion devices </li> <li>No need to manage infrastructure</li> </ul>"},{"location":"chap2/6Coll_IOT/#2-2-mqtt","title":"2-2 MQTT","text":"<p>Message broker supports Quality of Service</p> <p> </p>"},{"location":"chap2/6Coll_IOT/#2-3-iot-message-broker","title":"2-3 IoT Message Broker","text":"<ul> <li>Pub/sub (publishers/subscribers) messaging pattern - low latency</li> <li>Devices can communicate with one another this way </li> <li>Messages sent using the MQTT, WebSockets or HTTP </li> <li>Messages are published into topics (just like SNS) </li> <li>Message Broker forwards messages to all clients connected to the topic </li> </ul>"},{"location":"chap2/6Coll_IOT/#2-4-iot-thing-registry-iam-of-iot","title":"2-4 IoT Thing Registry - IAM of IoT","text":"<ul> <li>All connected IoT devices are represented in the AWS IoT registry </li> <li>Organizes the resources associated with each device in the AWS Cloud</li> <li>Each device gets a unique </li> <li>Supports metadata for each device (ex: Celsius vs Fahrenheit, etc...) \u2022</li> <li>Can create X.509 certificate to IoT devices connect to AWS </li> <li>IoT Groups: group devices together and apply permissions to the group </li> </ul>"},{"location":"chap2/6Coll_IOT/#2-5-authentication","title":"2-5 Authentication","text":"<ul> <li> <p>3 possible authentication methods for Things: </p> <ul> <li>Create X509 certificates an\u7684 load them securely onto the Things</li> <li>AWS SigV4 </li> <li>Custom tokens with Custom authorizers \u2022 </li> </ul> </li> <li> <p>For mobile apps: </p> <ul> <li>Cognito identities (extension to Google, Facebook login, etc...)  </li> </ul> </li> <li> <p>Web / Desktop / CLI: </p> <ul> <li>IAM </li> <li>Federated Identities </li> </ul> </li> </ul> <p> </p>"},{"location":"chap2/6Coll_IOT/#2-6-authorization","title":"2-6 Authorization","text":"<p>AWS IoT policies: </p> <ul> <li>Attached to X.509 certificates or Cognito Identities </li> <li>Able to revoke any device at any time </li> <li>IoT Policies are JSON docuements </li> <li>Can be attached to groups instead of individual Things. </li> </ul> <p>IAM Policies: </p> <ul> <li>Attached to users, group or roles </li> <li>Used for controlling loT AWS APIs </li> </ul> <p>Summary: Your devices are ruled by AWS IoT policies </p> <p>Your users, roles, and groups just like in AWS normal are ruled by IAM policies </p>"},{"location":"chap2/6Coll_IOT/#2-7-device-shadow","title":"2-7 Device Shadow","text":"<p>Device Shadow concept: Even if a device was offline we could change its shadow in the AWS cloud and as soon as the device came back up online it would look at what </p> <ul> <li>JSON document representing the state of a connected Thing </li> <li>We can set the state to a different desired state (ex: light on) </li> <li>The IoT thing will retrieve the state when online and adapt </li> </ul> <p> </p>"},{"location":"chap2/6Coll_IOT/#2-8-rules-engine-exam","title":"2-8 Rules Engine (Exam)","text":"<ul> <li>Rules are defined on the MATT topics</li> <li>Rules = when it's triggered / Action = what is does </li> <li> <p>Rules use cases: </p> <ul> <li>Augment or filter data received from a device </li> <li>Write data received from a device to a DynarnoDB database </li> <li>Save a file to S3</li> <li>Send a push notification to all users using SNS </li> <li>Publish data to a SQS queue </li> <li>Invoke a Lambda function to extract data </li> <li>Process messages from a large number of devices using Amazon Kinesis</li> <li>Send data to the Amazon Elasticsearch Service </li> <li>Capture a CloudWatch metric and Change a CloudWatch alarm</li> <li>Send the data from an MQTT message to Amazon Machine Learning to make predictions based on an Amazon NIL model </li> <li>&amp; more </li> </ul> </li> <li> <p>Rules need IAM Roles to perform their actions </p> </li> </ul> <p> </p>"},{"location":"chap2/6Coll_IOT/#2-9-iot-greengrass","title":"2-9 IoT Greengrass","text":"<ul> <li>IoT Greengrass brings the compute layer to the device directly </li> <li> <p>You can execute AWS Lambda functions on the devices: </p> <ul> <li>Pre-process the data </li> <li>Execute predictions based on ML models </li> <li>Keep device data in sync </li> <li>Communicate between local devices </li> </ul> </li> <li> <p>Operate offline </p> </li> <li>Deploy functions from the cloud directly to the devices </li> </ul> <p> </p>"},{"location":"chap2/7Coll_MSK/","title":"L7 MSK Managed Streaming for Apache Kafka (Amazon MSK)","text":""},{"location":"chap2/7Coll_MSK/#1msk-managed-streaming-for-apache-kafka","title":"1\u3001MSK Managed Streaming for Apache Kafka","text":"<ul> <li>Alternative to Kinesis (Kafka vs Kinesis next lecture) </li> <li> <p>Fully managed Apache Kafka on AWS </p> <ul> <li>Allow you to create, update, delete clusters </li> <li>MSK creates &amp; manages Kafka brokers nodes &amp; Zookeeper nodes for you</li> <li>Deploy the MSK cluster in yourVPC, multi-AZ (up to 3 for HA) </li> <li>Automatic recovery from common Apache Kafka failures </li> <li>Data is stored on EBS volumes </li> </ul> </li> <li> <p>You can build producers and consumers of data </p> </li> <li>Can create custom configurations for your clusters <ul> <li>Default message size of 1 MB </li> <li>Possibilities of sending large messages (ex: 10MB) into Kafka after custom configuration </li> </ul> </li> </ul>"},{"location":"chap2/7Coll_MSK/#1-1-apache-kafka-at-high-level","title":"1-1 Apache Kafka at High Level","text":"<ul> <li>Your responsibilityjis to create your own producers so you write your own code and these producers run the code pull data from data like IoT </li> <li>Producer get data and write to Kafka topic. You write the data to your main broker, then the leader broker then is going to be replicated to follower brokers</li> <li>Once it's fully replicated its going to be available for a consumer to be your code pull and read from that topic and receive the data. </li> </ul>"},{"location":"chap2/7Coll_MSK/#1-2-msk-configurations","title":"1-2 MSK \u2014 Configurations","text":"<ul> <li>Choose the number of AZ (3 \u2014 recommended, or 2) </li> <li>Choose the VPC &amp; Subnets </li> <li>The broker instance type (ex: kafka.m5.1arge) </li> <li>The number of brokers per AZ (can add brokers later) </li> <li>Size of your EBS volumes (1GB \u2014 16TB)</li> </ul>"},{"location":"chap2/7Coll_MSK/#1-3-msk-security","title":"1-3 MSK \u2014 Security","text":"<p>Encryption: </p> <ul> <li>Optional in-flight using TLS between the brokers </li> <li>Optional in-flight with TLS between the clients and brokers </li> <li>At rest for your EBS volumes using KMS</li> </ul> <p>Network Security: </p> <ul> <li>Authorize specific security groups for your Apache Kafka clients  </li> </ul> <p>Authentication &amp; Authorization (important): </p> <ul> <li>Define who can read/write to which topics </li> <li>Mutual TLS (AuthN) + Kafka ACLs (AuthZ) </li> <li>SASL/SCRAM (AuthN) + Kafka ACLs (AuthZ) </li> <li>IAM Access Control (AuthN AuthZ) </li> </ul> <p> </p>"},{"location":"chap2/7Coll_MSK/#1-4-msk-monitoring","title":"1-4 MSK \u2014 Monitoring","text":"<p>CloudWatch Metrics </p> <ul> <li>Basic monitoring (cluster and broker metrics) </li> <li>Enhanced monitoring (++enhanced broker metrics) </li> <li>Topic-level monitoring (++enhanced topic-level metrics) </li> </ul> <p>Prometheus (Open-Source Monitoring) </p> <ul> <li>Opens a port on the broker to export cluster, broker and topic-level metrics </li> <li>Setup the JMX Exporter (metrics) or Node Exporter (CPU and disk metrics) </li> </ul> <p>Broker Log Delivery </p> <ul> <li>Delivery to CloudWatch Logs </li> <li>Delivery to Amazon S3 </li> <li>Delivery to Kinesis Data Streams </li> </ul>"},{"location":"chap2/7Coll_MSK/#1-5-msk-override-kafka-configurations","title":"1-5 MSK Override Kafka Configurations","text":"<ul> <li>List of properties you can set: </li> </ul> <p>Important to note: </p> <ul> <li> <p>Max message size in Kakfa by default is 1 MB bnicvelytes) </p> <ul> <li>Can override this with the broter message.max.bytes settings</li> <li>Must also change the consumer max.fetch.bytes setting </li> </ul> </li> <li> <p>Latency: </p> <ul> <li>By default ifs low in Kafka 10-40ms (way less than Kinesis) </li> <li>The producer can increase latency to increase hatching using linge.rms</li> </ul> </li> </ul>"},{"location":"chap2/7Coll_MSK/#2kinesis-vs-msk","title":"2\u3001Kinesis VS MSK","text":""},{"location":"chap2/7Coll_MSK/#2-1-kinesis-data-streams","title":"2-1 Kinesis Data Streams","text":"<ul> <li>1MB message size limit </li> <li>Data Streams with Shards </li> <li>Shard Spitting &amp; Verging </li> <li>TLS In-flight encryption </li> <li>KMS At-rest encryption </li> <li>Security: <ul> <li>IAM policies for AuthN/Auth/ </li> </ul> </li> </ul>"},{"location":"chap2/7Coll_MSK/#2-2-amazon-msk","title":"2-2 Amazon MSK","text":"<ul> <li>1MB, default, configure for higher (ex: 1OMB) </li> <li>Kafka Topics with Partitions </li> <li>Can only add partitions to a topic </li> <li>PLAINTEXT or TLS In-flight Encryption </li> <li>KMS At-rest encryption  </li> <li>Security: <ul> <li>Mutual MS (AuthN) + KafKa ACLs(AuthZ) </li> <li>SASL/SCARM (AuthN) + Kafka ACLs (Auth7) </li> <li>IAM Access Control (AuthN + AuthZ) </li> </ul> </li> </ul>"},{"location":"chap2/7Coll_Others/","title":"L6 Data Collection Others","text":""},{"location":"chap2/7Coll_Others/#1database-migration-servicedms","title":"1\u3001Database Migration Service(DMS)","text":"<ul> <li>Quickly and securely migrate databases to AWS, resilient, self healing </li> <li>The source database remains available during the migration </li> <li>Supports: <ul> <li>Homogeneous migrations: ex Oracle to Oracle </li> <li>Heterogeneous migrations: ex Microsoft SQL Server to Aurora </li> </ul> </li> <li>Continuous Data Replication using CDC </li> <li>You must create an EC2 instance to perform the replication tasks </li> </ul>"},{"location":"chap2/7Coll_Others/#1-1-dms-resources-and-targets","title":"1-1 DMS Resources and Targets","text":"<p><code>_SOURCES_</code>: </p> <ul> <li>On-Premise and EC2 instances databases: Oracle, MS SQL Server MySQL, MariaDB, PostgreSQL, MongoDB, SAP, DB2 </li> <li>Azure: Azure SQL Database </li> <li>Amazon RDS: all including Aurora </li> <li>Amazon S3 </li> </ul> <p><code>_TARGETS_</code></p> <ul> <li>On-Premise and EC2 instances databases: Oracle, MS SQL Server, MySQL, MariaDB, PostgreSQL, SAP</li> <li>Amazon RDS </li> <li>Amazon Redshift </li> <li>Amazon DynamoDB </li> <li>Amazon S3 </li> <li>ElasticSearch Service </li> <li>Kinesis Data Streams </li> <li>DocumentDB </li> </ul>"},{"location":"chap2/7Coll_Others/#1-2-aws-schema-conversion-tool-sct","title":"1-2 AWS Schema Conversion Tool (SCT)","text":"<ul> <li>Convert your Database's Schema from one engine to another </li> <li>Example OLTP: (SQL Server or Oracle) to MySQL, PostgreSQL, Aurora </li> <li>Example OLAP: (Teradata or Oracle) to Amazon Redshift </li> <li>You can use AWS SCT to create AWS DMS endpoints and tasks. </li> </ul>"},{"location":"chap2/7Coll_Others/#2direct-connect","title":"2\u3001Direct Connect","text":"<ul> <li>Provides a dedicated private connection from a remote network to yourVPC </li> <li>Can setup multiple 1 Gbps or 10 Gbps dedicated network connections </li> <li>Setup Dedicated connection between your DC and Direct Connect locations </li> <li>You need to setup a Virtual Private Gateway on your VPC </li> <li>Access public resources (S3) and private (EC2) on same connection </li> <li>Use Cases: <ul> <li>Increase bandwidth throughput - working with large data sets - lower cost </li> <li>More consistent network experience - applications using real-time data feeds </li> <li>Hybrid Environments (on premise + cloud) </li> <li>Enhanced security (private connection) </li> </ul> </li> <li>Supports both IPv4 and IPv6 </li> <li>High-availability: Two DC as failover or use Site-to-Site VPN as a failover</li> </ul> <ol> <li>Basically we see that from our customer network</li> <li>we have a router and we connect that router into a direct connect location right here which goes into a direct connect end point </li> <li>This direct connect end point is connected directly either into the public resources of AWS such as Glacier, S3, </li> <li>Or into the private resources of AWS using a virtual private gateway where we can connect to our EC2 instances in a private manner.</li> </ol>"},{"location":"chap2/7Coll_Others/#2-1-direct-conned-gateway","title":"2-1 Direct Conned Gateway","text":"<ul> <li>If you want to setup a Direct Connect to one or more VPC in many different regions (same account), you must use a Direct Connect Gateway </li> </ul>"},{"location":"chap2/7Coll_Others/#3snowball","title":"3\u3001SnowBall","text":""},{"location":"chap2/7Coll_Others/#3-1-snowball","title":"3-1 Snowball","text":"<ul> <li>Physical data transport solution that helps moving TBs or PBs of data in or out of AWS </li> <li>Alternative to moving data over the network (and paying network fees) </li> <li>Secure, tamper resistant, uses KMS 256 bit encryption </li> <li>Tracking using SNS and text messages. E-ink ship ping label</li> <li>Pay per data transfer job </li> <li>Use cases:<ul> <li>large data cloud migrations, </li> <li>DC decomission </li> <li>disaster recovery </li> </ul> </li> <li>If it takes more than a week to transfer over the network, use Snowball devices! </li> </ul>"},{"location":"chap2/7Coll_Others/#3-2-snowball-process","title":"3-2 Snowball Process","text":"<ol> <li>Request snowball devices from the AWS console for delivery </li> <li>Install the snowball client on your servers </li> <li>Connect the snowball to your servers and copy files using the client </li> <li>Ship back the device when you're done (goes to the right AWS facility)  </li> <li>Data will be loaded into an S3 bucket </li> <li>Snowball is completely wiped </li> <li>Tracking is done using SNS, text messages and the AWS console </li> </ol>"},{"location":"chap2/7Coll_Others/#3-3-snowball-diagrams","title":"3-3 Snowball Diagrams","text":"<p>Direct upload to s3</p> <p> </p> <p>With Snowball</p> <p> </p>"},{"location":"chap2/7Coll_Others/#3-4-snowball-edge","title":"3-4 Snowball Edge","text":"<ul> <li>Snowball Edges add computational capability to the device </li> <li>1OOTB capacity with either: <ul> <li>Storage optimized \u2014 24 vCPU </li> <li>Compute optimized \u2014 52 vCPU &amp; optional GPU </li> </ul> </li> <li>Supports a custom EC2 AMI so you can perform processing on the go</li> <li>Supports custom Lambda functions </li> <li>Very useful to pre-process the data wile moving </li> <li>Use case: <ul> <li>data migration</li> <li>image collation </li> <li>IoT capture</li> <li>machine learning</li> </ul> </li> </ul>"},{"location":"chap2/7Coll_Others/#3-5-snowball-edge-for-data-transfers","title":"3-5 Snowball Edge (for data transfers)","text":"<ul> <li>Physical data transport solution: move TBs or PBs of data in or out of AWS</li> <li>Ahernative to moving data over the network (and paying network fees) </li> <li>Pay per data transfer job </li> <li>Provide block storage and Amazon S3-compatible object storage </li> <li>Snowball Edge Storage Optimized <ul> <li>80 TB of HDD capacity for block volume and 53 compatible object storage </li> </ul> </li> <li>Snowball Edge Compute Optimized <ul> <li>42 TB of HDD canacity for block volume and S3 compatible object storage </li> </ul> </li> </ul>"},{"location":"chap2/7Coll_Others/#3-6-snowmobile","title":"3-6 Snowmobile","text":"<ul> <li>Transfer exabytes of data ( 1 EB = 1,000 PB = 1,000,000TBs) </li> <li>Each Snowmobile has 100 PB of capacity (use multiple in parallel) </li> <li>Better than Snowball if you transfer more than 10 PB </li> <li>High security: temperature controlled, GPS, 24/7 video surveillance</li> </ul>"},{"location":"chap2/7Coll_Others/#3-7-aws-snowcone","title":"3-7 AWS SnowCone","text":"<ul> <li>Small, portable computing, anywhere, rugged &amp; secure, withstands harsh environments </li> <li>Light (4.5 pounds, 2.1 kg) </li> <li>Device used for edge computing, storage, and data transfer </li> <li>8 TBs of usable storage </li> <li>Use Snowcone where Snowball does not fit (space-constrained environment)</li> <li> <p>Must provide your own battery / cables </p> </li> <li> <p>Can be sent back to AWS offline, or connect it to intemet and use AWS DataSync to send data </p> </li> </ul> <p> </p>"},{"location":"chap2/7Coll_Others/#3-8-aws-snow-family-for-data-migrations","title":"3-8 AWS Snow Family for Data Migrations","text":""},{"location":"chap2/7Coll_Others/#3-9-snow-family-usage-process","title":"3-9 Snow-Family - Usage process","text":"<ol> <li>Request Snowball devices from the AWS console for delivery </li> <li>Install the snowball client / AWS OpsHub on your servers </li> <li>Connect the snowball to your servers and copy files using the client </li> <li>Ship back the device when you're done (goes to the right AWS facility) </li> <li>Data will be loaded into an S3 bucket </li> <li>Snowball is completely wiped </li> </ol>"},{"location":"chap2/7Coll_Others/#4edge-computing","title":"4\u3001Edge-Computing","text":""},{"location":"chap2/7Coll_Others/#4-1-whats-edge-computing","title":"4-1 What's Edge-Computing","text":"<ul> <li> <p>Process data while its being created on an edge location</p> <ul> <li>A truck on the road, a ship on the sea, a mining station underground </li> </ul> </li> <li> <p>These locations may have </p> <ul> <li>Limited / no intemet access  </li> <li>Limited / no easy access to computing power</li> </ul> </li> <li> <p>We setup a Snowball Edge / Snowcone device to do edge computing </p> </li> <li> <p>Use cases of Edge Computing </p> <ul> <li>Preprocess data </li> <li>Machine learning at the edge </li> <li>Transcoding media streams</li> </ul> </li> <li> <p>Eventually (if need be) we can ship back the device to AWS (for transferring data for example) </p> </li> </ul>"},{"location":"chap2/7Coll_Others/#4-2-snow-family-edge-computing","title":"4-2 Snow Family \u2014 Edge Computing","text":"<ul> <li> <p>Snowcone (smaller) </p> <ul> <li>2 CPUs, 4 GB of memory wired or wireless access </li> <li>USB-C power using a cord or the optional battery </li> </ul> </li> <li> <p>Snowball Edge \u2014 Compute Optimized </p> <ul> <li>52 vCPUs. 208 GiB of RAM  </li> <li>Optional GPU (useful for video processing or machine) learning) </li> <li>42TB usable storage </li> </ul> </li> <li> <p>Snowball Edge \u2014 Storage Optimized </p> <ul> <li>Up to 40 vCPUs, 80 GiB of RAM </li> <li>Object storage clustering available  </li> </ul> </li> <li> <p>All: Can run EC2 Instances &amp; AWS Lambda functions (using AWS IoT Greengras\uff09 </p> </li> <li>Long-term deployment options: 1 and 3 years discounted pricing </li> </ul>"},{"location":"chap2/7Coll_Others/#5aws-opshub","title":"5\u3001AWS OpsHub","text":"<ul> <li>Historically, to use Snow Family devices, you needed a al (Command Line Interface tool) </li> <li>Today, you can use AWS op Hub (a software you install onyour computer / laptop) to manage your Snow Family Device <ul> <li>Unlocking and configuring single or clustered devices </li> <li>Transferring files </li> <li>Launching and managing instances running on Snow Earn Devices</li> <li>Monitor device metrics (storage capacity, active instances on your device </li> <li>Launch compatible AWS services on your devices (ex:Amazon EC2 instances, AWS DataSync, Network Ede System (NFS) </li> </ul> </li> </ul>"},{"location":"chap3/10Storage_cache/","title":"L4 ElastiCache Overview","text":""},{"location":"chap3/10Storage_cache/#1aws-elasticache-overview","title":"1\u3001AWS ElastiCache Overview","text":"<ol> <li>The same way RDS is to get managed Relational Databases... </li> <li>ElastiCache is to get managed Redis or Memcached </li> <li>Caches are in-memory databases with really high performance, low latency </li> <li>Helps reduce load off of databases for read intensive workloads </li> <li>Helps make your application stateless </li> <li>Write Scaling using sharding  Read Scaling using Read Replicas </li> <li>Multi AZ with Failover Capability </li> <li>AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups </li> </ol>"},{"location":"chap3/10Storage_cache/#2redis-overview","title":"2\u3001Redis Overview","text":"<ul> <li>Redis is an in-memory key-value store </li> <li>Super low latency (sub ms) </li> <li>Cache survive reboots by default (it's called persistence)</li> <li> <p>Great to host </p> <ul> <li>User sessions</li> <li>Leaderboard (for gaming) </li> <li>Distributed states </li> <li>Relieve pressure on databases (such as RDS) </li> <li>Pub / Sub capability for messaging </li> </ul> </li> <li> <p>Multi AZ with Automatic Failover for disaster recovery if you don't want to lose your cache data </p> </li> <li>Support for Read Replicas </li> </ul>"},{"location":"chap3/10Storage_cache/#3memcached-overview","title":"3\u3001Memcached Overview","text":"<ul> <li>Memcached is an in-memory object store </li> <li>Cache doesn't survive reboots </li> <li> <p>Use cases: </p> <ul> <li>Quick retrieval of objects from memory </li> <li>Cache often accessed objects </li> </ul> </li> <li> <p>Overall, Redis has largely grown in popularity and has better feature sets than Memcached. </p> </li> <li>I would personally only use Redis for caching needs. </li> </ul>"},{"location":"chap3/8Hands_onS3/","title":"L3 Hands on S3","text":""},{"location":"chap3/8Hands_onS3/#1s3-storage-classes-hands-on","title":"1\u3001S3 Storage Classes Hands on","text":"<p>Storage Classes</p> <p> </p> <p>Initiate restore</p> <p> </p>"},{"location":"chap3/8Hands_onS3/#2s3-lifecycle-rules-hands-on","title":"2\u3001S3 Lifecycle Rules Hands on","text":"<p>Life rule actions</p> <p> </p> <p> </p> <p>Timeline summary</p> <p> </p> <p> </p>"},{"location":"chap3/8Hands_onS3/#3s3-versioning-hands-on","title":"3\u3001S3 Versioning - Hands on","text":"<p>Enable S3 Versioning</p> <p> </p> <p>Delete object firstly</p> <p> </p> <p>Add <code>Delete marker</code> to object</p> <p> </p> <p>Permantely delete</p> <p> </p>"},{"location":"chap3/8Hands_onS3/#3s3-replication-hands-on","title":"3\u3001S3 Replication - Hands on","text":"<p>Enable Replication rule and Replication Destination</p> <p> </p> <p> </p> <p> </p>"},{"location":"chap3/8Hands_onS3/#4s3-encryption-hands-on","title":"4\u3001S3 Encryption - Hands on","text":"<p>Object Encryption SSE-S3 &amp; SSE-KMS</p> <p> </p> <p>Bucket Encryption SSE-S3 &amp; SSE-KMS</p> <p> </p>"},{"location":"chap3/8Hands_onS3/#4s3-security-bucket-policies-hands-on","title":"4\u3001S3 Security &amp; Bucket Policies - Hands on","text":"<p>Add Bucket policy conditions</p> <p> </p> <p> </p> <p> </p>"},{"location":"chap3/8Hands_onS3/#5s3-events-notification-hands-on","title":"5\u3001S3 Events Notification - Hands on","text":""},{"location":"chap3/8Hands_onS3/#5-1-add-upload-events","title":"5-1 Add upload events","text":""},{"location":"chap3/8Hands_onS3/#5-2-add-upload-events","title":"5-2 Add upload events","text":"<p>Send Notification to SQS queue</p> <p> </p> <p>Also need add policy to SQS enable the notification</p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"chap3/8Storage_S3/","title":"L1 Storage S3","text":""},{"location":"chap3/8Storage_S3/#1s3-overview","title":"1\u3001S3 Overview","text":""},{"location":"chap3/8Storage_S3/#1-1-aws-s3-overview-buckets","title":"1-1 AWS S3 Overview - Buckets","text":"<ul> <li>Amazon S3 allows people to store objects (files) in \"buckets\" (directories) </li> <li>Buckets must have a globally unique name </li> <li>Buckets are defined at the region level</li> <li>Naming convention <ul> <li>No uppercase </li> <li>No underscore </li> <li>3-63 characters long </li> <li>Not an IP </li> <li>Must start with lowercase letter or number </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#1-2-aws-s3-overview-objects","title":"1-2 AWS S3 Overview - Objects","text":"<ul> <li>Objects (files) have a Key.The key is the FULL path: <ul> <li><code>&lt;my_bucket&gt;/my_file.txt</code> \u2022</li> <li><code>&lt;my_bucket&gt;/my_folder/another_folder/myfile.txt</code> </li> </ul> </li> <li>There's no concept of\"directories\" within buckets (although the UI will trick you to think otherwise) </li> <li>Just keys with very long names that contain slashes (\"/\") </li> <li>Object Values are the content of the body <ul> <li>Max Size is 5TB </li> <li>If uploading more than 5GB, must use \"multi-part upload\" </li> </ul> </li> <li>Metadata (list of text key / value pairs \u2014 system or user metadata) </li> <li>Tags (Unicode key / value pair \u2014 up to 10) \u2014 useful for security / lifecycle </li> <li>Version ID (if versioning is enabled) </li> </ul>"},{"location":"chap3/8Storage_S3/#1-3-aws-s3-consistency-model","title":"1-3 AWS S3 - Consistency Model","text":"<ul> <li> <p>Read after write consistency for PUTS of new objects</p> <ul> <li>As soon as an object is written, we can retrieve it <ul> <li>ex (<code>PUT 200 -&gt; GET 200</code>) </li> </ul> </li> <li>This is true, except if we did a GET before to see if the object existed <ul> <li>ex (GET 404 -&gt; PUT 200 -&gt; GET 404) \u2014 eventually consistent(wait 1s or 2s then you will get 200)</li> </ul> </li> </ul> </li> <li> <p>Eventual Consistency for DELETES and PUTS of existing objects </p> <ul> <li>If we read an object after updating we might get the older version <ul> <li>ex: (PUT 200 -&gt; PUT 200 -&gt; GET 200 (might be older version)) </li> </ul> </li> <li>If we delete an object, we might still be able to retrieve it for a short time <ul> <li>ex (DELETE 200 -&gt; GET 200) </li> </ul> </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2s3-storage-tiers","title":"2\u3001S3 Storage Tiers","text":"<ul> <li>Amazon S3 Standard - General Purpose </li> <li>Amazon S3 Standard-Infrequent Access (IA) </li> <li>Amazon S3 One Zone-Infrequent Access </li> <li>Amazon S3 Reduced Redundancy Storage (deprecated) </li> <li>Amazon S3 IntelligentTiering (new!) </li> <li>Amazon Glacier </li> </ul>"},{"location":"chap3/8Storage_S3/#2-1-s3-standard-general-purpose","title":"2-1 S3 Standard \u2014 General Purpose","text":"<ul> <li>High durability (11)(99.999999999%) of objects across multiple AZ</li> <li>If you store 10,000,000 objects with Amazon S3, you can on average expect to incur a loss of a single object once every 10,000 years </li> <li>99.99% Availability over a given year </li> <li>Sustain 2 concurrent facility failures </li> <li>Use Cases: <ul> <li>Big Data analytics </li> <li>mobile &amp; gaming applications</li> <li>content distribution... </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2-2-s3-reduced-redundancy-storage-rrs-deprecated","title":"2-2 S3 Reduced Redundancy Storage (RRS) - DEPRECATED","text":"<ul> <li>Designed to provide 99.99% durability </li> <li>99.99% availability of objects over a given year </li> <li>Designed to sustain the loss of data in a single facility </li> <li>Use cases: <ul> <li>noncritical, </li> <li>reproducible data at lower levels of redundancy than Amazon S3's standard storage (thumbnails, transcoded media, processed data that can be reproduced) </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2-3-s3-standard-infrequent-access-ia","title":"2-3 S3 Standard \u2014 Infrequent Access (IA)","text":"<ul> <li>Suitable for data that is less frequently accessed, but requires rapid access when needed </li> <li>High durability (99.999999999%) of objects across multiple AZs </li> <li>99.9% Availability (less than General Purpose)</li> <li>Low cost compared to Amazon S3 Standard </li> <li>Sustain 2 concurrent facility failures </li> <li>Use Cases:<ul> <li>As a data store for disaster recovers </li> <li>backups... </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2-4-s3-one-zone-infrequent-access-ia","title":"2-4 S3 One Zone - Infrequent Access (IA)","text":"<ul> <li>Same as IA but data is stored in a single AZ </li> <li>High durability (99.999999999%) of objects in a single AZ; data lost when AZ is destroyed</li> <li>99.5% Availability \u2022 Low latency and high throughput performance </li> <li>Supports SSL for data at transit and encryption at rest </li> <li>Low cost compared to IA (by 20%)</li> <li>Use Cases: <ul> <li>Storing secondary backup copies of on-premise data,</li> <li>storing data you can recreate </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2-5-s3-intelligenttiering-new","title":"2-5 S3 IntelligentTiering (new!)","text":"<ul> <li>Probably not at the exam (yet!) </li> <li>Same low latency and high throughput performance of S3 Standard </li> <li>Small monthly monitoring and auto-tiering fee </li> <li>Automatically moves objects between two access tiers based on changing access patterns </li> <li>Designed for durability of 99.999999999% of objects across multiple Availability Zones </li> <li>Resilient against events that impact an entire Availability Zone </li> <li>Designed for 99.9% availability over a given year </li> </ul>"},{"location":"chap3/8Storage_S3/#2-6-s3-glacier","title":"2-6 S3 Glacier","text":"<ul> <li>Low cost object storage meant for archiving / backup</li> <li>Data is retained for the longer term (10s of years) </li> <li>Alternative to on-premise magnetic tape storage </li> <li>Average annual durability is 99.999999999%</li> <li>Cost per storage per month ($0.004 / GB) + retrieval cost </li> <li>Each item in Glacier is called \"Archive\" (up to 40TB) </li> <li>Archives are stored in \"Vaults\" </li> <li>3 retrieval options: <ul> <li>Expedited (1 to 5 minutes retrieval) \u2014 $0.03 per GB and $0.01 per request </li> <li>Standard (3 to 5 hours) - $0.01 per GB and 0.05 per 1000 requests </li> <li>Bulk (5 to 12 hours) - $00025 per GB and $0.025 per 1000 requests </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#2-7-s3-storage-tiers-comparisons","title":"2-7 S3 Storage Tiers Comparisons","text":""},{"location":"chap3/8Storage_S3/#2-8-s3-storage-classes-price-comparison-example-us-east-2","title":"2-8 S3 Storage Classes \u2014 Price Comparison Example us-east-2","text":""},{"location":"chap3/8Storage_S3/#3s3-lifecycle-rules","title":"3\u3001S3 Lifecycle Rules","text":"<ul> <li>Set of rules to move data between different tiers, to save storage cost </li> <li>Example: General Purpose =&gt; Infrequent Access =&gt; Glacier </li> <li>Transition actions: It defines when objects are transitioned to another storage class. <ul> <li>Eg: We can choose to move objects to Standard IA class 60 days after you created them or can move to Glacier for archiving after 6 months </li> </ul> </li> <li>Expiration actions: Helps to configure objects to expire after a certain time period. S3 deletes expired objects on our behalf <ul> <li>Eg: Access log files can be set to delete after a specified period of time </li> </ul> </li> <li>Moving to Glacier is helpful for backup / long term retention / regulatory needs </li> </ul>"},{"location":"chap3/8Storage_S3/#4s3-versioning","title":"4\u3001S3 Versioning","text":"<ul> <li>You can version your files in AWS S3 </li> <li>It is enabled at the bucket level </li> <li>Same key overwrite will increment the \"version\": 1 , 2, 3.... </li> <li>It is best practice to version your buckets <ul> <li>Protect against unintended deletes (ability to restore a version) </li> <li>Easy roll back to previous version </li> </ul> </li> <li>Any file that is not versioned prior to enabling versioning will have version \"null\" </li> <li>You can \"suspend\" versioning </li> </ul> <p><code>Enable versioning</code> =&gt; <code>version id</code></p> <p> </p>"},{"location":"chap3/8Storage_S3/#5s3-cross-region-replication","title":"5\u3001S3 Cross Region Replication","text":"<ul> <li>Must enable versioning (source and destination) </li> </ul> <ul> <li>Buckets must be in different AWS regions </li> <li>Can be in different accounts </li> </ul> <ul> <li>Copying is asynchronous </li> </ul> <ul> <li>Must give proper IAM permissions to S3 </li> </ul> <ul> <li>Use cases: <ul> <li>compliance, </li> <li>lower latency access, </li> <li>replication across accounts </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#6s3-etags-entity-tag","title":"6\u3001S3 ETags (Entity Tag)","text":"<ul> <li>Flow do you verify if a file has already been uploaded to S3? </li> <li>Names work, but how are you sure the file is exactly the same? </li> <li>For this, you can use AWS ETags: <ul> <li>For simple uploads (less than 5GB), it's the MD5 hash </li> <li>For multi-part uploads, it's more complicated, no need to know the algorithm </li> </ul> </li> <li>Using ETag, we can ensure integrity of files </li> </ul>"},{"location":"chap3/8Storage_S3/#6aws-s3-performance","title":"6\u3001AWS S3 Performance","text":"<p>Historic fact and current exam </p> <ul> <li>When you had &gt; 100 TPS (transaction per second), S3 performance could degrade </li> <li>Behind the scene, each object goes to an S3 partition and for the best performance, we want the highest partition cistribution </li> <li> <p>In the exam, and historically, it was recommended to have random characters in front of your key name to optimise performance: </p> <ul> <li><code>&lt;my_bucket&gt;/5r4d_my_folder/my_file1.txt</code> </li> <li><code>&lt;my_bucket&gt;/a91e_my_folder/my_file2.txt</code> </li> <li>...</li> </ul> </li> <li> <p>It was recommended never to use dates to prefix keys: </p> <ul> <li><code>&lt;my_bucket&gt;/2018_09_09_my_folder/my_file1.txt</code> </li> <li><code>&lt;my_bucket&gt;/2018_09_10_my_folder/my_file2.txt</code></li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#6-1-aws-s3-performance-key-names-current-performance-not-yet-exam","title":"6-1 AWS S3 Performance Key Names Current performance (not yet exam)","text":"<p>https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/</p> <ul> <li>As of July 17th 2018, we can scale up to 3500 RPS(request per second) for PUT and 5500 RPS for GET for EACH PREFIX </li> <li>\"This S3 request rate performance increase removes any previous guidance to randomize object prefixes to achieve faster performance\" </li> <li>It's a \"good to know\", until the exam gets updated </li> </ul>"},{"location":"chap3/8Storage_S3/#6-2-aws-s3-performance","title":"6-2 AWS S3 Performance","text":"<ul> <li>Faster upload of large objects (&gt;5GB), use multipart upload: <ul> <li>parallelizes PUTs for greater throughput </li> <li>maximize your network bandwidth </li> <li>decrease time to retry in case a part fails </li> </ul> </li> <li>Use CloudFront to cache 53 objects around the world (improves reads) </li> <li>S3 Transfer Acceleration (uses edge locations) \u2014 just need to change the endpoint you write to, not the code. </li> <li>If using SSE-KMS encryption, you may be limited to your AWS limits for KMS usage (~100s \u2014 1000s downloads / uploads per second) </li> </ul>"},{"location":"chap3/8Storage_S3/#7s3-encryption","title":"7\u3001S3 Encryption","text":""},{"location":"chap3/8Storage_S3/#7-1-s3-encryption-for-objects","title":"7-1 S3 Encryption for Objects","text":"<p>There are 4 methods of encrypting objects in S3 </p> <ul> <li>SSE-S3: encrypts S3 objects using keys handled &amp; managed by AWS </li> <li>SSE-KMS: leverage AWS Key Management Service to manage encryption keys </li> <li>SSE-C: when you want to manage your own encryption keys </li> <li>Client Side Encryption </li> <li>It's important to understand which ones are adapted to which situation for the exam </li> </ul>"},{"location":"chap3/8Storage_S3/#7-2-sse-s3","title":"7-2 SSE-S3","text":"<ul> <li>SSE-S3: encryption using keys handled &amp; managed by AWS S3 </li> <li>Object is encrypted server side </li> <li>AES-256 encryption type </li> <li>Must set header: \"x-amz-server-side-encryption\": \"AES256\" </li> </ul> <p>Remember the form it's x-amz for Amazon server-side-encryption AES256 which makes sense because requesting Amazon to perform servers that encryption for us with the algorithm AES-256.</p> <ol> <li>Make an HTTP or HTTPS request and I'm going to had to add that header \"x-amz-server-side-encryption\": \"AES256\"</li> <li>We requested server side encryption it's also going to create a manage key and manage data key.</li> </ol>"},{"location":"chap3/8Storage_S3/#7-3-sse-kms","title":"7-3 SSE KMS","text":"<ul> <li>SSE-KMS: encryption using keys handled &amp; managed by KMS</li> <li>KMS Advantages: user control + audit trail </li> <li>Object is encrypted server side</li> <li>Must set header: \"x-amz-server-side-encryption\": \"aws:kms\" </li> </ul> <ul> <li>KMS Customer Master Keys : KMS CMK</li> <li>We transfer the object using HTTP or HTTPS in the header that we set before and so the object is now in S3.</li> <li>And so now the key that is use is a KMS customer master key or CMK</li> </ul>"},{"location":"chap3/8Storage_S3/#7-4-sse-c","title":"7-4 SSE-C","text":"<ul> <li>SSE-C: server-side encryption using data keys fully managed by the customer outside of AWS </li> <li>Amazon S3 does not store the encryption key you provide </li> <li>HTTPS must be used </li> <li>Encryption key must provided in HTTP headers, for every HTTP request made </li> </ul>"},{"location":"chap3/8Storage_S3/#7-5-client-side-encryption","title":"7-5 Client Side Encryption","text":"<ul> <li>Client library such as the Amazon S3 Encryption Client </li> <li>Clients must encrypt data themselves before sending to S3 </li> <li>Clients must decrypt data themselves when retrieving from S3 </li> <li>Customer fully manages the keys and encryption cycle </li> </ul> <p>Left Side</p> <ol> <li>Using the S3 encryption in SDK we will generate a client side data key altogether with the object we will encrypt that data client side.</li> <li>The clients must decrypt the data themselves as well when they retrieved it from S3 </li> <li>The customer fully manages the key and encryption cycle.</li> </ol> <p> </p> <p>We cannot do SSE-C and we cannot do client side encryption from UI but IT's possible to do progrmmatically</p> <p> </p>"},{"location":"chap3/8Storage_S3/#7-6-encryption-in-transit-ssl","title":"7-6 Encryption in transit (SSL)","text":""},{"location":"chap3/8Storage_S3/#aws-s3-exposes","title":"AWS S3 exposes:","text":"<ul> <li>HTTP endpoint: non encrypted</li> <li> <p>HITTPS endpoint: encryption in flight</p> </li> <li> <p>You're free to use the endpoint you want, but HTTPS is recommended </p> </li> <li>HITTPS is mandatory for SSE-C </li> <li>Encryption in flight is also called SSL /TLS </li> </ul>"},{"location":"chap3/8Storage_S3/#8s3-security","title":"8\u3001S3 Security","text":""},{"location":"chap3/8Storage_S3/#8-1-s3-cors-cross-origin-resource-sharing","title":"8-1 S3 CORS (Cross-Origin Resource Sharing)","text":"<ul> <li>If you request data from another website, you need to enable CORS </li> <li>Cross Origin Resource Sharing allows you to limit the number of websites that can request your files in S3 (and limit your costs) </li> <li>It's a popular exam question</li> </ul> <ol> <li>Here's our client and we have mywebsite.com and all the Web</li> <li>The Web site images are my are in my image bucket.</li> <li>So the client connects to the Web site.</li> <li>Now the image bucket looks at the origin of the request mywebsite.com and compares it to the CORS and if the CORS is positive and contains that mywebsite.com it says Yes you're fine you can definitely request that file.</li> </ol>"},{"location":"chap3/8Storage_S3/#8-2-s3-access-logs","title":"8-2 S3 Access Logs","text":"<ul> <li>For audit purpose, you may want to log all access to S3 buckets </li> <li>Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket </li> <li>That data can be analyzed using data analysis tools... </li> <li>Or Amazon Athena as we'll see later in this course!</li> </ul> <ul> <li>The log format is at: https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html  </li> </ul>"},{"location":"chap3/8Storage_S3/#8-3-s3-security","title":"8-3 S3 Security","text":"<p>User based </p> <ul> <li>IAM policies - which API calls should be allowed for a specific user from IAM console </li> </ul> <p>Resource Based </p> <ul> <li>Bucket Policies - bucket wide rules from the S3 console - allows cross account </li> <li>Object Access Control List (ACL) \u2014 finer grain </li> <li>Bucket Access Control List (ACL) \u2014 less common </li> </ul>"},{"location":"chap3/8Storage_S3/#8-4-s3-bucket-policies","title":"8-4 S3 Bucket Policies","text":"<p>JSON based policies </p> <ul> <li>Resources: buckets and objects </li> <li>Actions: Set of API to Allow or Deny </li> <li>Effect: Allow / Deny </li> <li>Principal: The account or user to apply the policy to </li> </ul> <p>Use S3 bucket for policy to: </p> <ul> <li>Grant public access to the bucket </li> <li>Force objects to be encrypted at upload </li> <li>Grant access to another account (Cross Account) </li> </ul>"},{"location":"chap3/8Storage_S3/#8-5-s3-default-encryption-vs-bucket-policies","title":"8-5 S3 Default Encryption vs Bucket Policies","text":"<ul> <li>The old way to enable default encryption was to use a bucket policy and refuse any HTTP command without the proper headers: </li> </ul> <ul> <li>The new way is to use the \"default encryption\" option in S3 </li> </ul> <ul> <li>Note: Bucket Policies are evaluated before \"default encryption\"</li> </ul>"},{"location":"chap3/8Storage_S3/#8-6-s3-security-other","title":"8-6 S3 Security - Other","text":"<p>Networking: </p> <ul> <li>Supports VPC Endpoints (for instances in VPC without www Internet) </li> </ul> <p>Logging and Audit: </p> <ul> <li>S3 access logs can be stored in other 53 bucket</li> <li>API calls can be logged in AWS CloudTrail </li> </ul> <p>User Security: </p> <ul> <li>MFA (multi factor authentication) can be required in versioned buckets to delete objects </li> <li>Signed URLs: URLs that are valid only for a limited time (ex: premium video service for logged in users) </li> </ul>"},{"location":"chap3/8Storage_S3/#9glacier-vault-lock-policies","title":"9\u3001Glacier &amp; Vault Lock Policies","text":""},{"location":"chap3/8Storage_S3/#9-1-glacier","title":"9-1 Glacier","text":"<ul> <li>Low cost object storage meant for archiving / backup  </li> <li>Data is retained for the longer term ( I Os of years) </li> <li>Alternative to on-premise magnetic tape storage \u2022 Average annual durability is 99.999999999%  </li> <li> <p>Cost per storage per month ($0.004 / GB) \u00b1 retrieval cost </p> </li> <li> <p>Each item in Glacier is called \"Archive\" (up to 40TB) </p> </li> <li> <p>Archives are stored in \"Vaults\" </p> </li> <li> <p>Exam tip: archival from S3 after XXX days \u2014&gt; use Glacier</p> </li> </ul>"},{"location":"chap3/8Storage_S3/#9-2-glacier-operations","title":"9-2 Glacier Operations","text":"<ul> <li>Restore links have an expiry date </li> <li>3 retrieval options: <ul> <li>Expedited (1 to 5 minutes retrieval) $0.03 per GB and $0.01 per request </li> <li>Standard (3 to 5 hours) - $0.01 per GB and 0.05 per 1000 requests </li> <li>Bulk (5 to 12 hours) - $0.0025 per GB and $0.025 per 1000 requests </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#9-3-glacier-vault-policies-vault-lock-exam","title":"9-3 Glacier -Vault Policies &amp; Vault Lock (Exam)","text":"<ul> <li>Vault is a collection of archives </li> <li>Each Vault has: <ul> <li>ONE vault access policy </li> <li>ONE vault lock policy </li> </ul> </li> <li>Vault Policies are written in JSON </li> <li>Vault Access Policy is similar to bucket policy (restrict user / account permissions) </li> <li>Vault Lock Policy is a policy you lock, for regulatory and compliance requirements. <ul> <li>The policy is immutable, it can never be changed (that's why it's call LOCK) </li> <li>Example 1: forbid deleting an archive if less than 1 year old </li> <li>Example 2: implement WORM policy (write once read many) </li> </ul> </li> </ul>"},{"location":"chap3/8Storage_S3/#10s3-glacier-select","title":"10\u3001S3 &amp; Glacier Select","text":"<ul> <li>Retrieve less data using SQL by performing server side filtering </li> <li>Can filter by rows &amp; columns (simple SQL statements) </li> <li>Less network transfer, less CPU cost client-side </li> </ul>"},{"location":"chap3/8Storage_S3/#10-1-s3-select-with-hadoop","title":"10-1 S3 Select with Hadoop","text":"<p>Transfer some data from S3 before analyzing it with your cluster </p> <p> </p>"},{"location":"chap3/8Storage_S3/#11s3-event-notification","title":"11\u3001S3 Event Notification","text":"<ul> <li><code>S3:ObjectCreated</code>, <code>S3:ObjectRemoved</code></li> <li><code>S3:ObjectRestore</code>,   <code>S3:Replication</code>... </li> <li>Object name filtering possible <code>(*.jpg)</code> </li> <li>Use case: generate thumbnails of images uploaded to S3 </li> <li> <p>Can create as many \"S3 events\" as desired </p> </li> <li> <p>S3 event notifications typically deliver events in seconds but can sometimes take a minute or longer </p> </li> <li>If two writes are made to a single non-versioned object at the same time, it is possible that only a single event notification will be sent </li> <li>If you want to ensure that an event notification is sent for every successful write, you can enable versioning on your bucket. </li> </ul> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/","title":"L2 DynamoDB","text":""},{"location":"chap3/9Storage_dynamoDB/#l2-dynamodb-overview","title":"L2 DynamoDB Overview","text":"<ul> <li>Fully Managed, Highly available with replication across 3 AZ </li> <li>NoSQL database - not a relational database </li> <li>Scales to massive workloads, distributed database</li> <li>Millions of requests per seconds, trillions of row, 100s of TB of storage </li> <li>Fast and consistent in performance (low latency on retrieval)</li> <li>Integrated with IAM for security, authorization and administration </li> <li>Enables event driven programming with DynamoDB Streams </li> <li>Low cost and auto scaling capabilities </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#1-1-dynamodb-basics","title":"1-1 DynamoDB - Basics","text":"<ul> <li>DynamoDB is made of tables </li> <li> <p>Each table has a primary key (must be decided at creation time)</p> </li> <li> <p>Each table can have an infinite number of items (= rows) </p> </li> <li>Each item has attributes (can be added over time can be null) </li> <li>Maximum size of a item is 400KB </li> <li>Data types supported are: <ul> <li>Scalar Types: String, Number, Binary, Boolean, Null </li> <li>Document Types: List, Map </li> <li>Set Types: String Set, Number Set, Binary Set </li> </ul> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#1-2-dynamodb-primary-key","title":"1-2 DynamoDB \u2014 Primary Key","text":"<ul> <li>Option 1: Partition key only (HASH) </li> <li>Partition key must be unique for each item </li> <li>Partition key must be \"diverse\" so that the data is distributed</li> <li>Example: user id for a users table</li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#1-3-dynamodb-primary-keys","title":"1-3 DynamoDB \u2014 Primary Keys","text":"<ul> <li>Option 2: Partition key + Sort Key </li> <li>The combination must be unique </li> <li>Data is grouped by partition key</li> <li>Sort key == range key </li> <li>Example:  users-games table <ul> <li><code>user_id</code> for the partition key </li> <li><code>game_id</code> for the sort key </li> </ul> </li> </ul> <p>partition key and sort key can be duplicate, but the combination must be unique</p>"},{"location":"chap3/9Storage_dynamoDB/#1-4-dynamodb-partition-keys-exercise","title":"1-4 DynamoDB Partition Keys exercise","text":"<ul> <li>We're building a movie database </li> <li> <p>What is the best partition key to maximize data distribution? </p> <ul> <li><code>movie_id</code> </li> <li><code>producer_name</code> </li> <li><code>leader_actor_name</code></li> <li><code>movie_language</code> </li> </ul> </li> <li> <p>movie_id has the highest cardinality(unqiue) so it's a good candidate </p> </li> <li><code>moving_language</code> doesn't take many values and may be skewed towards English so it's not a great partition key </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#1-5-dynamodb-in-big-data","title":"1-5 DynamoDB in Big Data","text":"<p>Common use cases include: </p> <ul> <li>Mobile apps </li> <li>Gaming </li> <li>Digital ad serving </li> <li>Live voting </li> <li>Audience interaction for live events </li> <li>Sensor networks </li> <li>Log ingestion </li> <li>Access control for web-based content</li> <li>Metadata storage for Amazon S3 objects</li> <li>E-commerce shopping carts</li> <li>Web session management </li> </ul> <p>Anti Pattern </p> <ul> <li>Pre-written application tied to a traditional relational database: use RDS instead </li> <li>joins or complex transactions </li> <li>Binary Large Object (BLOB) data: store data in S3 &amp; metadata in DynamoDB </li> <li>Large data with low I/O rate: use S3 instead </li> </ul> <p>DynamoDB is to be more for data is hot and smaller</p> <p>S3 is goiing to be colder but bigger</p>"},{"location":"chap3/9Storage_dynamoDB/#2dynamodb-rcu-wcu","title":"2\u3001DynamoDB RCU &amp; WCU","text":""},{"location":"chap3/9Storage_dynamoDB/#2-1-dynamodb-provisioned-throughput","title":"2-1 DynamoDB Provisioned Throughput","text":"<ul> <li>Table must have provisioned read and write capacity units </li> <li>Read Capacity Units (RCU): throughput for reads </li> <li>Write Capacity Units (WCU): throughput for writes </li> <li>Option to setup auto-scaling of throughput to meet demand </li> <li>Throughput can be exceeded temporarily using \"burst credit\"</li> <li>If burst credit are empty, you'll get a \"ProvisionedThroughputException\". </li> <li>It's then advised to do an exponential back-off retry </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#2-2-dynamodb-write-capacity-units","title":"2-2 DynamoDB \u2014 Write Capacity Units","text":"<ul> <li>One write capacity unit represents one write per second for an item up to 1 KB in size. </li> <li> <p>If the items are larger than 1 KB, more WCU are consumed </p> </li> <li> <p>Example 1: We write 10 objects per seconds of 2 KB each. </p> </li> </ul> <pre><code>We need 2 * 10 = 20 WCU \n</code></pre> <ul> <li>Example 2: we write 6 objects per second of 4.5 KB each </li> </ul> <pre><code>We need 6 * 5 = 30 WCU  #(4.5 gets rounded to the upper KB)\n</code></pre> <ul> <li>Example 3: we write 120 objects per minute of 2 KB each </li> </ul> <pre><code>We need 120 / 60 * 2 = 4 WCU \n</code></pre>"},{"location":"chap3/9Storage_dynamoDB/#2-3-strongly-consistent-read-vs-eventually-consistent-read","title":"2-3 Strongly Consistent Read vs Eventually Consistent Read","text":"<p>Eventually Consistent Read: </p> <p>If we read just after a write, it's possible we'll get unexpected response because of replication </p> <p>Strongly Consistent Read: </p> <p>If we read just after a write, we will get the correct data </p> <p>By default DynamoDB uses Eventually Consistent Reads, but <code>Getltem</code>, <code>Query</code> &amp; <code>Scan</code> provide a \"ConsistentRead\" parameter you can set to True </p> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#2-3-dynamodb-read-capacity-units","title":"2-3 DynamoDB Read Capacity Units","text":"<ul> <li>One read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. </li> <li>If the items are larger than 4 KB, more RCU are consumed </li> </ul> <p>1 strongly consistent read/s</p> <p>2 eventually consistent reads/s</p> <p>4kb up</p> <ul> <li>Example 1: 10 strongly consistent reads per seconds of 4 KB each </li> </ul> <pre><code>We need 10 * 4 KB / 4 KB = 10 RCU \n</code></pre> <ul> <li>Example 2: 16 eventually consistent reads per seconds of 12 KB each </li> </ul> <pre><code>We need (16 / 2) * ( 12 / 4 ) = 24 RCU \n</code></pre> <ul> <li>Example 3: 10 strongly consistent reads per seconds of 6 KB each </li> </ul> <pre><code>We need 10 * 8 KB / 4 = 20 RCU (we have to round up 6 KB to 8 KB) \n</code></pre>"},{"location":"chap3/9Storage_dynamoDB/#2-4-dynamodb-throttling","title":"2-4 DynamoDB -Throttling","text":"<ul> <li>If we exceed our RCU or WCU, we get ProvisionedThroughputExceededExceptions </li> <li> <p>Reasons: </p> <ul> <li>Hot keys / partitions: one partition key is being read too many times (popular item for ex) </li> <li>Very large items: remember RCU and WCU depends on size of items </li> </ul> </li> <li> <p>Solutions: </p> <ul> <li>Exponential back-off when exception is encountered (already in SDK) </li> <li>Distribute partition keys as much as possible </li> <li>If RCU issue, we can use DynamoDB Accelerator (DAX)</li> </ul> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#2-5-on-demand-rcu-and-wcu","title":"2-5 on-demand RCU and WCU","text":"<p>Select on-demand if you want to pay only for the read and writes you perform, with no capacity planning required. It's pretty expensive</p> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#2-6-capacity-calculator","title":"2-6 Capacity calculator","text":""},{"location":"chap3/9Storage_dynamoDB/#3dynamodb-partitions","title":"3\u3001DynamoDB Partitions","text":""},{"location":"chap3/9Storage_dynamoDB/#3-1-dynamodb-partitions-internal","title":"3-1 DynamoDB - Partitions Internal","text":"<ul> <li>You start with one partition </li> <li> <p>Each partition: </p> <ul> <li>Max of 3000 RCU / 1000 WCU</li> <li>Max of 10GB </li> </ul> </li> <li> <p>To compute the number of partitions:</p> </li> <li> <p>By capacity: <code>(TOTAL RCU / 3000) + (TOTAL WCU / 1000)</code> </p> </li> <li>By size: <code>Total Size / 10 GB</code> </li> <li>Total partitions = <code>CEILING(MAX(Capacity, Size))</code> </li> <li>WCU and RCU are spread evenly between partitions </li> </ul> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#4dynamodb-apis-adus","title":"4\u3001DynamoDB APIs (ADUS)","text":""},{"location":"chap3/9Storage_dynamoDB/#4-1-dynamodb-writing-data","title":"4-1 DynamoDB \u2014 Writing Data","text":"<ul> <li>PutItem - Write data to DynamoDB (create data or full replace) <ul> <li>Consumes WCU </li> </ul> </li> <li>UpdateItem \u2014 Update data in DynamoDB (partial update of attributes) <ul> <li>Possibility to use Atomic Counters and increase them </li> </ul> </li> <li>Conditional Writes: <ul> <li>Accept a write / update only if conditions are respected, otherwise reject </li> <li>Helps with concurrent access to items</li> <li>No performance impact </li> </ul> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#4-2-dynamodb-deleting-data","title":"4-2 DynamoDB \u2014 Deleting Data","text":"<ul> <li> <p>Deleteltem </p> <ul> <li>Delete an individual row </li> <li>Ability to perform a conditional delete </li> </ul> </li> <li> <p>DeleteTable </p> <ul> <li>Delete a whole table and all its items </li> <li>Much quicker deletion than calling Deleteltem on all items </li> </ul> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#4-3-dynamodb-batching-writes","title":"4-3 DynamoDB \u2014 Batching Writes","text":"<ul> <li> <p>BatchWriteltem </p> <ul> <li>Up to 25 Putltem and / or Deleteltem in one call </li> <li>Up to 16 MB of data written </li> <li>Up to 400 KB of data per item </li> </ul> </li> <li> <p>Batching allows you to save in latency by reducing the number of API calls done against DynamoDB </p> </li> <li>Operations are done in parallel for better efficiency </li> <li>It's possible for part of a batch to fail, in which case we have the try the failed items (using exponential back-off algorithm) </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#4-4-dynamodb-reading-data","title":"4-4 DynamoDB \u2014 Reading Data","text":"<ul> <li> <p>GetItem: </p> <ul> <li>Read based on Primary key </li> <li>Primary Key = HASH or HASH-RANGE </li> <li>Eventually consistent read by default </li> <li>ption to use strongly consistent reads (more RCU - might take longer)</li> <li>ProjectionExpression can be specified to include only certain attributes </li> </ul> </li> <li> <p>BatchGetltem: </p> <ul> <li>Up to 100 items </li> <li>Up to 16 MB of data </li> <li>Items are retrieved in parallel to minimize latency </li> </ul> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#4-5-dynamodb-query","title":"4-5 DynamoDB \u2014 Query","text":"<ul> <li>Query returns items based on: <ul> <li>PartitionKey value (must be = operator) </li> <li>SortKey value (=, &lt;, &lt;=, &gt;, &gt;=, Between, Begin) \u2014 optional </li> <li>FilterExpression to further filter (client side filtering) </li> </ul> </li> </ul> <p>Query by PartitionKey</p> <p> </p> <p>Query by PartitionKey + SortKey</p> <p> </p> <p>The only thing you can query is PartitionKey and SortKey</p> <p>You could have filter at the very end and it's client side filtering</p> <p> </p> <ul> <li> <p>Returns: </p> <ul> <li>Up to 1 MB of data </li> <li>Or number of items specified in Limit </li> </ul> </li> <li> <p>Able to do pagination on the results </p> </li> <li>Can query table, a local secondary index, or a global secondary index </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#4-6-dynamodb-scan","title":"4-6 DynamoDB - Scan","text":"<ul> <li>Scan the entire table and then filter out data (inefficient) </li> <li>Returns up to 1 MB of data use pagination to keep on reading </li> <li>Consumes a lot of RCU </li> <li>Limit impact using Limit or reduce the size of the result and pause </li> <li> <p>For faster performance, use parallel scans: </p> <ul> <li>Multiple instances scan multiple partitions at the same time</li> <li>Increases the throughput and RCU consumed </li> <li>Limit the impact of parallel scans just like you would for Scans </li> </ul> </li> <li> <p>Can use a ProjectionExpression \u00b1 FilterExpression (no change to RCU) </p> </li> </ul> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#5dynamodb-indexes-lsi-gsi","title":"5\u3001DynamoDB Indexes: LSI &amp; GSI","text":""},{"location":"chap3/9Storage_dynamoDB/#5-1-dynamodb-lsi-local-secondary-index","title":"5-1 DynamoDB \u2014 LSI (Local Secondary Index)","text":"<ul> <li>Alternate range key for your table, local to the hash key </li> <li>Up to five local secondary indexes per table. </li> <li>The sort key consists of exactly one scalar attribute. </li> <li>The attribute that you choose must be a scalar String, Number, or Binary </li> <li>LSI must be defined at table creation time</li> </ul> <p>Create local secondary indexex with partition key + Sort key</p> <p> </p> <p>LSI must be defined at table creation time</p> <p> </p> <p>instead Query table, you can query index</p> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#5-2-dynamodb-gsi-global-secondary-index","title":"5-2 DynamoDB \u2014 GSI (Global Secondary Index)","text":"<ul> <li>To speed up queries on non-key attributes, use a Global Secondary Index </li> <li>GSI = partition key \u00b1 optional sort key </li> <li> <p>The index is a new \"table\" and we can project attributes on it </p> <ul> <li>The partition key and sort key of the original table are always projected (KEYS_ONLY) </li> <li>Can specify extra attributes to project (INCLUDE) </li> <li>Can use all attributes from main table (ALL)</li> </ul> </li> <li> <p>Must define RCU /WCU for the index</p> </li> <li>Possibility to add / modify GSI (not LSI)</li> </ul> <p> </p> <p> </p> <p>partition key + Sort key</p> <p>Add RCU /WCU for the index</p> <p> </p> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#6dynamodb-dax","title":"6\u3001DynamoDB DAX","text":"<ul> <li>DAX = DynamoDB Accelerator </li> <li>Seamless cache for DynamoDB, no application re-write </li> <li>Writes go through DAX to DynamoDB </li> <li>Micro second latency for cached reads &amp; queries </li> <li>Solves the Hot Key problem (too many reads) </li> <li>5 minutes TTL for cache by default </li> <li>Up to 10 nodes in the cluster</li> <li>Multi AZ (3 nodes minimum recommended for production) </li> <li>Secure (Encryption at rest with KMS,VPC, IAM, CloudTrail...) </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#7dynamodb-streams","title":"7\u3001DynamoDB Streams","text":"<ul> <li>Changes in DynamoDB (Create, Update, Delete) can end up in a DynamoDB Stream </li> <li> <p>This stream can be read by AWS Lambda, and we can then do: </p> <ul> <li>React to changes in real time (welcome email to new users) </li> <li>Create derivative tables / views </li> <li>Insert into ElasticSearch </li> </ul> </li> <li> <p>Could implement Cross Region Replication using Streams </p> </li> <li>Stream has 24 hours of data retention \u3011</li> <li>Configurable batch size (up to 1,000 rows, 6 MB) </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#7-1-dynamodb-streams-kinesis-adapater","title":"7-1 DynamoDB Streams Kinesis Adapater","text":"<ul> <li>Use the KCL library to directly consume from DynamoDB Streams </li> <li>You just need to add a \"Kinesis Adapter\" library </li> <li>The interface and programming is exactly the same as Kinesis Streams </li> <li>That's the alternative to using AWS Lambda </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#8dynamodb-ttl-time-to-live","title":"8\u3001DynamoDB TTL (Time to Live)","text":"<ul> <li>TTL = automatically delete an item after an expiry date / time </li> <li>TTL is provided at no extra cost, deletions do not use WCU / RCU </li> <li>TTL is a background task operated by the DynamoDB service itself </li> <li>Helps reduce storage and manage the table size over time</li> <li>Helps adhere to regulatory norms </li> <li>TTL is enabled per row (you define a TTL column, and add a date there) </li> <li>DynamoDB typically deletes expired items within 48 hours of expiration </li> <li>Deleted items due to TTL are also deleted in GSI / LSI </li> <li>DynamoDB Streams can help recover expired items </li> </ul> <p>TTL is enabled per row</p> <p>Add attribute: expire_on</p> <p> </p> <p> </p> <p>https://www.epochconverter.com/</p> <p>Enable TTL on table level</p> <p> </p>"},{"location":"chap3/9Storage_dynamoDB/#9dynamodb-security-other-features","title":"9\u3001DynamoDB \u2014 Security &amp; Other Features","text":""},{"location":"chap3/9Storage_dynamoDB/#9-1-security","title":"9-1 Security:","text":"<ul> <li>VPC Endpoints available to access DynamoDB without internet </li> <li>Access fully controlled by IAM </li> <li>Encryption at rest using KMS </li> <li>Encryption in transit using SSL /TLS \u2022 </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#9-2-backup-and-restore-feature-available","title":"9-2 Backup and Restore feature available","text":"<ul> <li>Point in time restore like RDS</li> <li>No performance impact </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#9-2-global-tables","title":"9-2 Global Tables","text":"<ul> <li>Multi region, fully replicated, high performance </li> </ul> <p>Amazon Database Migration Service (DMS) can be used to migrate to DynamoDB (from Mongo, Oracle,TlySQL, S3, etc...) </p> <ul> <li>You can launch a local DynamoDB on your computer for development purposes </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#10dynamodb-storing-large-objects","title":"10\u3001DynamoDB: Storing Large Objects","text":""},{"location":"chap3/9Storage_dynamoDB/#10-1-dynamodb-storing-large-objects","title":"10-1 DynamoDB Storing large objects","text":"<ul> <li>Max size of an item in DynamoDB = 400 KB </li> <li>For large objects, store them in S3 and reference them in DynamoDB</li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#10-2-dynamodb-price-comparison-for-300-kb","title":"10-2 DynamoDB - Price comparison for 300 KB","text":"<ul> <li> <p>Amazon S3 (300KB of storage) </p> <ul> <li><code>$0.0000069</code> storage per month </li> <li><code>$0.0000050</code> initial PUT </li> <li><code>$0.0000004</code> per GET </li> </ul> </li> <li> <p>DynamoDB (&lt; 1 KB of storage) </p> <ul> <li><code>$0.0006500</code> for one WCU per month </li> <li><code>$0.0001300</code> for one RCU per month </li> <li><code>$0.00000025</code> storage per month </li> </ul> </li> <li> <p>Assuming I write, 100 reads per month: </p> <ul> <li><code>$0.00119215</code> per month </li> </ul> </li> </ul> <p> </p> <ul> <li> <p>DynamoDB (300 KB of storage) </p> <ul> <li><code>$0.195</code> for <code>300</code> WCU per month </li> <li><code>$0.004940</code> for <code>38</code> RCU per month </li> <li><code>$0.000075</code> storage per month </li> </ul> </li> <li> <p>Assuming I write, 100 reads per month: </p> <ul> <li>Storage is  11x more expensive </li> <li>WCU + RCU are under-used </li> </ul> </li> <li> <p>Even for items that fit in DynamoDB, if under-used, S3 + DynamoDB is a solution </p> </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#11-aws-elasticache-overview","title":"11 AWS ElastiCache Overview","text":"<ul> <li>The same way RDS is to get managed Relational Databases... </li> <li>ElastiCache is to get managed Redis or Memcached </li> <li>Caches are in-memory databases with really high performance, low latency </li> <li>Helps reduce load off of databases for read intensive workloads </li> <li>Helps make your application stateless </li> <li>Write Scaling using sharding </li> <li>Read Scaling using Read Replicas </li> <li>Multi AZ with Failover Capability</li> <li>AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#11-1-redis-overview","title":"11-1 Redis Overview","text":"<ul> <li>Redis is an in-memory key-value store </li> <li>Super low latency (sub ms) </li> <li>Cache survive reboots by default (it's called persistence) </li> <li>Great to host <ul> <li>User sessions </li> <li>Leaderboard (for gaming) </li> <li>Distributed states </li> <li>Relieve pressure on databases (such as RDS) Pub / Sub capability for messaging </li> </ul> </li> <li>Multi AZ with Automatic Failover for disaster recovery if you don't want to lose your cache data </li> <li>Support for Read Replicas </li> </ul>"},{"location":"chap3/9Storage_dynamoDB/#11-2-memcached-overview","title":"11-2 Memcached Overview","text":"<ul> <li>Memcached is an in-memory object store(Like S3) </li> <li>Cache doesn't survive reboots </li> <li>Use cases: <ul> <li>Quick retrieval of objects from memory </li> <li>Cache often accessed objects </li> </ul> </li> <li>Overall, Redis has largely grown in popularity and has better feature sets than Memcached. </li> <li>I would personally only use Redis for caching needs. </li> </ul>"},{"location":"chap4/11Process_Lambda/","title":"L1 AWS Lambda","text":"<p>Serverless Data processing</p> <p> </p>"},{"location":"chap4/11Process_Lambda/#1what-is-lambda","title":"1\u3001What is Lambda?","text":"<ul> <li>A way to run code snippets \"in the cloud\" <ul> <li>Serverless </li> <li>Continuous scaling </li> </ul> </li> <li>Often used to process data as it's moved around <ul> <li>Some services don't talk directly to other services in AWS but lambda can be used as the glue between these services </li> <li>So it can sit there and get triggered by some other service sending data into it like a Kinesis data stream reformat that information into a format required by some other service send that data to another service for further processing and maybe retrieve that data and send it back.</li> </ul> </li> </ul>"},{"location":"chap4/11Process_Lambda/#2example-serverless-website","title":"2\u3001Example: Serverless Website","text":"<ol> <li>Build your Web site by just having static html and ajax calls embedded within that html well you can serve that from S3</li> <li>You have an API Gateway in Amazon it sort of serves as the wall between the outside clients and you the the interior of your system there.</li> <li>User Log in request go through the API Gateway which in turn would then get sent off to AWS Lambda Lambda would say OK the Web site wants this person to log in</li> <li>It could turn around and craft request to Amazon Cognito to say do you authenticate this user or not Amazon Cognito will come back and say Sure here's your token lambda could then format that result and send it back to the Web site.</li> <li>Or It would then turn around craft that request a DynamoDB for that chat history.</li> <li>Talk to DynamoDB to get that and then send it back through the API Gateway back to the Web site.</li> </ol>"},{"location":"chap4/11Process_Lambda/#3example-transcation-rate-alarm","title":"3\u3001Example: Transcation rate alarm","text":"<ol> <li>Kinesis data stream that's receiving events it says something weird is going on that requires someone's attention.</li> <li>Lambda is going to be triggered by those data stream events </li> <li>Lambda will then turn around and craft an SNS request to actually send out a message to your cell phone notifying you that something requires our attention.</li> </ol>"},{"location":"chap4/11Process_Lambda/#4lambda-integration","title":"4\u3001Lambda Integration","text":""},{"location":"chap4/11Process_Lambda/#4-1-why-not-just-run-a-server","title":"4-1 Why not just run a server?","text":"<ul> <li>Server management (patches, monitoring, hardware failures, etc.) </li> <li>Servers can be cheap, but scaling gets expensive really fast</li> <li>You don't pay for processing time you don't use </li> <li>Easier to split up development between front-end and back-end </li> </ul>"},{"location":"chap4/11Process_Lambda/#4-2-main-uses-of-lambda","title":"4-2 Main uses of Lambda","text":"<ul> <li>Real-time file processing </li> <li>Real-time stream processing </li> <li>ETL </li> <li>Cron replacement </li> <li>Process AWS events </li> </ul>"},{"location":"chap4/11Process_Lambda/#4-3-supported-languages","title":"4-3 Supported languages","text":"<ul> <li>Node.js </li> <li>Python </li> <li>Java </li> <li>C# </li> <li>Go </li> <li>Powershell </li> <li>Ruby </li> </ul>"},{"location":"chap4/11Process_Lambda/#4-4-lambda-triggers","title":"4-4 Lambda triggers","text":"<ol> <li>DynamoDB table that can trigger event data that invokes a lambda function as well and that allows for real time event driven data processing for the data arriving in dynamo DB tables</li> <li>You can integrate lambda with Kinesis streams and then the lambda function can read records from a stream and be processed accordingly</li> <li>Kinesis isn't actually pushing that data into lambda as the architectural diagrams might suggest lambda actually pulls that stream periodically and collects information from it in a batch manner.</li> </ol>"},{"location":"chap4/11Process_Lambda/#4-5-lambda-and-amazon-elasticsearch-service","title":"4-5 Lambda and Amazon ElasticSearch Service","text":"<ol> <li>data being sent into Amazon S3 like a data lake</li> <li>object creation in S3 can then trigger off a lambda function </li> <li>lambda function processes that data and send to the Amazon Elastic search service.</li> </ol>"},{"location":"chap4/11Process_Lambda/#4-6-lambda-and-data-pipeline","title":"4-6 Lambda and Data Pipeline","text":"<ol> <li>Object comes into S3 and we might trigger in a lambda function there to process that data </li> <li>Kick off a data pipeline to process that data further.</li> </ol> <p>Normally data pipeline you can schedule activities where you can define preconditions that see whether or not data exists on S3 and then allocate resources accordingly.</p> <p>But by using lambda that's a better mechanism because data pipeline can be activated at any random time and not on a fixed schedule.</p>"},{"location":"chap4/11Process_Lambda/#4-7-lambda-and-redshift","title":"4-7 Lambda and Redshift","text":"<p>We're going to copy data in one record at a time we could just do that by having a trigger from S3 that says OK some new data was received in S3 lambda go deal with it your lambda function will turn around and Insert that into your redshift database but that's not very efficient</p> <p>It's better batch things up and send it in together in a parallel manner.</p> <p>The problem here is that lambda cannot have any stateful information so there's no way to pass information from one call of lambda to another.</p> <p>The reason being that your lambda function could be deployed on many different servers all running concurrently at the same time.</p> <ol> <li>S3 as triggering off an event a Lambda Lambda</li> <li>Using dynamo DB to keep track of how much data has been received so far.</li> <li>When hit some threshold we'll batch that up and actually copy it into redshift altogether at once.</li> </ol>"},{"location":"chap4/11Process_Lambda/#4-8-lambda-kinesis-exam","title":"4-8 Lambda + Kinesis [exam]","text":"<ul> <li> <p>Your Lambda code receives an event with a batch of stream records </p> <ul> <li>You specify a batch size when setting up the trigger (up to 10,000 records) </li> <li>Too large a batch size can cause timeouts!</li> <li>Batches may also be split beyond Lambda's payload limit (6 MB) </li> </ul> </li> <li> <p>Lambda will retry the batch until it succeeds or the data expires </p> <ul> <li>This can stall the shard if you don't handle errors properly </li> <li>Use more shards to ensure processing isn't totally held up by errors </li> </ul> </li> <li>Lambda processes shard data synchronously </li> </ul>"},{"location":"chap4/11Process_Lambda/#5lambda-costs-promises-and-anti-patterns","title":"5\u3001Lambda Costs, Promises, and Anti-Patterns","text":""},{"location":"chap4/11Process_Lambda/#5-1-cost-model","title":"5-1 Cost Model","text":"<ul> <li>\"Pay for what you use\" </li> <li>Generous free tier (1M requests / month, 400K GB-seconds compute time) </li> <li><code>$0.2</code> / million requests </li> <li><code>$.00001667</code> per GB/second </li> </ul>"},{"location":"chap4/11Process_Lambda/#5-2-other-promises","title":"5-2 Other promises","text":"<ul> <li>High availability  </li> <li>Unlimited scalability</li> <li>High performance  <ul> <li>But you do specify a timeout! This can cause problems. Max is 900 seconds. </li> </ul> </li> </ul> <p>If you're trying to do something in a lambda function that takes more than 900 seconds lambda is not the tool for you or maybe you need to reduce your batch size to reduce the load of that individual function call.</p>"},{"location":"chap4/11Process_Lambda/#5-3-anti-patterns","title":"5-3 Anti-patterns","text":"<ul> <li>Long-running applications </li> </ul> <p>You should be using EC2 instead or you can also chain multiple lambda functions together.</p> <ul> <li>Dynamic websites </li> </ul> <p>EC2 and Cloud Front is a better choice for a building dynamic web sites.</p> <ul> <li>Stateful applications </li> </ul> <p>You can't maintain information from one lambda call to another. Like we said it is stateless but you can store state information in DynamoDB or S3</p>"},{"location":"chap4/12Process_Lambda_Exer/","title":"L2 [Exercise] AWS Lambda","text":""},{"location":"chap4/12Process_Lambda_Exer/#1requirement-order-history-app","title":"1\u3001Requirement : Order history app","text":""},{"location":"chap4/12Process_Lambda_Exer/#2create-iam-role-enable-aws-lambda","title":"2\u3001Create IAM role enable AWS Lambda","text":"<p>Policies</p> <ul> <li>Read only access from Kinesis</li> <li>DynamoDB Full Access</li> </ul> <p> </p>"},{"location":"chap4/12Process_Lambda_Exer/#3aws-lambda-function","title":"3\u3001AWS Lambda Function","text":"<ul> <li>Runtime: python 3.6</li> <li>Excuting role: existing role</li> </ul>"},{"location":"chap4/12Process_Lambda_Exer/#3-1-add-lambda-trigger","title":"3-1 Add Lambda trigger","text":""},{"location":"chap4/12Process_Lambda_Exer/#3-2-runtime-code","title":"3-2 Runtime code","text":"<p><code>lambda_function.py</code></p> <pre><code>import base64\nimport json\nimport boto3\nimport decimal\n\ndef lambda_handler(event, context):\n    item = None\n    dynamo_db = boto3.resource('dynamodb')\n    table = dynamo_db.Table('CadabraOrders')\n    decoded_record_data = [base64.b64decode(record['kinesis']['data']) for record in event['Records']]\n    deserialized_data = [json.loads(decoded_record) for decoded_record in decoded_record_data]\n\n    with table.batch_writer() as batch_writer:\n        for item in deserialized_data:\n            invoice = item['InvoiceNo']\n            customer = int(item['Customer'])\n            orderDate = item['InvoiceDate']\n            quantity = item['Quantity']\n            description = item['Description']\n            unitPrice = item['UnitPrice']\n            country = item['Country'].rstrip()\n            stockCode = item['StockCode']\n\n            # Construct a unique sort key for this line item\n            orderID = invoice + \"-\" + stockCode\n\n            batch_writer.put_item(                        \n                Item = {\n                                'CustomerID': decimal.Decimal(customer),\n                                'OrderID': orderID,\n                                'OrderDate': orderDate,\n                                'Quantity': decimal.Decimal(quantity),\n                                'UnitPrice': decimal.Decimal(unitPrice),\n                                'Description': description,\n                                'Country': country\n                        }\n            )\n\n</code></pre>"},{"location":"chap4/12Process_Lambda_Exer/#3-3-generate-log","title":"3-3 Generate Log","text":"<pre><code>./LogGenerator.py 10\n</code></pre>"},{"location":"chap4/13Process_ETL_intro/","title":"L3 AWS Glue &amp; Lake Formation","text":""},{"location":"chap4/13Process_ETL_intro/#1what-is-glue-partitioning-your-data-lake","title":"1\u3001What is Glue? + Partitioning your Data Lake","text":"<p>Table definitions and ETL </p> <p>Basically ETL can define table definitions and perform ETL on your underlying data lake and provide structure to unstructured data.</p> <p> </p>"},{"location":"chap4/13Process_ETL_intro/#1-1-what-is-glueaws-glue-metadata-repo-for-ur-data","title":"1-1 What is Glue?(AWS Glue: Metadata repo for ur data)","text":"<ol> <li>AWS Glue  main use is to serve as a central metadata repository for your data lake in S3 so it's able to discover schemas or table definitions and publish those for use with analysis tools such as Athena or redshift or EMR down the road.</li> <li>AWS Glue do custom ETL jobs on your data so as it's finding new data in S3 it can actually trigger off jobs to actually transform that data into a more structured or purpose built format for later processing.</li> <li> <p>AWS Glue ETL jobs use Apache Spark is completely serverless and fully managed. <li> <p>Serverless discovery and definition of table definitions and schema</p> <ul> <li>S3 \"data lakes\" </li> <li>RDS </li> <li>Redshift </li> <li>Most other SQL databases </li> </ul> </li> <li> <p>Custom ETL jobs </p> <ul> <li>Trigger-driven, on a schedule, or on demand </li> <li>Fully managed </li> </ul> </li>"},{"location":"chap4/13Process_ETL_intro/#1-2-glue-crawler-data-catalog","title":"1-2 Glue Crawler / Data Catalog","text":""},{"location":"chap4/13Process_ETL_intro/#1-3-aws-glue-crawler","title":"1-3 AWS glue crawler","text":"<p>AWS glue crawler is one component of glue.</p> <ul> <li>Basically it scans your data in S3 and often the glue crawler will infer a schema automatically just based on the structure of the data that it finds there in your S3 buckets.</li> <li>You can schedule that crawler to run periodically if you need to.</li> <li>Example: If you have new data or new types of data just popping into S3 at random times, Glue can discover those automatically and just run on a schedule and automatically pick up that data</li> </ul>"},{"location":"chap4/13Process_ETL_intro/#1-4-glue-data-catalogue","title":"1-4 Glue data catalogue","text":"<p>Glue data catalogue is a central metadata repository used by all the other tools that might analyze that data.</p> <ul> <li>The data itself remains where it was originally in S3.</li> <li>Only the table definition itself is stored by glue in the glue data catalog. Means things like the column names the types of data in those columns where that data is stored</li> <li>Glue data catalog just tells these other services like spectrum or Athena or EMR how to interpret that data and how it's structured.</li> </ul>"},{"location":"chap4/13Process_ETL_intro/#1-5-glue-and-s3-partitions","title":"1-5 Glue and S3 Partitions","text":"<p>Glue cannot work magic and automatically structure your data in S3 </p> <ul> <li>Glue crawler will extract partitions based on how your S3 data is organized </li> <li>Think up front about how you will be querying your data lake in S3 </li> <li>Example: devices send sensor data every hour </li> <li>Do you query primarily by time ranges? <ul> <li>If so, organize your buckets as <code>yyyy/mm/dd/device</code> </li> </ul> </li> <li>Do you query primarily by device? <ul> <li>If so, organize your buckets as <code>device/yyyy/mm/dd</code> </li> </ul> </li> </ul> <p> </p>"},{"location":"chap4/13Process_ETL_intro/#2glue-hive","title":"2\u3001Glue + Hive","text":"<p>Apache Hive runs on Elastic MapReduce that allows you to issue SQL like queries on data accessible to your EMR cluster</p> <ul> <li>AWS glue data catalog as metadata store for hive </li> <li>And also can import a hive meta store into glue.</li> <li>The glue data catalog can provide metadata information to hive on EMR.</li> </ul>"},{"location":"chap4/13Process_ETL_intro/#2-1-glue-etl","title":"2-1 Glue ETL","text":"<ul> <li>Can automatically generate code for you to perform that ETL after you define the transformations you want to make to your data in a graphical manner.</li> <li>Scala or Python </li> <li>Encryption  <ul> <li>Server-side (at rest) </li> <li>SSL (in transit) </li> </ul> </li> <li>Can be event-driven </li> </ul> <p>It can be run in response to new data being discovered for example.</p> <ul> <li>Can provision additional \"DPU's\" (data processing units) to increase performance of underlying Spark jobs </li> <li>Errors reported to CloudWatch </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#3glue-etl-developer-endpointsrunning-etl-jobs-with-bookmarks","title":"3\u3001Glue ETL: Developer Endpoints,Running ETL Jobs with Bookmarks","text":""},{"location":"chap4/13Process_ETL_intro/#3-1-glue-etl","title":"3-1 Glue ETL","text":"<ul> <li>Transform data, Clean Data, Enrich Data (before doing analysis) <ul> <li>Generate ETL code in Python or Scala, you can modify the code </li> <li>Can provide your own Spark or PySpark scripts </li> <li>Target can be S3, JDBC (RDS, Redshift), or in Glue Data Catalog </li> </ul> </li> <li>Fully managed, cost effective, pay only for the resources consumed </li> <li>Jobs are run on a serverless Spark platform </li> <li>Glue Scheduler to schedule the jobs </li> <li>Glue Triggers to automate job runs based on \"events\" </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#3-2-glue-etl-transformations","title":"3-2 Glue ETL - Transformations","text":"<ul> <li> <p>Bundled Transformations:  </p> <ul> <li>DropFields, DropNullFields \u2014 remove (null) fields </li> <li>Filter \u2014 specify a function to filter records </li> <li>Join \u2014 to enrich data </li> <li>Map - add fields, delete fields, perform external lookups \u2022 </li> </ul> </li> <li> <p>Machine Learning Transformations:  </p> <ul> <li>FindMatches ML: identify duplicate or matching records in your dataset, even when the records do not have a common unique identifier and no fields match exactly.</li> </ul> </li> </ul> <p>You have multiple vendor is multiple third party merchants submitting their different products into the catalog. And often they're selling the same thing just under slightly different names or slightly different descriptions with fine matches that Mel. You can train that system on a known set of duplicate items and it will learn from that training set and use that information to identify future duplicates going forward that might not be exact matches but still represent the same thing.</p> <ul> <li>Format conversions: CSV, JSON, Avro, Parquet, ORC, XML </li> <li>Apache Spark transformations (example: K-Means) </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#3-3-aws-glue-development-endpoints","title":"3-3 AWS Glue Development Endpoints","text":"<ul> <li> <p>Develop ETL scripts using a notebook </p> <ul> <li>Then create an ETL job that runs your script (using Spark and Glue) </li> </ul> </li> <li> <p>Endpoint is in a VPC controlled by security groups, connect via: </p> <ul> <li>Apache Zeppelin on your local machine </li> <li>Zeppelin notebook server on EC2 (via Glue console) </li> <li>SageMaker notebook </li> <li>Terminal window</li> <li>PyCharm professional edition </li> <li>Use Elastic IP's to access a private endpoint address </li> </ul> </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#3-4-running-glue-jobs","title":"3-4 Running Glue jobs","text":"<ul> <li>Time-based schedules (cron style) </li> </ul> <p>You can there's a glue scheduler that lets you run these on some sort of fixed frequency.</p> <ul> <li>Job bookmarks <ul> <li>Persists state from the job run </li> <li>Prevents reprocessing of old data </li> <li>Allows you to process new data only when re-running on a schedule</li> <li>Works with S3 sources in a variety of formats </li> </ul> </li> </ul> <p>Mostly job bookmarks are used with S3 data links.</p> <ul> <li>Works with relational databases via JDBC (if PK'[primary key]s are in sequential order) </li> <li> <p>Only handles new rows, not updated rows</p> </li> <li> <p>CloudWatch Events </p> <ul> <li>Fire off a Lambda function or SNS notification when ETL succeeds or fails </li> <li>Invoke EC2 run, send event to Kinesis, activate a Step Functior, </li> </ul> </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#4glue-costs-and-anti-patterns","title":"4\u3001Glue Costs and Anti-Patterns","text":""},{"location":"chap4/13Process_ETL_intro/#4-1-glue-cost-model","title":"4-1 Glue cost model","text":"<ul> <li>Billed by the minute for crawler and ETL jobs </li> <li>First million objects stored and accesses are free for the Glue Data Catalog</li> <li>Development endpoints for developing ETL code charged by the minute </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#4-2-glue-anti-patterns","title":"4-2 Glue Anti-patterns","text":"<ul> <li>Streaming data (Glue is batch oriented, minimum 5 minute intervals)</li> </ul> <p>Now if you must ETL your data while streaming it in it would be a better idea to perform your ETL using Kinesis, store the data in S3 or redshift, and then trigger glue ETL to continue transforming it.</p> <p>Or you use a trigger to actually kick off ETL on demand after your data has been coming in from some stream someplace now gclue ETL is implemented in spark.</p> <ul> <li>Multiple ETL engines </li> </ul> <p>You're going to be running jobs using other engines such as Hive or pig or something data pipeline or EMR might be a better choice for doing that ETL than glue ETL.</p> <ul> <li>NoSQL databases </li> </ul> <p>Glue does not support NoSQL databases such as DynamoDB and that wouldn't make sense anyway because NoSQL databases don't require a rigid schema. Glue provides a schema for unstructured data for databases or analysis tools that require some sort of structure to the data</p>"},{"location":"chap4/13Process_ETL_intro/#5aws-glue-studio","title":"5\u3001AWS Glue Studio","text":"<ul> <li>Visual interface for ETL workflows </li> <li> <p>Visual job editor </p> <ul> <li>Create DAG's for complex workflows </li> <li>Sources include S3, Kinesis, Kafka, JDBC </li> <li>Transform / sample / join data </li> <li>Target to S3 or Glue Data Catalog </li> <li>Support partitioning </li> </ul> </li> <li> <p>Visual job dashboard </p> <ul> <li>Overviews, status, run times </li> </ul> </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#5-1-create-aws-glue-studio-job","title":"5-1 Create AWS Glue Studio Job","text":"<ul> <li>Source: S3</li> <li>Target: S3</li> </ul> <p>Add filter and filter condition</p> <p> </p> <p> </p>"},{"location":"chap4/13Process_ETL_intro/#6aws-glue-databrew","title":"6\u3001AWS Glue Databrew","text":"<p>A visual data preparation tool</p> <ul> <li>UI for pre-processing large data sets </li> <li>Input from S3, data warehouse, or database </li> <li>Output to S3 </li> </ul> <p>Over 250 ready-made transformations </p> <p>You create \"recipes\" of transformations that can be saved as jobs within a larger project </p> <p>Security</p> <ul> <li>Can integrate with KMS (with customer master keys only) </li> <li>SSL in transit </li> <li>IAM can restrict who can do what </li> <li>CloudWatch &amp; CloudTrail </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#6-1-create-databrew-project","title":"6-1 Create Databrew Project","text":"<ul> <li>Add role</li> </ul> <ul> <li>Generate Sample Data</li> </ul> <ul> <li>Apply transformation and filter</li> </ul> <ul> <li>Add filter</li> </ul> <p>It's relatively a new feature and possibly an alternative to using Glue ETL</p>"},{"location":"chap4/13Process_ETL_intro/#7aws-glue-elastic-views","title":"7\u3001AWS Glue Elastic Views","text":"<ul> <li>Coming soon! </li> <li>Builds materialized views from Aurora, RDS, DynamoDB </li> <li>Those views can be used by Redshift, Elasticsearch, S3, DynamoDB, Aurora, RDS </li> <li>SQL interface</li> <li>Handles any copying or combining / replicating data needed </li> <li>Monitors for changes and continuously updates</li> <li>Serverless </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#8aws-lake-formation","title":"8\u3001AWS Lake Formation","text":""},{"location":"chap4/13Process_ETL_intro/#8-1-aws-lake-formation","title":"8-1 AWS Lake Formation","text":"<ul> <li>\"Makes it easy to set up a secure data lake in days\" </li> <li>Loading data &amp; monitoring data flows </li> <li>Setting up partitions </li> <li>Encryption &amp; managing keys </li> <li>Defining transformation jobs &amp; monitorng them </li> <li>Access control </li> <li>Auditing </li> <li>Built on top of Glue </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#8-2-aws-lake-formation-pricing","title":"8-2 AWS Lake Formation: Pricing","text":"<ul> <li>No cost for Lake Formation itself </li> <li>But underlying services incur charges <ul> <li>Glue </li> <li>S3 </li> <li>EMR </li> <li>Athena </li> <li>Redshift </li> </ul> </li> </ul>"},{"location":"chap4/13Process_ETL_intro/#8-3-aws-lake-formation-building-a-data-lake","title":"8-3 AWS Lake Formation: Building a Data Lake","text":""},{"location":"chap4/13Process_ETL_intro/#8-4-aws-lake-formation-the-finer-points","title":"8-4 AWS Lake Formation: the Finer Points","text":"<ul> <li> <p>Cross-account Lake Formation permission </p> <ul> <li>Recipient must be set up as a data lake administrator </li> <li>Can use AWS Resource Access Manager for accounts external to your organization </li> <li>IAM permissions for cross-account access </li> </ul> </li> <li> <p>Lake Formation does not support manifests in Athena or Redshift queries </p> </li> <li>IAM permissions on the KMS encryption key are needed for encrypted data catalogs in Lake Formation </li> <li>IAM permissions needed to create blueprints and workflows </li> </ul>"},{"location":"chap4/15process_DataPipeline/","title":"L6 AWS Data Pipeline","text":""},{"location":"chap4/15process_DataPipeline/#1data-pipeline-example","title":"1\u3001Data Pipeline Example","text":"<p>Basically data pipeline lets you schedule tasks for processing your big data.</p> <ol> <li>Log files that are published on EC2 instances.</li> <li>We need to publish those log files into S3 and later analyze them using EMR.</li> <li>data pipeline can schedule a daily task or whatever frequency you want to copy those log files from EC2 into S3 </li> </ol> <p>Basically it's a web service that helps you reliably process and move data between different AWS compute(EC2) and storage(S3) services at specified intervals.</p>"},{"location":"chap4/15process_DataPipeline/#2data-pipeline-features","title":"2\u3001Data Pipeline Features","text":"<ul> <li>Destinations include S3, RDS, DynamoDB, Redshift and EMR</li> <li>Manages task dependencies </li> <li>Retries and notifies on failures</li> <li>Cross-region pipelines </li> <li>Precondition checks </li> <li>Data sources may be on-premises </li> <li>Highly available </li> </ul>"},{"location":"chap4/15process_DataPipeline/#2-1-precondition-checks","title":"2-1 Precondition checks","text":"<p>DynamoDB Precondition :</p> <p>Data exists so that can check for the existence of data inside a dynamo db table before you try to move it or process it somewhere else.</p> <p>Dynamo db table exists that can check for the existence of an entire table for S3 :</p> <p>S3 key exists and S3 prefix exists which can both be used to test for the existence of either a specific path in S3 or a specific prefix you know sort of a path that exists within S3 itself.</p> <p>shell command precondition : </p> <p>This runs an arbitrary script of your own on your resources and checks that the script succeeds.</p>"},{"location":"chap4/15process_DataPipeline/#2-2-data-pipeline-activities","title":"2-2 Data Pipeline Activities","text":"<ul> <li>EMR<ul> <li>Spin up an EMR instance and run a sequence of steps automatically and then automatically terminate the cluster when it's done. </li> </ul> </li> <li>Hive <ul> <li>Allows you to execute hive queries on a schedule. </li> </ul> </li> <li>Copy <ul> <li>Copy data between Amazon S3 and JBDC data sources or run a SQL query and copy its output into Amazon S3. </li> </ul> </li> <li>SQL </li> <li>Scripts<ul> <li>Run arbitrary Linux shell commands or programs as part of your data pipeline.  </li> </ul> </li> </ul>"},{"location":"chap4/15process_DataPipeline/#2-3-custom-data-pipeline-activities","title":"2-3 Custom Data Pipeline Activities","text":"<p>You can specify this as a custom activity or will be automatically added if you're using any of the templates specified by AWS during the pipeline creation.</p> <ul> <li>Default activity: will retry three times before entering a hard failure state.</li> <li>You can increase the number of automatic retry up to 10 if you want to after an activity exhaust its attempts it will trigger any configured on failure alarm </li> </ul>"},{"location":"chap4/15process_DataPipeline/#3aws-step-functions-a-high-level-overview","title":"3\u3001AWS Step Functions - a high-level overview","text":"<ul> <li>Use to design workflows </li> <li>Easy visualizations </li> <li>Advanced Error Handling and Retry mechanism outside the code</li> <li>Audit of the history of workflows </li> <li>Ability to \"Wait\" for an arbitrary amount of time </li> <li>Max execution time of a State Machine is 1 year </li> </ul>"},{"location":"chap4/15process_DataPipeline/#3-1-step-functions-examples-train-a-machine-learning-model","title":"3-1 Step Functions Examples Train a Machine Learning Model","text":"<p>generate the data set =&gt; (kicking off a lambda function) =&gt; Trains the model using Sage makers x g boost algorithm =&gt;  saves that trained model from stage maker  =&gt; Applies a batch transform to that model from some data set that we had at that point</p> <ul> <li>When it's done it extracts that model path and then it saves the tuned model that it's settled on.</li> <li>We extract the model name of the tune model and then use that to apply a transformation of a bunch of data in a batch format to that tuned model automatically.</li> </ul>"},{"location":"chap4/15process_DataPipeline/#3-2-step-functions-examples-tune-a-machine-learning-model","title":"3-2 Step Functions Examples Tune a Machine Learning Model","text":""},{"location":"chap4/15process_DataPipeline/#3-3-step-functions-examples-manage-a-batch-job","title":"3-3 Step Functions Examples Manage a Batch Job","text":"<p>You just need to know that they manage workflows and they give you a nice graphical representation of those workflows and they can monitor whether individual steps succeed or fail and notify you based on</p>"},{"location":"chap4/15process_EMR/","title":"L4 EMR Elastic MapReduce","text":""},{"location":"chap4/15process_EMR/#1elastic-mapreduce-emr-architecture-and-usage","title":"1\u3001Elastic MapReduce (EMR) Architecture and Usage","text":""},{"location":"chap4/15process_EMR/#1-1-what-is-emr","title":"1-1 What is EMR?","text":"<ul> <li>Elastic MapReduce </li> <li>Managed Hadoop framework on EC2 instances </li> <li>Includes Spark, HBase, Presto, Flink, Hive &amp; more </li> <li>EMR Notebooks </li> <li>Several integration points with AWS</li> </ul>"},{"location":"chap4/15process_EMR/#1-2-an-emr-cluster","title":"1-2 An EMR Cluster","text":"<p>Master node: manages the cluster </p> <ul> <li>Tracks status of tasks, monitors cluster health </li> <li>Single EC2 instance (it can be a single node cluster even) </li> <li>AKA \"leader node\" </li> </ul> <p>Core node: Hosts HDFS data and runs tasks </p> <ul> <li>Can be scaled up &amp; down, but with some risk </li> <li>Multi-node clusters have at least one </li> </ul> <p>Task node: Runs tasks, does not host data </p> <ul> <li>Optional </li> <li>No risk of data loss when removing </li> <li>Good use of spot instances </li> </ul>"},{"location":"chap4/15process_EMR/#1-3-emr-usage","title":"1-3 EMR Usage","text":"<ul> <li>Frameworks and applications are specified at cluster launch </li> <li>Connect directly to master to run jobs directly </li> <li> <p>Or, submit ordered steps via the console </p> <ul> <li>Process data in S3 or HDFS </li> <li>Output data to S3 or somewhere </li> <li>Once defined, steps can be invoked via the console </li> </ul> </li> <li> <p>Transient vs Long-Running Clusters </p> <ul> <li>Transient clusters terminate once all steps are complete<ul> <li>Loading data, processing, storing \u2014 then shut down </li> <li>Saves money </li> </ul> </li> </ul> </li> <li> <p>Long-running clusters must be manually terminated </p> <ul> <li>Basically a data warehouse with periodic processing on large datasets </li> <li>Can spin up task nodes using Spot instances for temporary capacity </li> <li>Can use reserved instances on long-running clusters to save $ </li> <li>Termination protection on by default, auto-termination on </li> </ul> </li> </ul>"},{"location":"chap4/15process_EMR/#2emr-aws-integration-and-storage","title":"2\u3001EMR, AWS integration, and Storage","text":""},{"location":"chap4/15process_EMR/#2-1-emr-aws-integration","title":"2-1 EMR / AWS Integration","text":"<ul> <li>Amazon EC2 for the instances that comprise the nodes in the cluster </li> <li>Amazon VPC to configure the virtual network in which you launch your instances</li> <li>Amazon S3 to store input and output data </li> <li>Amazon Cloud Watch to monitor cluster performance and configure alarms </li> <li>AWS IAM to configure permissions </li> <li>AWS CloudTrail to audit requests made to the service </li> <li>AWS Data Pipeline to schedule and start your clusters </li> </ul> <p>self-contained job that requires you to spin up an EMR cluster run that job and then  shut it down.</p>"},{"location":"chap4/15process_EMR/#2-2-emr-storage","title":"2-2 EMR Storage","text":"<ul> <li>HDFS</li> <li> <p>EMRFS: access S3 as if it were HDFS </p> <ul> <li>EMRFS Consistent View \u2014 Optional for Consistency(exam) </li> <li>Uses DynamoDB to track consistency </li> </ul> </li> <li> <p>Local file system</p> </li> <li>EBS for HDFS</li> </ul>"},{"location":"chap4/15process_EMR/#2-3-hdfs-description-hadoop-distributed-file-system","title":"2-3 HDFS Description (Hadoop distributed file system)","text":"<ul> <li>HDFS is a distributed scalable file system for Hadoop and it distributes the data at stores across different instances in your cluster. </li> <li>Allows Hadoop to actually, try to run the code that analyzes your data on the same instance where that data is stored --- performance optimization</li> <li>Stores multiple copies of your data on different instances and that ensures that no data is lost if an individual instance fails</li> <li>HDFS is ephemeral when you terminate your cluster that data is gone. </li> <li>It is useful for caching intermediate results during MapReduce processing or for workloads </li> </ul>"},{"location":"chap4/15process_EMR/#2-4-hdfs-block","title":"2-4 HDFS Block","text":"<ul> <li>Each file in HDFS is stored as blocks and it's distributed across the entire Hadoor cluster. </li> <li>If you have a large file that you're storing in HDFS it's going to get broken up into blocks and those blocks are going to be stored in multiple places for backup purposes. </li> <li>By default a block size is 128 megabytes </li> <li>If you have a big file and you're gonna be storing it on HDFS that file will ultimately be split up into 128 megabyte chunks for processing. </li> </ul>"},{"location":"chap4/15process_EMR/#2-5-emrfs","title":"2-5 EMRFS","text":"<ul> <li>This basically creates a file system that looks like HDFS but it's actually backed by S3. </li> <li>Terminate your cluster your data will still live in S3 and you don't lose anything. </li> <li>Also S3 would be used to store your input and output data and you could still use HDFS to store intermediate results </li> <li>With S3, you may encounter consistency problem, EMRFS consistent view solves for you. </li> <li>DynamoDB database to store object metadata and track consistency with S3 </li> </ul>"},{"location":"chap4/15process_EMR/#2-6-local-file-system","title":"2-6 Local file system","text":"<ul> <li>The local file system pre-configured with an instance store. And of course that will only persist until the lifetime of that individual EC2 instance </li> </ul>"},{"location":"chap4/15process_EMR/#2-7-ebs-for-hdfs","title":"2-7 EBS for HDFS","text":"<ul> <li>Amazon EBS general purpose SSD 10GB volume as the root device for its AMIs to enhance your performance </li> <li>You can add additional EBS volumes to the instances in your EMR cluster to allow you to customize a storage on an instance </li> <li>EMR will delete these volumes once the cluster is terminated. </li> <li>You cannot attach an EBS volume to a running cluster, You can only add EBS volumes when launching a cluster </li> <li>Can't mess with your EBS storage once your cluster is up </li> </ul>"},{"location":"chap4/15process_EMR/#3emr-promises-intro-to-hadoop","title":"3\u3001EMR Promises; Intro to Hadoop","text":""},{"location":"chap4/15process_EMR/#3-1-emr-promises","title":"3-1 EMR promises","text":"<ul> <li> <p>EMR charges by the hour </p> <ul> <li>Plus EC2 charges </li> </ul> </li> <li> <p>Provisions new nodes if a core node fails </p> </li> <li>Can add and remove tasks nodes on the fly </li> <li>Can resize a running cluster's core nodes </li> </ul>"},{"location":"chap4/15process_EMR/#3-2-whats-hadoop","title":"3-2 What's hadoop","text":"<p>Hadoop consists of these three systems MapReduce, Yarn, and HDFS these contain the libraries and utilities required for other Hadoop modules and provides the underlying file system and operating system level abstractions that we need. Also contains all the jar files and scripts that we need to start Hadoop itself. </p> <p>1. HDFS </p> <p>What This is a distributed scalable file system for Hadoop. </p> <p>It distributes the data it stores across the instances in the cluster and it stores r,rewft copies of that data on different instances to ensure that no data is lost. </p> <p>Negative</p> <p>That data will be lost if you terminate your EMR cluster it is stored on the cluster itself. </p> <p>Positive </p> <p>This can be useful from a performance standpoint because it allows Hadoop to try to run the analysis of your code on the same node where that data is stored </p> <p>2. Yarn </p> <p>Yarn stands another resource negotiator</p> <p>What </p> <p>It's a component introduced in Hadoop 2.0 to centrally manage cluster resources or multiple data processing frameworks. </p> <p>How</p> <p>Manages what gets run </p> <p>3.Hadoop MapReduce </p> <p>The software framework for easily writing applications that process vast amounts of data in parallel on large clusters of commodity hardware in a reliable fault tolerant manner. </p> <p>Map functions </p> <ul> <li>Map data to sets of key value pairs called intermediate results </li> </ul> <p>Reduce functions </p> <p>Combine the intermediate results applies additional algorithms and produces the final output from your system. </p>"},{"location":"chap4/15process_EMR/#4intro-to-apache-spark","title":"4\u3001Intro to Apache Spark","text":""},{"location":"chap4/15process_EMR/#4-1-apache-spark","title":"4-1 Apache Spark","text":""},{"location":"chap4/15process_EMR/#4-2-what-is-spark","title":"4-2 What is Spark","text":"<p>Mainly taking the place of MapReduce is Apache Spark and it's an open source distributed processing system commonly used for big data workloads. </p> <p>Its secret is using in memory caching so it really does a lot of work in memory instead of on disk and it uses directed acyclic graphs to optimize its query execution for very fast analytic queries against data of any size </p>"},{"location":"chap4/15process_EMR/#4-3-how-to-use-spark","title":"4-3 How to use Spark","text":"<p>Spark provides development APIs in Java, Scala, python, and R, so you do need to write code to use Spark </p> <p>Spark provides lot of code libraries built in so you can reuse that code across multiple workloads and some of the libraries it provides you will do </p> <ul> <li>batch processing </li> <li>interactive queries</li> <li>real time analytics</li> <li>machine learning</li> <li>graph processing </li> </ul> <p>Common Usage </p> <ul> <li>Apache Spark includes stream processing through Spark streaming. This allows you to process data collected from Amazon Kinesis for example but also things outside of the AWS ecosystem such as Apache Kafka or any other data stream that spark streaming can integrate with on Amazon EMR. </li> <li>it can also do streaming analytics and it's performed in a fault tolerant way and you can write the results of those analytics to HDFS or in the case of AWS to S3. </li> <li>You can also use Spark for machine learning at massive scale and includes a library called M.L. lib which is a library of machine learning algorithms that work on data at massive scale </li> <li>You can do interactive SQL using Spark SQL that's used for low latency interactive queries using either SQL or Hive QL </li> </ul> <p>Anti pattern</p> <ul> <li>So it's not really meant for real time  usage. </li> <li>Spark is not meant for OLTP or batch processing, Spark jobs generally takes some time to complete because it has to distribute all that work across the cluster and collect the results back to it. </li> </ul>"},{"location":"chap4/15process_EMR/#4-4-how-spark-works","title":"4-4 How Spark Works","text":"<p>Driver - Spark context object:</p> <p>Spark context object within your main program and that program is known as the driver program or the driver script. </p> <p>This is the actual code of your Spark program that tells a Sark cluster what you want to do with your data the Spark context will connect to different cluster managers </p> <p>Cluster Managers</p> <p>cluster managers will take care of allocating all the resources that your driver script needs across different applications.</p> <p>In the case of EMR it's going to be using Apache yarn because that's a component of Hadoop.</p> <p>You can also use Apache Spark outside of a Hadoop cluster as well it has its own cluster manager </p> <p>so once the cluster manager has decided how to distribute that work Spark will acquire executors on nodes </p> <p>Executors </p> <p>Within the cluster executors are processes that run computations and store the data for your applications.</p> <p>The application code is then sent to each executor and in the final step the Spark context sends the tasks to the executors to run. </p>"},{"location":"chap4/15process_EMR/#4-5-spark-components","title":"4-5 Spark Components","text":"<p>Spark core </p> <p>It's responsible for memory management, fault recovery, scheduling, distributing and monitoring jobs, and interacting with storage systems. </p> <p>It supports APIs for Java, Scala, python, and R at the lowest level here it's dealing with something called a resilient distributed dataset(RDD) and that represents a logical collection of data partitioned across the different compute nodes. </p> <p>Spark SQL </p> <p>We tend to deal with data these days in Spark at a higher level than the RDDs and that's where Spark SQL comes in. So Spark SQL is a distributed query engine that provides low latency interactive queries up to 100 times faster than MapReduce. </p> <ul> <li> <p>Spark SQL includes: </p> <ul> <li>cost based optimizer</li> <li>columnar storage </li> <li>cogeneration for fast queries </li> </ul> </li> <li> <p>It supports various data sources coming into it such as JDBC, ODBC, JSON, HDFS, Hive, Orc, and Parquet </p> </li> <li>It also supports querying Hive tables using Hive QL. </li> </ul> <p>Spark SQL is especially important because it contains a construct known as a data set that basically lets you view the data that you have on Spark as a giant database if you will and by using straight up SQL to interact with your data it makes the development of your Spark driver scripts a lot more simple and it allows Spark itself to perform optimizations that it could not normally do. </p> <p>Modern Spark code its using the datasets that are exposed through Spark SQL</p> <p>Spark Streaming </p> <p>Spark streaming is also built on top of Spark core and it also integrates with Spark SQL to use datasets as well Spark streaming is a real time solution that leverages Spark core's fast scheduling capability to do streaming analytics </p> <p>It ingests data in mini batches and it enables analytics on that data with the same application code you would write for batch analytics it improves your developer productivity because the same code can be used for both batch processing </p> <p>Real time streaming applications it supports data from a variety of streaming sources as well including Kafka, Flume, HDFS, and Zero MQ </p> <p>ML lib </p> <p>ML library of algorithms to do machine learnin on data at large scale </p> <p>These algorithms include things like the ability to do classification, regression, clustering, collaborative filtering, and pattern mining. </p> <p>ML lib can read data from HDFS, Hbase, or any Hadoop data source as well as S3 on EMR.</p> <p>Spark code you can write your M.L. lib applications with Scala, Java, Python, or Spark, R. </p> <p>GraphX</p> <p>GraphX that's a distributed graph processing framework built on top of Spark, graphs in the data structure sense</p> <p>It provides ETL capabilities, exploratory analysis, and iterative graph computation to enable users to interactively build and transform a graph data structure at scale</p> <p>If has a highly flexible API and you can select from different distributed graph algorithms. </p> <p>5\u3001Spark Integration with Kinesis and Redshift</p>"},{"location":"chap4/15process_EMR/#5-1-spark-structured-streaming","title":"5-1 Spark Structured Streaming","text":"<p>Spark applications usually use something called a data set in their code to refer to your data and a data set is treated very much like a database table with Spark streaming </p> <p>New data is received by the stream it just keeps adding rows to that virtual database table in the form of a data set so you can query this data using windows of time. </p> <p>Code Example </p> <p>Monitor all the stuff that's being thrown into a logs bucket in S3.</p> <pre><code>val inputDF = spark.readStream.json(\"s3://logs\") \ninputDF.groupBy($\"action\", window(Vtime\", \"1 hour\")).count().writeStream.formandb c\").start(ldbc:mysql//...\") \n</code></pre> <ul> <li>1 hour: Continually counting up the records being received in that bucket over the previous one hour and the write those counts using JDBC into some external MySQL database </li> </ul>"},{"location":"chap4/15process_EMR/#5-2-spark-streaming-kinesis","title":"5-2 Spark Streaming + Kinesis","text":"<p>There is a library for Spark streaming built on top of the Kinesis client library to allow Spark streaming to import data from Amazon Kinesis data streams and you just have to plug in that library and code against it and you can treat Kinesis as any other stream of data coming into a data set in Spark structured streaming. </p> <p> </p> <p>So for example </p> <ol> <li>There are some Kinesis producers use bunch of EC2 host generating logs </li> <li>Pumping data into a Kinesis data stream. </li> <li>Integrate that using the Spark data set integration code as any other dataset coming in to Spark streaming</li> <li>Process dataset acros the tire cluster on EMR using Apache Spark</li> </ol>"},{"location":"chap4/15process_EMR/#5-3-spark-redshift","title":"5-3 Spark + Redshift","text":"<ul> <li> <p>spark-redshift package allows Spark datasets from Redshift </p> <ul> <li>Its a Spark SQL data source </li> </ul> </li> <li> <p>Useful for ETL using Spark </p> </li> </ul> <p>Redshift is a massive distributed data warehouse that's offered by AWS. </p> <p>There is Spark Redshitt package and that allows Spark to treat data sets from Redshift just like any other SQL database. </p> <p> </p> <p>Integrating Redshift with Spark I an distribute the processing of that !huge data set sitting in S3 </p> <ol> <li>Deploy Amazon Redshift spectrum on top of that data in S3 which will provide SQL Interface on top of that data that lives in S3.  </li> <li>Using the Spark Redshift package spin up in Apache Spark cluster on Amazon EMR </li> <li>Perform ETL on that data that's residing in S3 through Amazon Redshift because Redshift like any other SQL data source to Apache Spark. </li> <li>Put that process data back into another Amazon Redshift table for further processing. </li> </ol>"},{"location":"chap4/15process_EMR/#6hive-on-emr","title":"6\u3001Hive on EMR","text":""},{"location":"chap4/15process_EMR/#6-1-apache-hive","title":"6-1 Apache Hive","text":"<ul> <li>Hive basically exposes SQL interface to your underlying data stored on your EMR cluster. </li> <li>Hive execute straight up SQL code on underlying unstructured data that might live in Hadoop, Yarn, or S3 </li> </ul> <p>EMR Hive sits on top of MapReduce to figure out how to distribute the processing of SQL on the underlying data </p> <p>Tez: </p> <p>Tez is kind of like Apache Spark and that it uses a lot of in memory directed acyclic graph[\u65e0\u73af\u56fe] to accelerate things, so Hive often being used on top of Tez instead of MapReduce </p>"},{"location":"chap4/15process_EMR/#6-2-why-hive","title":"6-2 Why Hive?","text":"<ul> <li>Uses familiar SQL syntax (HiveQL)</li> <li>Interactive </li> <li>Scalable - works with \"big data\" on a cluster <ul> <li>Really most appropriate for data warehouse applications </li> </ul> </li> <li>Easy OLAP queries WAY easier than writing MapReduce in Java </li> <li>Highly optimized Highly extensible <ul> <li>User defined functions </li> <li>Thrift server </li> <li>JDBC / ODBC driver </li> </ul> </li> </ul> <p>anti-pattern</p> <p>Hive is not really for OLTP so you shouldn't be writing a web service that hits Hive continuously hundreds of times per second or anything like that trying to get results back very quickly </p>"},{"location":"chap4/15process_EMR/#6-3-the-hive-metastore","title":"6-3 The Hive Metastore","text":"<ul> <li>Hive maintains a \"metastore\" that imparts a structure you define on the unstructured data that is stored on HDFS etc. <ul> <li>Column names N</li> <li>Data types </li> </ul> </li> </ul> <pre><code>CREATE TABLE ratings ( \n    userID INT, \n    movieID INT, \n    rating INT, \n    time INT) \nROW FORMAT DELIMTED \nFIELDS TERMINATED BY '\\t \nSTORED AS TEXTFILE; \n\n\nLOAD DATA LOCAL INPATH '${env:HOME}/m1-100k/u.data' \nOVERWRITE INTO TABLE ratings; \n</code></pre> <p>How the actual data is delimited and terminated and the format that it's stored in and where it is actually located That information has to be stored somewhere and that's what we call the Hive Metastore. </p>"},{"location":"chap4/15process_EMR/#6-4-external-hive-metastores","title":"6-4 External Hive Metastores","text":"<ul> <li>By default the hive metastore just stored in a MySQL database on the master node of your cluster (Not persistence if shut down master node) </li> <li>External metastores offer better resiliency / integration <ul> <li>AWS Glue Data Catalog</li> <li>Amazon RDS </li> </ul> </li> </ul> <p>1. store Hive Metastore within AWS glue data catalog </p> <p>AWS glue data catalog that serves double duty as a hive metastore and that allows you to centrally locate your metadata for your unstructured data  and ex ose that directly to hive where Amazon EMR can get to it but also expose that same metadata to Amazon Redshift, Amazon Athena. </p> <p>2.Store your hive metastore on an external Amazon RDS instance or Amazon Aurora</p> <p>Master node you can choose to store that in an external RDS database instance that will be more persistent. So even if you shut down your cluster that metastore will survive in your RDS database. </p>"},{"location":"chap4/15process_EMR/#6-5-aws-integrates-with-hive-in-other-ways","title":"6-5 AWS integrates with Hive in other ways","text":"<ul> <li>Load table partitions from S3</li> <li>Write tables in S3 </li> <li>Load scripts from S3 </li> <li>DynamoDB as an external table </li> </ul> <p>1. integrates with S3</p> <ul> <li> <p>Using hive with EMR provides the ability to load a table partitions automatically from S3</p> <ul> <li>Example: Store your data in S3 undr different sub directories for example year then month then date then hour </li> <li>Translated into table partitions and you can do that automatically with hive on EMR </li> </ul> </li> <li> <p>Hive with Amazon EMR provides the ability to specify an off instance metadata store </p> </li> </ul> <p>2. integrates with DynamoDB </p> <ul> <li>Use hive to analyze the data stored in dynamo DB and either load the results back into dynamo DB or archive them into Amazon S3. </li> <li>Allows you to copy data from a dynamoDB into EMR FS or HDFS and vice versa</li> </ul> <p> </p>"},{"location":"chap4/15process_EMR/#7apache-pig-on-emr","title":"7\u3001Apache Pig on EMR","text":"<p>Apache Pig is also an important part of the Hadoop ecosystem that comes pre-installed on Amazon EMR. </p> <p>Pig is an alternative interface to MapReduce.it recognizes that writing code from mappers and reducers using MapReduce takes a tong time</p> <ul> <li>Writing mappers and reducers by hand takes a long time. </li> <li>Pig introduces Pig Latin, a scripting language that lets yon use SQL-like syntax to define your map and reduce steps instead of Java code for MapReduce. </li> <li>Highly extensible with user-defined functions (LIDF's) </li> </ul>"},{"location":"chap4/15process_EMR/#7-1-how-pig-works","title":"7-1 How pig works","text":""},{"location":"chap4/15process_EMR/#7-2-pig-aws-integration","title":"7-2 Pig AWS Integration","text":"<ul> <li>Ability to use multiple file systems (not just HDFS) <ul> <li>i.e., query data in S3 </li> </ul> </li> <li>Load JAR's and scripts from S3 </li> </ul>"},{"location":"chap4/15process_EMR/#8hbase-on-emr","title":"8\u3001HBase on EMR","text":"<ul> <li>Non-relational, petabyte-scale database </li> <li>Based on Google's BigTable, on top of HDFS </li> <li>In-memory (fast) </li> <li>Hive integration </li> </ul>"},{"location":"chap4/15process_EMR/#8-1-sounds-a-lot-like-dynamodb","title":"8-1 Sounds a lot like DynamoDB","text":"<ul> <li>Both are NoSQL databases intended for the same sorts of things </li> <li> <p>But if you're all-in with AWS anyhow, DynamoDB has advantages </p> <ul> <li>Fully managed (auto-scaling) </li> <li>More integration with other AWS services </li> <li>AWS Glue integration </li> </ul> </li> <li> <p>HBase has some advantages though: </p> <ul> <li>Efficient storage of sparse data,</li> </ul> <p>If vou have data that's just really scattered across your entire cluster. HBase tends to be able to deal with that better than dynamo DB. </p> <ul> <li>Appropriate for high frequency counters (consistent reads &amp; writes)</li> <li>High write &amp; update throughput </li> <li>More integration with Hadoop </li> </ul> </li> </ul>"},{"location":"chap4/15process_EMR/#8-2-hbase-aws-integration","title":"8-2 HBase AWS integration","text":"<ul> <li>Can store data (StoreFiles and metadata) on S3 via EMRFS </li> <li>Can back up to S3 </li> </ul>"},{"location":"chap4/15process_EMR/#9presto-on-emr","title":"9\u3001Presto on EMR","text":""},{"location":"chap4/15process_EMR/#9-1-presto","title":"9-1 Presto","text":"<ul> <li>It can connect to many different \"big data\" databases and data stores at once. and query across them </li> </ul> <p>You can write a SQL join command that combines data from different databases stored in different technologies that live on your cluster. </p> <ul> <li>Interactive queries at petabayte scale </li> <li>Familiar SQL syntax </li> <li>Optimized for OLAP analytical queries, data warehousing </li> <li>Developed, and still partially maintained by Faceboolik ---</li> </ul> <p>Athena is a serverless version of Presto and with a nice little skin on top of it</p> <ul> <li>This is what Amazon Athena uses under the hood </li> <li>Exposes JDBC, Command-Line, and Tableau interfaces </li> </ul>"},{"location":"chap4/15process_EMR/#9-2-presto-connectors","title":"9-2 Presto connectors","text":"<ul> <li>HDFS </li> <li>S3 </li> <li>Cassandra </li> <li>MongoDB </li> <li>HBase </li> <li>SQL </li> <li>Redshift </li> <li>Teradata </li> </ul> <p>Using Presto can be both relational and non relational databases like it doesn't care can treat them all as a SQL interface</p> <p>Amazon EMR you can launch a Presto cluster in just minutes. You don't have to do node provisioning or a cluster setup or Presto configuration or cluster tuning </p>"},{"location":"chap4/15process_EMR/#10zeppelin-and-emr-notebooks","title":"10\u3001Zeppelin and EMR Notebooks","text":"<ul> <li> <p>If you're familiar with iPython notebooks \u2014it's like that </p> <ul> <li>Lets you interactively run scripts against our data o</li> <li>Can interleave with nicely formatted notes </li> <li>Can share notebooks with others on your cluster </li> </ul> </li> <li> <p>Spark, Python, JDBC, HBase, Elasticsearch + more </p> </li> </ul>"},{"location":"chap4/15process_EMR/#10-1-zeppelin-spark","title":"10-1 Zeppelin + Spark","text":"<ul> <li>Can run Spark code interactively (like you can in the Spark shell) <ul> <li>This speeds up your development cycle</li> <li>And allows easy experimentation and exploration of your big data </li> </ul> </li> <li>Can execute SQL queries directly against SparkSQL </li> <li>Query results may be visualized in charts and graphs </li> <li>Makes Spark feel more like sicence tool! </li> </ul>"},{"location":"chap4/15process_EMR/#10-2-emr-notebook","title":"10-2 EMR Notebook","text":"<ul> <li>Similar concept to Zeppelin, with more AWS integration </li> <li>Notebooks backed up to S3 </li> <li>Provision clusters from the notebook! </li> <li>Hosted inside a VPC </li> <li>Accessed only via AWS console </li> </ul>"},{"location":"chap4/15process_EMR/#10-3-emr-notebook-features","title":"10-3 EMR Notebook Features","text":"<ul> <li>Packaged with some popular open source graphical libraries from the anaconda repository that helps you to prototype code and visualize results </li> <li>Perform exploratory analysis with Spark data frames they can be attached to an existing cluster or you can revision new clusters directly from the notebook. </li> <li>Allows multiple users from the organization to create their own notebooks attach them to shared multi tenant EMR clusters </li> <li>No additional charge to Amazon EMR customers. </li> </ul>"},{"location":"chap4/15process_EMR/#11hue-splunk-and-flume","title":"11\u3001Hue, Splunk, and Flume","text":""},{"location":"chap4/15process_EMR/#11-1-hue","title":"11-1 Hue","text":"<ul> <li>Hadoop User Experience </li> <li>Graphical front-end for applications on your EMR cluster </li> <li>IAM integration: Hue Super-users inherit IAM roles </li> <li>S3: Can browse &amp; move data between HDFS and S3 </li> </ul> <p>Exam: Which tool: </p> <p>Hue is this a management tool it's the front end  dashboard for your entire cluster </p>"},{"location":"chap4/15process_EMR/#11-2-splunk","title":"11-2 Splunk","text":"<ul> <li>Splunk / Hunk \"makes machine data accessible, usable, and valuable to everyone\" </li> <li>Operational tool \u2014 can be used to visualize EMR and S3 data using your EMR Hadoop cluster. </li> </ul> <p>Exam: Which tool: </p> <p>Splunk is just an operational tool</p>"},{"location":"chap4/15process_EMR/#11-3-flume","title":"11-3 Flume","text":"<p>Another way of streaming data into your cluster, like Kinesis or Kafka </p> <ul> <li>Another way to stream data into your clustr </li> <li> <p>Made from the start with Hadoop in mind</p> <ul> <li>Built-in sinks for HDFS and HBas </li> </ul> </li> <li> <p>Originally made to handle log aggregation </p> </li> </ul> <p> </p> <ul> <li>A web server act as an external source that provides events to a flume source. </li> <li>That event is then stored in one or more channels </li> <li>A channel acts as a passive store that keeps the event until it is consumed by a flume sink </li> <li>The flume sink then removes the event from the channel </li> <li>And the flume sink puts event into an external repository like HDFS on your EMR cluster. </li> </ul> <p>Flume sink </p> <ul> <li>HDFS sink that writes events into HDFS it supports creating text and sequence files and supports compression and both file types as well. </li> <li>Hive sink and that would stream events containing delimited text or JSON data directly into a hive table or partition events are written using hive transactions </li> </ul> <p>Exam: Which tool: </p> <p>Flume is a way of streaming log data into a cluster, as an alternative technology</p> <p>for handling streaming applications on an EMR cluster.</p>"},{"location":"chap4/15process_EMR/#11-4-mxnet","title":"11-4 MXNet","text":"<ul> <li>Like Tensorflow, a library for building and accelerating neural networks </li> <li>Included on EMR </li> </ul> <p>Exam: Which tool</p> <p>MXNet is a framework and library that is used to build deep learning applications. </p>"},{"location":"chap4/15process_EMR/#12s3distcp-and-other-services","title":"12\u3001S3DistCP and Other Services","text":"<ul> <li> <p>Tool for copying large amounts of data </p> <ul> <li>From S3 into HDFS </li> <li>From HDFS into S3 </li> </ul> </li> <li> <p>Uses MapReduce to copy in a distributed manner </p> </li> <li>Suitable for parallel copying of large numbers of objects <ul> <li>Across buckets, across accounts </li> </ul> </li> </ul>"},{"location":"chap4/15process_EMR/#12-1-other-emr-hadoop-tools-throw-out-for-misdirect","title":"12-1 Other EMR / Hadoop Tools (Throw out for misdirect)","text":"<ul> <li>Ganglia (monitoring like cloudwatch) </li> <li>Mahout (machine learning like spark's ML lib) </li> <li>Accumulo (another NoSQL database like HBase and dynamo DB) </li> <li>Sqoop (relational database connector like S3DistCP, used primarily for importing data from external databases into your cluster in a very scalable manner.) </li> <li>HCatalog (table and storage management for Hive metastore) </li> <li>Kinesis Connector (directly access Kinesis streams in your scripts on EC2 node) </li> <li>Tachyon (accelerator for Spark) </li> <li>Derby (open-source relational DB in Java) </li> <li>Ranger (data security manager for Hadoop) </li> <li>Install whatever you want </li> </ul>"},{"location":"chap4/15process_EMR/#13emr-security-and-instance-types","title":"13\u3001EMR Security and Instance Types","text":""},{"location":"chap4/15process_EMR/#13-1-emr-security","title":"13-1 EMR Security","text":"<ul> <li>IAM policies Kerberos </li> <li>SSH </li> <li>IAM roles </li> </ul> <p>IAM policies </p> <ul> <li>IAM rules for EMRFS requests to Amazon S3</li> </ul> <p>Kerberos </p> <p>Kerberos is a way of providing strong authenti alio through secret key cryptography. </p> <p>This is a network authentication protocol that ensures that passwords or other credentials aren't sent over the network in an unencrypted format </p> <p>SSH</p> <ul> <li>SSH provides a secure way for users to connect to the command line on cluster instances </li> <li>It provides tunneling so you can view web interfaces that are hosted on your master node of your cluster from outside of the cluster itself. </li> </ul> <p>IAM roles </p> <p>If you're going to be enabling automatic scaling on your cluster you're going to need an auto scaling IAM role attached to it </p>"},{"location":"chap4/15process_EMR/#13-2-emr-choosing-instance-types","title":"13-2 EMR: Choosing Instance Types","text":"<p>Master Node: </p> <ul> <li>m4.large if &lt; 50 nodes, m4.xlarge if &gt; 50 nodes </li> </ul> <p>Core &amp; task nodes: </p> <ul> <li>m4 large is usually good </li> <li>If cluster waits a lot on external dependencies (i.e. a web crawler), t2.medium </li> <li>Improved performance: m4.xlarge </li> <li>Computation-intensive applications: high CPU instances </li> <li>Database, memory-caching applications: high memory instances </li> <li>Network / CPU-intensive (NLP, ML) \u2014 cluster computer instances </li> </ul> <p>Spot instances </p> <ul> <li>Good choice for task nodes </li> <li>Only use on core &amp; master if you're testing or very cost-sensitive; you're risking partial data loss </li> </ul>"},{"location":"chap4/17Process_EMR_Exer/","title":"L5 Elastic MapReduce Exercise","text":""},{"location":"chap4/17Process_EMR_Exer/#1create-emr","title":"1\u3001Create EMR","text":"<ul> <li>Name: CadabraRecs</li> <li>Appliactions: Spark</li> <li>Instance type: C5<ul> <li>Apache Spark doing machine learning and machine learning tends to be a very CPU heavy operation.</li> <li>Tensor flow cluster to use a GPU optimized cluster</li> </ul> </li> </ul>"},{"location":"chap4/17Process_EMR_Exer/#change-master-node-sg","title":"Change master node SG","text":"<p>Add Port 22:</p> <p> </p> <p>SSH Master public DNS</p> <p> </p> <p> </p> <p> </p> <pre><code>ssh -i Data.pem hadoop@ip-10-250-0-78.ec2.internal\n</code></pre>"},{"location":"chap4/17Process_EMR_Exer/#2example-using-algorithm-called-als-alternating-least-squares","title":"2\u3001Example: Using Algorithm called ALS alternating least squares","text":"<p>Under the samples directory of Spark itself.</p> <pre><code>$ cp /user/lib/spark/examples/src/main/python/als_example.py ./\n$ ls\nals_example.py\n</code></pre>"},{"location":"chap4/17Process_EMR_Exer/#2-1-als_examplepy","title":"**2-1 <code>als_example.py**</code>","text":"<p>This is a python script that is a spark driver script it kicks off a Spark session, calls ALSExample</p> <pre><code>rom __future__ import print_function\n\nimport sys\nif sys.version &gt;= '3':\n    long = int\n\nfrom pyspark.sql import SparkSession\n\n# $example on$\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.sql import Row\n# $example off$\n\nif __name__ == \"__main__\":\n    spark = SparkSession\\\n        .builder\\\n        .appName(\"ALSExample\")\\\n        .getOrCreate()\n\n    # $example on$\n    lines = spark.read.text(\"data/mllib/als/sample_movielens_ratings.txt\").rdd\n    parts = lines.map(lambda row: row.value.split(\"::\"))\n    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n                                         rating=float(p[2]), timestamp=long(p[3])))\n    ratings = spark.createDataFrame(ratingsRDD)\n    (training, test) = ratings.randomSplit([0.8, 0.2])\n\n    # Build the recommendation model using ALS on the training data\n    # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n              coldStartStrategy=\"drop\")\n    model = als.fit(training)\n\n    # Evaluate the model by computing the RMSE on the test data\n    predictions = model.transform(test)\n    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n                                    predictionCol=\"prediction\")\n    rmse = evaluator.evaluate(predictions)\n    print(\"Root-mean-square error = \" + str(rmse))\n\n    # Generate top 10 movie recommendations for each user\n    userRecs = model.recommendForAllUsers(10)\n    # Generate top 10 user recommendations for each movie\n    movieRecs = model.recommendForAllItems(10)\n\n    # Generate top 10 movie recommendations for a specified set of users\n    users = ratings.select(als.getUserCol()).distinct().limit(3)\n    userSubsetRecs = model.recommendForUserSubset(users, 10)\n    # Generate top 10 user recommendations for a specified set of movies\n    movies = ratings.select(als.getItemCol()).distinct().limit(3)\n    movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n    # $example off$\n    userRecs.show()\n    movieRecs.show()\n    userSubsetRecs.show()\n    movieSubSetRecs.show()\n\n    spark.stop()\n</code></pre> <ul> <li>Reads in data here from something called <code>sample_movielens_ratings.txt</code> so by default it's using some movie ratings data.<ul> <li>Not work on S3, actually work in the HDFS file system on this cluster.</li> </ul> </li> <li>Spark on EMR on top of a Hadoop cluster with HDFS file system</li> <li>Reading every line of that movie ratings data it's mapping it out to actually split that up based on individual fields it looks like </li> <li>It's delimited by double colon characters and then creates rows into an RDD by splitting out the user I.D., movie I.D., rating, and timestamp for each movie rating,</li> <li>Creates a data frame from that, splits that into a training, and test set and then it creates this ALS recommendation model</li> </ul> <p>Goal: Generate top 10 user recommendations for a specified set of movies</p>"},{"location":"chap4/17Process_EMR_Exer/#2-2-copy-sample-data-into-hadoops-hdfs-file-system","title":"2-2 Copy sample data into Hadoop's HDFS file system.","text":"<pre><code>hadoop fs -mkdir  -p /user/hadoop/data/mlib/als \n</code></pre> <ul> <li>Created that directory in the HDFS file systems that's shared across this cluster.</li> </ul> <pre><code>hadoop fs -copyFromLocal /user/lib/hadoop/data/mlib/als/sample_movielens_ratings.txt /user/hadoop/data/mlib/als/sample_movielens_ratings.txt\n</code></pre> <ul> <li>Copy from the local path and putting it into HDFS under the same place</li> </ul> <pre><code>spark-submit als_example.txt\n</code></pre> <ul> <li>Distribute script across the entire cluster of three machines and that entire cluster will just start chewing on the data and building that recommendation model </li> </ul>"},{"location":"chap4/17Process_EMR_Exer/#2-3-add-error-log-output","title":"2-3 Add error log output","text":"<pre><code>$ sudo vim als_example.txt\n\nspark.sparkContext.setLogLevel(\"Error\")\n\n\n$ spark-submit als_example.txt\n</code></pre>"},{"location":"chap4/17Process_EMR_Exer/#2-4-root-mean-square-error","title":"2-4 Root mean square error","text":""},{"location":"chap4/17Process_EMR_Exer/#3customer-recommend-data","title":"3\u3001Customer Recommend Data","text":""},{"location":"chap4/17Process_EMR_Exer/#3-1-make-s3-data-public-only-for-exercise","title":"3-1 Make S3 data public (Only for Exercise)","text":"<pre><code>$ sudo vim als_example.txt\n</code></pre> <pre><code>lines = spark.read.text(\"s3://kin-orderlogs/2020/02/09/20/*\").rdd\nparts = lines.map(lambda row: row.value.split(','))\n\n#Filter out postage, shipping, bank charges, discounts, commissions\nproductsOnly = parts.filter(lambda p: p[1][0:5].isdigit())\n\n#Filter out empty customer ID's\ncleanData = productsOnly.filter(lambda p: p[6].isdigit())\nratingsRDD = cleanData.map(lambda p: Row(customerId=int(p[6]), \\\n        itemId=int(p[1][0:5]), rating=1.0))\n\nals = ALS(maxIter=5, regParam=0.01, userCol=\"customerId\", itemCol=\"itemId\", ratingCol=\"rating\", \n</code></pre> <pre><code>$ spark-submit als_example.txt\n</code></pre>"},{"location":"chap4/20Process_DL/","title":"L7 Deep Learning","text":""},{"location":"chap4/20Process_DL/#1deep-learning-101","title":"1\u3001Deep Learning 101","text":""},{"location":"chap4/20Process_DL/#1-1-the-biological-inspiration","title":"1-1 The biological inspiration","text":"<p>Individual nerve cells areconnected to each other via axons and dendrites.</p> <ul> <li>Neurons in your cerebral cortex are connected via axons </li> <li>A neuron \"fires\" to the neurons it's connected to, when enough of its input signals are activated. </li> <li>Very simple at the individual neuron level \u2014 but layers of neurons connected in this way can yield learning behavior. </li> <li>Billions of neurons, each with thousands of connections, yields a mind </li> </ul>"},{"location":"chap4/20Process_DL/#1-2-cortical-columns","title":"1-2 Cortical columns","text":"<ul> <li>Neurons in your cortex seem to be arranged into many stacks, or \"columns\" that process information in parallel </li> <li>\"mini-columns\" of around 100 neurons are organized into larger \"hyper-columns\". There are 100 million mini-columns in your cortex </li> <li>This is coincidentally similar to how GPU's work... </li> </ul> <p>3D video card in computer works. It has a bunch of very simple, very small processing units that are responsible for computing how little groups of pixels on your screen are computed.</p>"},{"location":"chap4/20Process_DL/#1-3-deep-neural-networks","title":"1-3 Deep Neural Networks","text":"<p>Input feature data at the bottom where attributes at the bottom of the neural networks and predicted labels come out of the top</p> <p>Exam</p> <p>Deep learning because there's more than one layer of neurons. </p> <ul> <li>Basically it's stacked up layers of neurons connected together in different ways </li> <li>Those weights between each neuron are what formed the basis of your neural network neural nets tend to lend themselves very well to parallelization </li> <li>Individual neurons are simple enough to be modeled as units on a GPU</li> <li>GPU can parallelize the processing lots of neurons <ul> <li>You can have many GPUs on a single node in a cluster </li> <li>You can have many nodes in a cluster.</li> </ul> </li> </ul>"},{"location":"chap4/20Process_DL/#1-4-deep-learning-frameworks","title":"1-4 Deep Learning Frameworks","text":"<ul> <li>Tensorflow / Keras </li> <li>MXNet </li> </ul> <ul> <li>Sets up a layer of 64 input neurons at the bottom where you're feeding in your input features.</li> <li>There's a hidden layer there of 64 neurons in the middle as well</li> <li>at the top there's a layer of 10 neurons that actually output the final classification of one of 10 different things</li> </ul>"},{"location":"chap4/20Process_DL/#1-5-types-of-neural-networks","title":"1-5 Types of Neural Networks","text":"<ul> <li>Feedforward Neural Network </li> <li>Convolutional Neural Networks (CNN) <ul> <li>Image classification (is there a stop sign in this image?)</li> </ul> </li> </ul> <p>Neural networks built for processing image data either 2D or 3D image data and typically they're being used for image classification.</p> <ul> <li>Recurrent Neural Networks (RNNs) <ul> <li>Deals with sequences in time (predict stock prices, understand words in a sentence, etc) </li> <li>LSTM(long short term memory cell) , GRU(gated recurrent units cell)</li> </ul> </li> </ul> <p>RNN is appropriate for dealing with things like predicting stock prices or understanding words in a sentence </p> <p> </p>"},{"location":"chap4/20Process_DL/#1-6-deep-learning-on-ec2-emr","title":"1-6 Deep Learning on EC2 / EMR","text":"<ul> <li>EMR supports Apache MXNet and GPU instance types </li> <li>Appropriate instance types for deep learning: <ul> <li>P3: 8 Tesla V100 GPU's </li> <li>P2: 16 K80 GPU's </li> <li>G3: 4 M60 GPU's (all Nvidia chips) </li> </ul> </li> <li>Deep Learning AMI's </li> </ul>"},{"location":"chap4/20Process_DL/#2aws-data-pipeline","title":"2\u3001AWS Data Pipeline","text":"<p>Data pipeline lets you schedule tasks for processing your big data.</p>"},{"location":"chap4/20Process_DL/#2-1-example","title":"2-1 Example","text":"<ol> <li>Log files that are published on EC2 instances.</li> <li>Data pipeline can schedule a daily task or whatever frequency to copy those log files from EC2 into S3</li> <li>Maybe on a weekly task basis launch that data analysis using an EMR cluster on the data that's been stored up in S3.</li> </ol> <p>It's kind of like Hadoop Oozie.</p> <p>It's basically a task scheduling framework where you can run different operations that depend on each other on different schedules.</p>"},{"location":"chap4/20Process_DL/#2-2-data-pipeline-features","title":"2-2 Data Pipeline Features","text":"<ul> <li>Destinations include S3, RDS, DynamoDB, Redshift and EMR </li> <li>Manages task dependencies </li> <li>Retries and notifies on failures </li> <li>Cross-region pipelines </li> <li>Precondition checks <ul> <li>DynamoDB Data exists: check for the existence of data inside a dynamo db table before you try to move it or process it </li> <li>DynamoDB table exists that can check for the existence of an entire table</li> <li>S3 key exists and S3 prefix exists which can both be used to test for the existence of either a specific path in S3 or a specific prefix you know sort of a path that exists within S3 itself</li> <li>Shell command precondition and this runs an arbitrary script of your own on your resources and checks that the script succeeds.</li> </ul> </li> <li>Data sources may be on-premises </li> <li>Highly available </li> </ul>"},{"location":"chap4/20Process_DL/#2-3-data-pipeline-activities","title":"2-3 Data Pipeline Activities","text":"<ul> <li>EMR </li> <li>Hive: Hive queries on a schedule</li> <li>Copy: Copy data between Amazon S3 and JBDC data sources</li> <li>SQL: SQL query and copy its output into Amazon S3. </li> <li>Scripts </li> </ul> <p>EMR</p> <p>It's possible to spin up an EMR instance and run a sequence of steps automatically and then automatically terminate the cluster when it's done.</p> <p>Scripts</p> <p>Run arbitrary Linux shell commands or programs as part of your data pipeline and will be automatically added if you're using any of the templates specified by AWS during the pipeline creation.</p>"},{"location":"chap4/20Process_DL/#3aws-step-functions","title":"3\u3001AWS Step Functions","text":"<ul> <li>Use to design workflows </li> <li>Easy visualizations </li> <li>Advanced Error Handling and Retry mechanism outside the code </li> <li>Audit of the history of workflows </li> <li>Ability to \"Wait\" for an arbitrary amount of time </li> <li>Max execution time of a State Machine is 1 year </li> </ul>"},{"location":"chap4/20Process_DL/#3-1-step-functions-examples-train-a-machine-learning-model","title":"3-1 Step Functions Examples: Train a Machine Learning Model","text":"<p>JSON based Amazon states language or ASL.</p> <p> </p> <ol> <li>Generate the data set by kicking off a lambda function</li> <li>Trainsthe model using Sagemakers(XGboost) algorithm</li> <li>Saves that trained model from Sagemaker</li> <li>Applies a batch transform to that model from some data set that we had at that point</li> </ol>"},{"location":"chap4/20Process_DL/#3-2-step-functions-examples-tune-a-machine-learning-model","title":"3-2 Step Functions Examples: Tune a Machine Learning Model","text":"<ol> <li>Generating a training dataset</li> <li>kick off a hyperparameter tuning job in Sagemaker that just tries different parameters on the machine learning while to figure out what the right set of parameters are for this given dataset.</li> <li>Extracts that model path</li> <li>Saves the tuned model that it's settled on.</li> <li>Extract the model name of the tune model</li> <li>Use that to apply a transformation of a bunch of data in a batch format to that tuned model automatically.</li> </ol>"},{"location":"chap4/20Process_DL/#3-3-step-functions-examples-tune-a-machine-learning-model","title":"3-3 Step Functions Examples: Tune a Machine Learning Model","text":"<ul> <li>Submitting a batch job </li> <li>Use step functions to notify us if it succeeds or fails.</li> </ul>"},{"location":"chap4/20Process_DL/#3-4-summary","title":"3-4 Summary","text":"<p>Step functions manage workflows and they give you a nice graphical representation of those workflows and they can monitor whether individual steps succeed or fail and notify you what happens there.</p>"},{"location":"chap5/21Ana_KA/","title":"L1 Kinesis Analytics","text":""},{"location":"chap5/21Ana_KA/#1amazon-kinesis-data-analytics","title":"1\u3001Amazon Kinesis Data Analytics","text":"<p>Querying streams of data </p> <p>Querying streams of data continuously very similar to Spark streaming but it is specific to AWS Kinesis. </p> <p> </p> <p>Kinesis data analytics can receive data from either a Kinesis data stream or from a Kinesis data firehose stream.</p> <p>Receiving stream of data =&gt; write straight up SQL to analyze that data =&gt; spit out the results to some other stream </p>"},{"location":"chap5/21Ana_KA/#2kinesis-analytics-parts","title":"2\u3001Kinesis analytics parts","text":"<ul> <li>Input or the source can either be Kinesis streams or firehose streams coming in from the left there. </li> <li>Input or the source goes into Input Streams </li> <li>Optionally configure a reference data source to enrich your input data stream within the application. And Store your reference data as an object in an S3 bucket <ul> <li>When your Kinesis analytics application starts the Amazon Kinesis data analytics will read the Amazon S3 object and create an in application table so you can refer to that data in S3 </li> </ul> </li> <li>Application code: The real time analytics or the application code in the middle where the actual analysis happens and perform real time analytics just using straight up SQL queries on your stream <ul> <li>SQL statements: on StreamIng data and Reference tables. </li> </ul> </li> <li> <p>Output Stream: Processed Data output can be sent </p> <ul> <li>Kinesis data stream or to another data firehose stream again </li> <li>Data warehouse: S3 bucket or Amazon Redshift </li> <li>Lambd</li> </ul> </li> <li> <p>Application error stream: </p> <ul> <li>Certain records like a type mismatch or late arrival will be written out to the error stream. </li> </ul> </li> </ul>"},{"location":"chap5/21Ana_KA/#2-1-common-use-cases","title":"2-1 Common use-cases","text":"<ul> <li>Streaming ETL </li> <li>Continuous metric generation </li> <li>Responsive analytics </li> </ul>"},{"location":"chap5/21Ana_KA/#2-2-streaming-etl","title":"2-2 Streaming ETL","text":"<p>Build an application that continuously reads IoT sensor data stored in a Kinesis data stream, organize that data by the sensor type, remove duplicate data, normalize the data for a specified schema, and then go on to deliver that process data to Amazon S3.</p>"},{"location":"chap5/21Ana_KA/#2-3-continuous-metric-generation","title":"2-3 Continuous metric generation","text":"<p>Build leader board for a mobile game by computing the top players every minute and then sending that on to Amazon DynamoDB or you could check the traffic to your website by calculating the number of unique web site visitors every five minutes or so and then sending the process results off to Amazon Redshift for further analysis responsive analytics is another one. </p>"},{"location":"chap5/21Ana_KA/#2-4-responsive-analytics","title":"2-4 Responsive analytics","text":"<p>Application computing the availability or success rate of a customer facing API over time and then sending those results on to Amazon CloudWatch </p>"},{"location":"chap5/21Ana_KA/#3kinesis-analytics-costs-random_cut_forest","title":"3\u3001Kinesis Analytics Costs; <code>RANDOM_CUT_FOREST</code>","text":""},{"location":"chap5/21Ana_KA/#3-1-kinesis-analytics-costs","title":"3-1 Kinesis Analytics Costs","text":"<ul> <li>Pay only for resources consumed (but it's not cheap) </li> <li>Serverless; scales automatically </li> <li>Use IAM permissions to access streaming source and destiontion(s)</li> <li>Schema discovery </li> </ul>"},{"location":"chap5/21Ana_KA/#3-2-random_cut_forest","title":"3-2 <code>RANDOM_CUT_FOREST</code>","text":"<ul> <li>SQL function offered by Kinesis data analytics used for anomaly detection on numeric columns in a stream</li> <li>They're especially proud of this because they published a paper on it </li> <li>It's a novel way to identify outliers in a data set so you can handle them however you need to </li> <li>Example: detect anomalous subway ridership during the NYC marathon</li> </ul> <p>EXAM </p> <p>Question about trying to detect wog-oldies or outliers in a stream of data <code>RANDOM_CUT_FOREST</code> with Kinesis analytics is very likely a good answer for that. </p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/","title":"L2 Kinesis Analytics Exercise","text":""},{"location":"chap5/22Ana_Kinesis_ana_Exer/#1transaction-rate-alarm","title":"1\u3001Transaction Rate Alarm","text":"<p>Getting more than 10 orders in the span of 10 seconds. Individual orders mind you. Which may means my site is under some sort of weird attack where someone's using a fraudulent credit card to buy stuff on my Web site over and over again automatically.</p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#first-get-order-logs-from-ec2-from-kinesis-data-stream","title":"First get order logs from EC2 from kinesis data stream","text":"<ul> <li>CadabraOrders</li> <li>OrderRateAlarms</li> </ul> <p>Number of shards: 1</p> <p> </p> <p> </p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#second-create-some-order-logs","title":"Second: Create some order logs","text":"<p>ssh to EC2 instance</p> <pre><code>$ sudo service aws-kinesis-agent start\naws-kinesis-agent startup                                  [  OK  ]\n\n$ sudo ./LogGenerator.py \nWriting 100 lines starting at line 332524\n\nWrote 100 lines.\n\n$ tail -f /var/log/aws-kinesis-agent/aws-kinesis-agent.log\n</code></pre>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#third-create-kinesis-analytics","title":"Third: Create Kinesis Analytics","text":"<ul> <li>Application Name: TranscationRateMonitor</li> <li>Runtime; SQL</li> <li>Source: <ul> <li>Kinesis Data Streams: CadabraOrders</li> </ul> </li> <li>Automaitcally Schema discovery:</li> </ul>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#fourth-run-sql-analytics","title":"Fourth: Run SQL Analytics","text":"<pre><code>CREATE OR REPLACE STREAM \"ALARM_STREAM\" (order_count INTEGER);\n\nCREATE OR REPLACE PUMP \"STREAM_PUMP\" AS \n    INSERT INTO \"ALARM_STREAM\"\n        SELECT STREAM order_count\n        FROM (\n            SELECT STREAM COUNT(*) OVER TEN_SECOND_SLIDING_WINDOW AS order_count\n            FROM \"SOURCE_SQL_STREAM_001\"\n            WINDOW TEN_SECOND_SLIDING_WINDOW AS (RANGE INTERVAL '10' SECOND PRECEDING)\n        )\n        WHERE order_count &gt;= 10;\n\nCREATE OR REPLACE STREAM TRIGGER_COUNT_STREAM(\n    order_count INTEGER,\n    trigger_count INTEGER);\n\nCREATE OR REPLACE PUMP trigger_count_pump AS INSERT INTO TRIGGER_COUNT_STREAM\nSELECT STREAM order_count, trigger_count\nFROM (\n    SELECT STREAM order_count, COUNT(*) OVER W1 as trigger_count\n    FROM \"ALARM_STREAM\"\n    WINDOW W1 AS (RANGE INTERVAL '1' MINUTE PRECEDING)\n)\nWHERE trigger_count &gt;= 1;\n</code></pre> <p>Save and run:</p> <p><code>Trigger_Count_Stream</code>:</p> <p> </p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#fifth-connect-to-destination","title":"Fifth: Connect to destination","text":"<p>OrderRateAlarms:</p> <p> </p> <p> </p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#6th-create-lambda-function","title":"6th: Create Lambda function","text":""},{"location":"chap5/22Ana_Kinesis_ana_Exer/#6-1-create-iam-role-for-lambda-function","title":"6-1 Create IAM Role for Lambda function","text":"<ul> <li>Name: LambdaKinesisSNS</li> <li>Policy: <ul> <li>AWSLambdaKinesisExecutionRole </li> <li>AmazonSNSFullAccess</li> <li>CloudWatchLogsFullAccess</li> <li>AWSLambdaBasicExecutionRole</li> </ul> </li> </ul>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#6-2-create-lambda-function","title":"6-2 Create lambda function","text":"<ul> <li>Name: TransactionRateAlarm</li> <li>Runtime: Python2.7</li> <li>IAM role: LambdaKinesisSNS</li> </ul>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#6-3-create-lambda-function-tigger","title":"6-3 Create lambda function tigger","text":"<p>Kinesis: CadabraAlarms</p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#6-4-add-lambda-function","title":"6-4 Add lambda function","text":"<pre><code>from __future__ import print_function\nimport boto3\nimport base64\n\nclient = boto3.client('sns')\n# Include your SNS topic ARN here.\ntopic_arn = 'arn:aws:sns:us-east-1:...:CadabraAlarms\n\ndef lambda_handler(event, context):\n    try:\n        client.publish(TopicArn=topic_arn, Message='Investigate sudden surge in orders', Subject='Cadabra Order Rate Alarm')\n        print('Successfully delivered alarm message')\n    except Exception:\n        print('Delivery failure')\n</code></pre> <p>Change timeout to: 1m</p> <p> </p>"},{"location":"chap5/22Ana_Kinesis_ana_Exer/#7th-create-sns-for-alaram","title":"7th: Create SNS for alaram","text":"<p>Name: Cadabra Alarm</p> <p> </p> <p>Copy ALARM ARN back to Lambda function</p> <pre><code>topic_arn = 'arn:aws:sns:us-east-1:...:CadabraAlarms\n</code></pre>"},{"location":"chap5/23Ana_ES/","title":"L3 Amazon Elasticsearch Service","text":"<p>Petabyte-scale analysis and reporting </p> <p></p>"},{"location":"chap5/23Ana_ES/#1what-is-elasticsearch","title":"1\u3001What is Elasticsearch?","text":"<ul> <li>The Elastic Stack </li> <li>A search engine <ul> <li>JSON requests go search for documents that contain these keywords or attributes</li> <li>Built on top of an open source solution called Lucine and Elasticsearch fundamentally is just a scalable version of Lucine as distributed horizontally across many nodes in a cluster. </li> </ul> </li> <li>An analysis tool </li> <li>A visualization tool (Kibana)</li> <li>A data pipeline (Beats / LogStash) </li> <li>You can use Kinesis too </li> <li>Horizontally scalable </li> </ul>"},{"location":"chap5/23Ana_ES/#1-1-what-is-kibana","title":"1-1 What is Kibana","text":""},{"location":"chap5/23Ana_ES/#1-2-elasticsearch-applications","title":"1-2 Elasticsearch applications","text":"<ul> <li>Full-text search </li> <li>Log analytics </li> <li>Application monitoring </li> <li>Security analytics </li> <li>Clickstream analytics </li> </ul>"},{"location":"chap5/23Ana_ES/#1-3-amazon-elasticsearch","title":"1-3 Amazon Elasticsearch","text":"<p>Amazon ES is shorthand for Elasticsearch service Adobe can easily see traffic patterns and error rates and quickly identify and troubleshoot any potential issues all with reduced operational overhead.</p>"},{"location":"chap5/23Ana_ES/#1-4-elasticsearch-concepts","title":"1-4 Elasticsearch Concepts","text":""},{"location":"chap5/23Ana_ES/#documents","title":"documents","text":"<p>Documents are the things you're searching for. They can be more than text \u2014 any structured JSON data works. Every document has a unique ID, and a type. </p>"},{"location":"chap5/23Ana_ES/#types","title":"types","text":"<p>Elasticsearch releases types are going to be eliminated entirely.</p> <p>A type defines the schema and mapping shared by documents that represent the same sort of thing. (A log entry, an encyclopedia article, etc.) </p>"},{"location":"chap5/23Ana_ES/#indices","title":"indices","text":"<p>An index powers search into all documents within a collection of types. They contain inverted indices that let you search across everything within them at once. </p> <p>types are gonna be a thing of the past soon really want to think about documents and indices</p>"},{"location":"chap5/23Ana_ES/#1-5-an-index-is-split-into-shards","title":"1-5 An index is split into <code>shards</code>","text":"<p>Documents are hashed to a particular shard. </p> <p></p> <ul> <li>Each shard may be on a different node in a cluster. </li> <li>Every shard is a self-contained Lucene index of its own. </li> </ul> <p>Every shard is actually its own little mini search engine.</p>"},{"location":"chap5/23Ana_ES/#1-6-redundancy","title":"1-6 Redundancy","text":"<ul> <li>This index has two primary shards and two replicas. </li> <li>Your application should round-robin requests amongst nodes. </li> </ul> <ul> <li>Write requests are routed to the primary shard, then replicated </li> <li>Read requests are routed to the primary or any replica </li> </ul>"},{"location":"chap5/23Ana_ES/#2amazon-elasticsearch-service","title":"2\u3001Amazon Elasticsearch Service","text":""},{"location":"chap5/23Ana_ES/#2-1-amazon-elasticsearch-service","title":"2-1 Amazon Elasticsearch Service","text":"<ul> <li>Fully-managed (but not serverless) <ul> <li>Need decide how many servers you want in your Elasticsearch Cluster</li> </ul> </li> <li>Scale up or down without downtime <ul> <li>But this isn't automatic </li> </ul> </li> <li>Offer a lot of services<ul> <li>Elasticsearch APIs</li> <li>Managed Kibana</li> <li>Integrations with log stash</li> <li>Integrations with AWS services such as Kinesis</li> </ul> </li> <li>Pay for what you use <ul> <li>Instance-hours, storage, data transfer </li> </ul> </li> <li>Network isolation<ul> <li>Amazon VPC</li> </ul> </li> <li>AWS integration <ul> <li>S3 buckets (via Lambda to Kinesis) </li> <li>Kinesis Data Streams </li> <li>DynamoDB Streams </li> <li>CloudWatch / CloudTrail </li> <li>Zone awareness </li> </ul> </li> </ul>"},{"location":"chap5/23Ana_ES/#aws-integration","title":"AWS integration","text":"<ul> <li> <p>Ensure data security by encrypting your data at rest and in transit using keys </p> </li> <li> <p>Manage authentication and access control using Amazon Cognito and IAM policies</p> </li> <li> <p>Integrates with IoT well one good use case is sending data into Elasticsearch from your devices from your Internet of Things which can then be analyzed and visualized.</p> </li> <li> <p>Zone awareness so you can actually allocate nodes in your Elasticsearch service cluster across to different availability zones in the same region.</p> <ul> <li>Increase your high availability</li> <li>Increased latency</li> </ul> </li> </ul>"},{"location":"chap5/23Ana_ES/#2-2-amazon-es-options","title":"2-2 Amazon ES options","text":"<ul> <li>Dedicated master node(s) </li> <li>Choice of count and instance types </li> <li>\"Domains\" <ul> <li>Amazon Elasticsearch service domain is a collection of all the resources needed to run the ES cluster. So it contains all the configuration for the cluster as a whole.</li> </ul> </li> <li>Snapshots to S3 (automatic backup)</li> <li>Zone Awareness </li> </ul>"},{"location":"chap5/23Ana_ES/#2-3-amazon-es-security","title":"2-3 Amazon ES Security","text":"<ul> <li>Resource-based policies </li> <li>Identity-based policies </li> <li>IP-based policies </li> <li>Request signing </li> <li>VPC </li> <li>Cognito </li> </ul>"},{"location":"chap5/23Ana_ES/#resource-based-policies","title":"Resource-based policies","text":"<p>Attach those to the service domain that determines what actions a principal can take on Elasticsearch API is where a principal is a user an account to a role that can be granted access.</p>"},{"location":"chap5/23Ana_ES/#request-signing","title":"Request signing","text":"<p>All request Amazon ES must be signed and when you send in requests from the AWS SDKs to Elasticsearch</p>"},{"location":"chap5/23Ana_ES/#2-4-securing-kibana","title":"2-4 Securing Kibana","text":"<ul> <li>Cognito </li> <li>Getting inside a VPC from outside is hard... <ul> <li>Nginx reverse proxy on EC2 forwarding to ES domain </li> <li>SSH tunnel for port 5601 </li> <li>VPC Direct Connect </li> <li>VPN </li> </ul> </li> </ul>"},{"location":"chap5/23Ana_ES/#2-5-amazon-es-anti-patterns","title":"2-5 Amazon ES anti-patterns","text":"<ul> <li>OLTP <ul> <li>No transactions </li> <li>RDS or DynamoDB is better </li> </ul> </li> <li>Ad-hoc data querying <ul> <li>Athena is better </li> </ul> </li> <li>Remember Amazon ES is primarily for search &amp; analytics </li> </ul>"},{"location":"chap5/23Ana_ES/#3amazon-es-performance","title":"3\u3001Amazon ES performance","text":"<p>Memory pressure in the JVM can result if: </p> <ul> <li>You have unbalanced shard allocations across nodes </li> <li>You have too many shards in a cluster</li> </ul> <p>Fewer shards can yield better performance if JVMMemoryPressure errors are encountered </p> <ul> <li>Delete old or unused indices </li> </ul>"},{"location":"chap5/24Ana_ES_Exer/","title":"L4 Amazon Elasticsearch Service Exercise","text":""},{"location":"chap5/24Ana_ES_Exer/#1near-real-time-log-analysis","title":"1\u3001Near-real-time log analysis","text":""},{"location":"chap5/24Ana_ES_Exer/#1-1-cenerate-fake-log","title":"1-1 Cenerate Fake Log","text":"<pre><code>$ pwd\n/home/ec2-user\n\n$ wget http://media.sundog-soft.com/AWSBigData/httpd.zip\n--2020-02-12 00:27:39--  http://media.sundog-soft.com/AWSBigData/httpd.zip\nResolving media.sundog-soft.com (media.sundog-soft.com)... 52.217.38.124\nConnecting to media.sundog-soft.com (media.sundog-soft.com)|52.217.38.124|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 39403376 (38M) [application/octet-stream]\nSaving to: 'httpd.zip'\n\nhttpd.zip                      100%[===================================================&gt;]  37.58M  48.3MB/s    in 0.8s    \n\n2020-02-12 00:27:40 (48.3 MB/s) - 'httpd.zip' saved [39403376/39403376]\n\n\n$ unzip httpd.zip\n$ sudo mv httpd /var/log/httpd\n</code></pre>"},{"location":"chap5/24Ana_ES_Exer/#2create-amazon-es","title":"2\u3001Create Amazon ES","text":"<ul> <li>Create a new domain</li> <li>Deployment type: Development and testing</li> <li>Elasticsearch version: 6.8</li> <li>Elasticsearch domain name: cadabra</li> </ul> <ul> <li>Network configuration: Public access (Not recommended, only for exercise)</li> <li>Uncheck: Enable fine-grained access control</li> <li>Access policy: <ul> <li>Custom Access Policy</li> <li>IAM ARN</li> <li>arn:aws:iam::...:user/jacob.xi</li> <li>allow</li> </ul> </li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"*\"  \n      },\n      \"Action\": \"es:*\",\n      \"Resource\": \"arn:aws:es:us-east-1:371089343861:domain/cadabra/*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"chap5/24Ana_ES_Exer/#3create-firehose-delivery-stream-and-lambda-function","title":"3\u3001Create firehose delivery stream and Lambda function","text":"<ul> <li>New delivery stream: Weblogs</li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#3-1-lambda-function-to-transform-source","title":"3-1 Lambda function to transform source","text":"<ul> <li>Transform source records with AWS Lambda: Enabled</li> <li>Create New: Apache Log to JSON</li> </ul> <ul> <li>FunctionNameParameter: LogTransform</li> <li>TableNameParameter: LogTransform</li> </ul> <ul> <li>Change timeout to: 1 minute</li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#3-2-add-amazon-elasticsearch-service","title":"3-2 Add Amazon ElasticSearch Service","text":"<ul> <li>Domain: cadabra</li> <li>index: weblogs</li> <li>index rotation: 1day</li> <li>Type: weblogs</li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#3-3-add-s3-backup","title":"3-3 Add S3 backup","text":"<ul> <li>S3: kin-orderlogs</li> <li>prefix: es/</li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#3-4-elasticsearch-service-buffer-condition","title":"3-4 ElasticSearch Service buffer condition","text":"<ul> <li>buffer interval: 300s</li> <li>buffer size: 5MB</li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#3-5-create-new-default-firehose-iam-role-firehose_delivery_role","title":"3-5 Create new default firehose IAM role: <code>firehose_delivery_role</code>","text":""},{"location":"chap5/24Ana_ES_Exer/#3-6-add-aws-kinesis-agent-new-config","title":"3-6 Add <code>aws-kinesis-agent</code> new config","text":"<pre><code>$ ssh -i ...\n$ sudo vi /etc/aws-kinesis/agent.json\n\n{\n  \"cloudwatch.emitMetrics\": true,\n  \"kinesis.endpoint\": \"kinesis.us-east-1.amazonaws.com\",\n  \"firehose.endpoint\": \"firehose.us-east-1.amazonaws.com\",\n\n // \"awsAccessKeyId\": \"\",\n // \"awsAccessAccessKey\": \"\"\n\n  \"flows\": [\n    {\n      \"filePattern\": \"/var/log/httpd/ssl_access*\",\n      \"deliveryStream\": \"Weblogs\",\n      \"initialPosition\": \"START_OF_FILE\"    \n    }\n  ]\n}\n\n\n$ sudo service aws-kinesis-agent restart\naws-kinesis-agent startup                                  [  OK  ]\n</code></pre>"},{"location":"chap5/24Ana_ES_Exer/#3-7-check-amazon-es-indices","title":"3-7 Check Amazon ES indices","text":""},{"location":"chap5/24Ana_ES_Exer/#4kibana","title":"4\u3001Kibana","text":""},{"location":"chap5/24Ana_ES_Exer/#4-1-add-new-index","title":"4-1 Add new index","text":"<ul> <li>Index pattern: <code>weblogs*</code></li> <li>Time Filter field name\uff1a <code>@timestamp</code></li> </ul>"},{"location":"chap5/24Ana_ES_Exer/#4-2-add-visualize","title":"4-2 Add visualize","text":""},{"location":"chap5/25Ana_Athena/","title":"L5 Amazon Athena","text":""},{"location":"chap5/25Ana_Athena/#1athena-introdution","title":"1\u3001Athena Introdution","text":"<p>Serverless interactive queries of S3 data</p> <p></p> <ul> <li>Interactive query service for S3 (SQL) <ul> <li>No need to load data, it stays in S3 </li> </ul> </li> <li>Presto under the hood </li> <li>Serverless! </li> <li>Supports many data formats <ul> <li>CSV (human readable) </li> <li>JSON (human readable) </li> <li>ORC (columnar, splittable) </li> <li>Parquet (columnar, splittable)</li> <li>Avro (splittable) </li> </ul> </li> <li>Unstructured, semi-structured, or structured </li> </ul> <p>Athena doesn't really care if your data in S3 is structured or semi-structured or structured it can work with glue and the glue data catalog to impart structure on that data and make it something that you can query from a SQL command.</p>"},{"location":"chap5/25Ana_Athena/#csv","title":"CSV","text":"<p>CSV which is comma separated value and its tab separated value lists is that they're human readable. Every line contains a bunch of fields separated by commas.</p>"},{"location":"chap5/25Ana_Athena/#json","title":"JSON","text":"<p>JSON  has a bit more structure to it and that you can have more hierarchical data inside of it but it's still human readable</p> <p>It's still one row per document</p>"},{"location":"chap5/25Ana_Athena/#non-human-readable-formats-such-as-orc-and-parquet","title":"Non-human readable formats such as ORC and Parquet.","text":"<p>ORC and Parquet are both examples of columnar or formats that are also splittable.</p> <p>Instead of organizing data by rows it's organizing it by each column.</p> <p>Massive ORC or a massive Parquet file and still have the ability for your cluster to split that data and view it across different instances.</p>"},{"location":"chap5/25Ana_Athena/#avro","title":"Avro","text":"<p>Splittable file format but it is not columnar so it is not human readable.</p> <p>Row based storage</p>"},{"location":"chap5/25Ana_Athena/#some-examples","title":"Some examples","text":"<ul> <li>Ad-hoc queries of web logs </li> <li>Querying staging data before loading to Redshift </li> <li>Analyze CloudTrail / CloudFront / VPC / ELB etc logs in S3 </li> <li>Integration with Jupyter, Zeppelin, RStudio notebooks </li> <li>Integration with QuickSight </li> <li>Integration via ODBC / JDBC with other visualization tools </li> </ul>"},{"location":"chap5/25Ana_Athena/#2athena-and-glue-costs-and-security","title":"2\u3001Athena and Glue, Costs, and Security","text":""},{"location":"chap5/25Ana_Athena/#2-1-athena-glue","title":"2-1 Athena + Glue","text":"<ol> <li>Glue crawler populating the glue data catalogue for your S3 data that's looking at what's stored in S3 and try to extract columns and table definitions</li> <li>You can use the glue console to refine that definition as needed. </li> <li>You have a glue data catalogue published for your S3 data Athena and it can build a table from it automatically as well.</li> <li>Athena that can use that glue data catalogue either it will allow any other analytics tool to visualize or analyze that data as well. </li> <li> <p>RDS, redshift, redshift spectrum, EMR, any application that's compatible with an Apache hive metastore as well because remember the glue data catalog can be used as a hive metastore too.</p> </li> <li> <p>Athena integrated with AWS's glue data catalog that allows you to create a unified metadata repository across various services </p> </li> <li>Crawl data to discover schemas</li> <li>Populate your catalog with new and modified table and partition definitions, </li> <li>Maintain schema versioning all under the hood.</li> <li>Athena just sits on top of that and provides a SQL interface to that underlying glue structure</li> </ol>"},{"location":"chap5/25Ana_Athena/#2-2-athena-cost-model","title":"2-2 Athena cost model","text":"<ul> <li><code>Pay-as-you-go</code> <ul> <li>$5 per TB scanned</li> <li>Successful or cancelled queries count, failed queries do not. </li> <li>No charge for DDL (CREATE/ALTER/DROP etc.) </li> </ul> </li> <li>Save LOTS of money by using columnar formats <ul> <li>ORC, Parquet (Converting your data to a columnar format with ORC and Parquet)</li> <li>Save <code>30-90%</code>, and get better performance </li> </ul> </li> <li>Glue and S3 have their own charges </li> </ul> <p>Converting your data to a columnar format with ORC and Parquet.</p>"},{"location":"chap5/25Ana_Athena/#2-3-athena-security","title":"2-3 Athena Security","text":"<ul> <li>Access control <ul> <li>IAM, ACLs, S3 bucket policies </li> <li>AmazonAthenaFullAccess / AWSQuicksightAthenaAccess </li> </ul> </li> <li>Encrypt results at rest in S3 staging directory<ul> <li>S3 Server-side encryption with S3-managed key (SSE-S3)</li> <li>Server-side encryption with KMS key (SSE-KMS) </li> <li>Client-side encryption with KMS key (CSE-KMS) </li> </ul> </li> <li>Cross-account access in S3 bucket policy possible </li> <li>Transport Layer Security (TLS) encrypts in-transit (between Athena and S3) </li> </ul>"},{"location":"chap5/25Ana_Athena/#2-4-athena-anti-patterns","title":"2-4 Athena anti-patterns","text":"<ul> <li>Highly formatted reports / visualization<ul> <li>That's what QuickSight is for </li> </ul> </li> <li>ETL <ul> <li>Use Glue instead or Apache Spark for a larger scale tests.</li> </ul> </li> </ul>"},{"location":"chap5/25Ana_Athena/#3athena-performance","title":"3\u3001Athena Performance","text":"<ul> <li>Use columnar data (ORC, Parquet) </li> <li>Small number of large files performs better than large number of small files </li> <li>Use partitions <ul> <li>If adding partitions after the fact, use MSCK REPAIR TABLE command</li> </ul> </li> </ul>"},{"location":"chap5/26Glue_Athena_Exer/","title":"L6 [Exercise] AWS Glue and Athena","text":""},{"location":"chap5/26Glue_Athena_Exer/#1data-warehousing-with-visualization","title":"1\u3001Data Warehousing with visualization","text":"<ul> <li>AWS Glue to actually infer a schema from our data lake in S3</li> <li>Issue queries against that data from Athena as if it were a SQL database.</li> </ul>"},{"location":"chap5/26Glue_Athena_Exer/#2create-glue-cralwer","title":"2\u3001Create Glue cralwer","text":"<ul> <li>Crawler name: orderdata</li> <li>Crawler Source type: Data Stores<ul> <li>S3</li> <li><code>s3://glue-orderlogs</code></li> <li>Exclude Pattern: <code>es/**</code></li> </ul> </li> <li>Create IAM Role: OrderData</li> <li>Schedule: Run on demand</li> <li>Crawler output Database name: orderlogs</li> </ul> <p>Run the cralwer, then go to the glue table when status changed from running to stopping</p> <p></p> <p></p> <p></p>"},{"location":"chap5/26Glue_Athena_Exer/#2-1-change-table-col-name-edit-schema","title":"2-1 Change table col name: Edit Schema","text":"<ul> <li>InvoiceNo</li> <li>StockCode</li> <li>Description</li> <li>Quantity</li> <li>InvoiceDate</li> <li>UnitPrice</li> <li>CustomerID</li> <li>Country</li> <li>year</li> <li>month</li> <li>day</li> <li>hour</li> </ul>"},{"location":"chap5/26Glue_Athena_Exer/#3run-athena-sql","title":"3\u3001Run Athena SQL","text":"<ul> <li>Database name: orderlogs</li> </ul> <pre><code>SELECT description,\n         count(*)\nFROM kin_orderlogs\nWHERE country='France'\n        AND year='2020'\n        AND month='02'\nGROUP BY  description\n</code></pre>"},{"location":"chap5/26Glue_Athena_Exer/#3-1-change-settings-to-same-region-s3-bucket-with-athena","title":"3-1 Change settings to same region S3 bucket with Athena","text":""},{"location":"chap5/26Glue_Athena_Exer/#3-2-output-and-result-saved-in-s3","title":"3-2 Output and result saved in S3","text":""},{"location":"chap5/27Ana_Redshift/","title":"L7 AWS Redshift","text":""},{"location":"chap5/27Ana_Redshift/#1redshift-intro-and-architecture","title":"1\u3001Redshift Intro and Architecture","text":"<p>Redshift AWS's distributed to data warehouse solution</p> <p>Full-managed, petabytes-scale data warehouse spread across an entire cluster</p> <p></p>"},{"location":"chap5/27Ana_Redshift/#1what-is-redshift","title":"1\u3001What is Redshift?","text":"<ul> <li>Fully-managed, petabyte scale data warehouse service</li> <li>10X better performance than other data warehouses <ul> <li>Via speed using machine learning, massively parallel query(MPP) execution, columnar storage </li> </ul> </li> <li>Designed for OLAP(Online analytic processing), not OLTP </li> <li>Cost effective </li> <li>SQL ODBC, JDBC interfaces (SQL based clients and BI tools just using standard ODBC and JDBC connections.)</li> <li>Scale up or down on demand by (<code>AWS management console/Single API call</code>)</li> <li>Built-in replication &amp; backups </li> <li>Monitoring via CloudWatch / CloudTrail <ul> <li>Metrics </li> <li>Compute utilization</li> <li>Storage utilization</li> <li>Read and write traffic to the cluster.</li> <li>Custom metrics</li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#1-1-redshift-use-cases","title":"1-1 Redshift Use-Cases","text":"<ul> <li>Accelerate analytics workloads</li> <li>Machine learning(MPP) and columnar storage on high performance disks and result caching to make it superfast. </li> <li>Unified data warehouse &amp; data lake </li> <li>Redshift spectrum importing your unstructured data in S3 as just another table in your data warehouse.</li> <li>Data warehouse modernization <ul> <li>Make it move faster and more scalable and easier </li> </ul> </li> <li>Analyze global sales data</li> <li>Store historical stock trade data </li> <li>Analyze ad impressions &amp; clicks </li> <li>Aggregate gaming data </li> <li>Analyze social trends </li> </ul>"},{"location":"chap5/27Ana_Redshift/#1-2-redshift-architecture","title":"1-2 Redshift architecture","text":"<p>A cluster is the core infrastructure component of an Amazon Redshift data warehouse </p> <p>A cluster is composed of: </p> <ul> <li>One leader node</li> <li>One or more compute nodes contain between 1 and 128 compute nodes depending on the node type.<ul> <li>User data is going to be stored on the compute nodes</li> </ul> </li> </ul> <p></p>"},{"location":"chap5/27Ana_Redshift/#1-3-leader-node","title":"1-3 Leader node","text":"<ul> <li>Managing communication with the client programs and all communication with the compute nodes</li> <li>It's sort of the interface between your external clients to redshift and the compute nodes under the hood</li> <li>It receives all the queries from client applications passes the queries</li> <li>Develops execution plans which are an ordered set of steps to process those queries.</li> <li>It coordinates the parallel execution of those plans with the compute nodes and also aggregates the intermediate results from those nodes.</li> <li>Finally the leader node will return those results back to the client applications.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#1-4-compute-nodes","title":"1-4 compute nodes","text":"<ul> <li>Responsible for executing the steps specified in the execution plans from the leader node</li> <li>Transmitting data among compute nodes to serve those queries</li> <li>Sendsintermediate results back to the leader node for aggregation</li> </ul>"},{"location":"chap5/27Ana_Redshift/#1-5-compute-node-types","title":"1-5 Compute node types","text":"<p>Compute node has its own dedicated CPU, memory, and attached disk storage which are determined by the node type.</p> <ul> <li><code>Dense storage =&gt; HDS</code></li> <li><code>Dense compute =&gt; SSD</code></li> </ul>"},{"location":"chap5/27Ana_Redshift/#dense-storageds-node","title":"Dense storage(D.S. node)","text":"<p>Very large data warehouse using hard disk drives(HDD) for a very low price point.</p> <ul> <li>xlarge (3HDD total 2TBs of magnetic storage on that node)</li> <li>8xlarge (24HDD total 16TBs of magnetic storage on that node)</li> <li>D.S. 2.8xlarge has 36 Intel Xeone 526 76 Haswell virtual cores and 244 GB of RAM whereas an extra large has for Intel Xeone 526 76 Haswell virtual cores and 31GB of RAM.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#dense-compute-dc-node","title":"Dense compute (D.C. node)","text":"<p>Create very high performance data warehouses using fast CPUs large amounts of ram and SSD.</p> <p>SSD size</p> <ul> <li>xlarge: 160gb of SSD storage 2vCPU and 15gbs of RAM</li> <li>8xlarge: 2.56tb of SSD, 32 vCPU and 244 gbs of RAM </li> </ul>"},{"location":"chap5/27Ana_Redshift/#1-6-compute-node-slice","title":"1-6 Compute Node Slice","text":"<p>Compute node have node slices. So every compute node is divided into slices and a portion of the nodes memory and disk space is going to be allocated to each slice where it processes a portion of the workload assigned to that node</p>"},{"location":"chap5/27Ana_Redshift/#2redshift-spectrum-and-performance-tuning","title":"2\u3001Redshift Spectrum and Performance Tuning","text":"<p>Athena could use the AWS Glue catalog to make tables on top of your S3 data redshift spectrum can do the same thing. </p> <p></p>"},{"location":"chap5/27Ana_Redshift/#2-1-redshift-spectrum","title":"2-1 Redshift Spectrum","text":"<ul> <li>Query exabytes of unstructured data in S3 without loading <ul> <li>Like tables embody in redshift redshift cluster.</li> </ul> </li> <li>Limitless concurrency<ul> <li>multiple queries to access the same data simultaneously in S3 it can scale out to thousands of instances if needed. </li> </ul> </li> <li>Horizontal scaling </li> <li>Separate storage &amp; compute resources <ul> <li>All of your storage is being done in S3. </li> <li>Spectrum is just doing the compute part of analyzing that data. </li> </ul> </li> <li>Wide variety of data formats <ul> <li>Avro, CSV, Grok, Ion, JSON, ORC, Parquet, RC file, Regx, Cirta, sequence files, text files, and TSVs </li> </ul> </li> <li>Support of Gzip and Snappy compression <ul> <li>Compress your S3 data to save space and save bandwidth </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#2-2-redshift-performance","title":"2-2 Redshift Performance","text":"<ul> <li>Massively Parallel Processing (MPP)</li> <li>Columnar Data Storage </li> <li>Column Compression </li> <li>Copy command / Analyze compression command</li> </ul>"},{"location":"chap5/27Ana_Redshift/#mpp","title":"MPP","text":"<p>Do that data and query loads are automatically distributed across all nodes and adding nodes to the data warehouse is made easy and also enables fast query performance as the data warehouse grows so it will do all of its queries in parallel.</p> <p>More speed or more capacity just add more nodes</p>"},{"location":"chap5/27Ana_Redshift/#columnar-data-storage","title":"Columnar Data Storage","text":"<ul> <li>Uses columnar data storage so your data is organized by column as column</li> <li>Ideal for data warehousing and analytics for large data set querying because typically you're just looking at specific columns of a large number of columns so you can save a lot of bandwidth</li> </ul>"},{"location":"chap5/27Ana_Redshift/#column-compression","title":"Column Compression","text":"<p>Data format multiple compression: </p> <ul> <li>Select the most appropriate compression schema</li> <li>Data is loaded into an empty table </li> <li>Compression is a column level operation that reduces the size of the data</li> <li>Compression can conserve storage space and and reduces the size of data that is read from the storage.</li> <li>It reduces the amount of disk IO and improves your query performance.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#copy-command-analyze-compression-command","title":"Copy command / Analyze compression command","text":"<ul> <li>Loading data into a redshift cluster by copy command</li> <li>Copy command it will automatically analyze and apply compression automatically.</li> <li>It's not possible to change the compression encoding for a column after the table is created.</li> <li>Analyze compression command which will perform compression analysis and produce a report with the suggested compression encoding for the tables analyzed.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#3redshift-durability-and-scaling","title":"3\u3001Redshift Durability and Scaling","text":""},{"location":"chap5/27Ana_Redshift/#3-1-redshift-durabillty","title":"3-1 Redshift Durabillty","text":"<ul> <li>Replication within cluster</li> <li>Backup to S3 </li> <li>Asynchronously replicated to snapshots to S3 in another region </li> <li>Automated snapshots (1 day retention period by default, top to 35 days)</li> <li>Failed drives/nodes automatically replaced</li> <li>AWS recommends at least two nodes in your cluster </li> <li>However\u4e00 limited to a single avallabdity zone(AZ) </li> </ul>"},{"location":"chap5/27Ana_Redshift/#three-copies-of-the-data-are-maintained","title":"Three copies of the data are maintained","text":"<ul> <li>On the original compute nodes</li> <li>On a replica on compute nodes </li> <li>In a backup in S3.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#drive-failure","title":"Drive failure","text":"<ul> <li>The Redshift cluster will remain available with a slight decline in performance of certain queries </li> <li>Redshift rebuilds that drive from a replica of the data on that drive which is stored on another drive within that node</li> </ul>"},{"location":"chap5/27Ana_Redshift/#single-node-cluster","title":"Single node cluster","text":"<ul> <li>Do not support data replication </li> <li>Only restore your cluster from a snapshot in S3 instead</li> </ul>"},{"location":"chap5/27Ana_Redshift/#individual-node-failure","title":"Individual node failure","text":"<ul> <li>Automatically detect that node failure</li> <li>Replace a failed node in data warehouse cluster. </li> </ul>"},{"location":"chap5/27Ana_Redshift/#limited-to-a-single-avallabdity-zoneaz","title":"limited to a single avallabdity zone(AZ)","text":"<p>However you can restore the cluster from any existing snapshot to a new availability zone within the <code>same region</code>.</p>"},{"location":"chap5/27Ana_Redshift/#3-2-scaling-redshift","title":"3-2 Scaling Redshift","text":"<ul> <li>Vertical and horizontal scaling on demand<ul> <li>Increasing the node instance type</li> <li>Increasing the number of nodes</li> </ul> </li> <li>During scaling: <ul> <li>A new cluster is created while your old one remains available for reads </li> <li>CNAME is flipped to new cluster (a few minutes of downtime) </li> <li>Data moved in parallel to new compute nodes </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#4redshift-distribution-styles","title":"4\u3001Redshift Distribution Styles","text":"<p>How the data in your table is distributed across many compute nodes and many slices within those nodes.</p> <p>Two primary goals of data distribution:</p> <ul> <li>Distribute the workload uniformly among the nodes in the cluster</li> <li>Minimize data movement during query execution. </li> </ul>"},{"location":"chap5/27Ana_Redshift/#4-1-redshift-distribution-styles","title":"4-1 Redshift Distribution Styles","text":"<ul> <li>AUTO <ul> <li>Redshift figures it out based on size of data </li> </ul> </li> <li>EVEN <ul> <li>Rows distributed across slices in round-robin </li> </ul> </li> <li>KEY <ul> <li>Rows distributed based on one column </li> </ul> </li> <li>ALL <ul> <li>Entire table is copied to every node </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#4-2-auto-distribution-dont-specify","title":"4-2 Auto distribution (don't specify)","text":"<p>Redshift will assign an optimal distribution style</p>"},{"location":"chap5/27Ana_Redshift/#4-3-even-distribution","title":"4-3 Even distribution","text":"<p>Even distribution regardless of the values in any particular column the leader node distributes the rows across the slices in a round robin fashion and spread things out as evenly as possible.</p> <p></p> <p>Step through each individual slice and keep assigning new data to each slice in a circular manner.</p>"},{"location":"chap5/27Ana_Redshift/#4-4-key-distribution","title":"4-4 key distribution","text":"<p>Make sure that all the data associated with a specific key value will be physically located on the same slice and that can speed up your queries.</p> <p></p> <ul> <li>New rows are coming in from your incoming data those keys will be hashed and set to a specific slice based on how that key is hashed.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#4-5-all-distribution","title":"4-5 All distribution","text":"<ul> <li>A copy of the entire table is distributed to every node </li> <li>Ensures that every row is co-located for every join that the table participates in the all distribution multiplies the storage required by the number of nodes in the cluster.</li> <li>Much longer to load update or insert data into multiple tables all distribution</li> <li>Small dimension tables do not benefit significantly from all distribution.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#5redshift-sort-keys","title":"5\u3001Redshift Sort Keys","text":"<ul> <li>Creating a table you can define one or more of its columns as sort keys.</li> <li>When data is initially loaded into an empty table the rows are stored on disk in sorted order.</li> <li>The sorting enables efficient handling of range restricted </li> <li>Predicates redshift will automatically store the minimum and maximum values for each block as part of its metadata.</li> <li>If a query uses a range restricted predicate the query processor can use the min and max values to rapidly skip over large numbers of blocks during table scans.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#5-1-redshift-sort-keys","title":"5-1 Redshift Sort Keys","text":"<ul> <li>Rows are stored on disk in sorted order based on the column you designate as a sort key </li> <li>Like an index </li> <li>Makes for fast range queries </li> <li>Choosing a sort key <ul> <li>Recency? Filtering? Joins? </li> </ul> </li> <li>Single vs. Compound vs Interleaved sort keys </li> </ul> <p>Recency(Recent Data) =&gt; timestamp column</p> <p>Frequent range filtering or equality filtering on one column</p> <p>Frequently join =&gt;  join column for source key and the distribution key.</p>"},{"location":"chap5/27Ana_Redshift/#5-2-sort-keys-single-column","title":"5-2 Sort Keys\uff1a Single Column","text":"<p>A single column a single value to sort the data.</p> <p></p> <p>Is useful if you're consistently querying for data within a single filter column like sort key by date</p>"},{"location":"chap5/27Ana_Redshift/#5-3-sort-keyscompound","title":"5-3 Sort Keys\uff1aCompound","text":"<p>A compound key is made up of all the columns listed in the sort key definition in the order they are listed in.</p> <p></p> <p>Most useful when a query's filter applies conditions such as filters and joins that use a prefix of the sort keys</p> <p>Performance decrease when queries depend only on secondary sort columns without referencing the primary column. =&gt; Make sure that your primary column is one that you will most often be including in your queries.</p> <ul> <li>Compound is the default sort type </li> <li>Improve compression so their default for a reason</li> </ul>"},{"location":"chap5/27Ana_Redshift/#sort-keys-interleaved","title":"Sort Keys\uff1a Interleaved","text":"<p>Gives equal weight to each column or subset of columns in the sort key.</p> <p>Useful if multiple queries use different columns for filters it uses an internal compression</p> <p></p> <p>Schema for a zone map values that enables them to better discriminate among column values that have a long common prefix.</p>"},{"location":"chap5/27Ana_Redshift/#6redshift-data-flows-and-the-copy-command","title":"6\u3001Redshift Data Flows and the COPY command","text":""},{"location":"chap5/27Ana_Redshift/#6-1-importing-exporting-data","title":"6-1 Importing / Exporting data","text":"<ul> <li>COPY command <ul> <li>Parallelized; efficient </li> <li>From S3, EMR, DynamoDB, remote hosts(SSH)</li> <li>role based or key based access control to provide authentication FOR load or unload</li> <li>S3 requires a manifest file and IAM role </li> </ul> </li> <li>UNLOAD command <ul> <li>Unload from a table into files in S3 </li> </ul> </li> <li>Enhanced VPC routing </li> </ul>"},{"location":"chap5/27Ana_Redshift/#example-copy-command-to-load-from-amazon-s3","title":"Example: copy command to load from Amazon S3","text":"<p>There are couple ways:</p> <ul> <li>Using an Amazon S3 object prefix which it would load all the data underneath a specific prefix or a path in S3.<ul> <li>COPY <code>s3://bucket_name/object_prefix</code>+<code>authorization</code></li> </ul> </li> <li>Use a manifest file which is a JSON format of files in S3 that lists the data files that you want to load.<ul> <li>COPY <code>s3://booking_name/manifest_file</code>+ <code>authorization</code></li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#enhanced-vpc-routing","title":"Enhanced VPC routing","text":"<ul> <li>Force all of your copy and unload traffic between your cluster and the repositories through your Amazon VPC. (Set up VPCe or Nat gateways or Internet gateways within your VPC)</li> <li>Otherwise all of that copy and unload traffic will be routed through the Internet.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#6-2-copy-command-more-depth","title":"6-2 COPY command: More depth","text":"<ul> <li>Use COPY to load large amounts of data from outside(EXTERNAL) of Redshift </li> <li>If your data is already in Redshift in another table(INTERNAL), <ul> <li>Use <code>INSERT INTO ...SELECT</code> </li> <li>Or <code>CREATE TABLE AS</code> </li> </ul> </li> <li>COPY can decrypt data as it is loaded from S3 <ul> <li><code>Hardware-accelerated SSL</code> used to keep it fast </li> </ul> </li> <li>Gzip, Izop, and bzip2 compression supported to speed it up further </li> <li>Automatic compression option <ul> <li>Analyzes data being loaded and figures out optimal compression scheme for storing it </li> </ul> </li> <li>Special case: narrow tables (lots of rows, few columns) <ul> <li>Load with a single COPY transaction if possible </li> <li>Otherwise hidden metadata columns consume too much space </li> </ul> </li> </ul> <p>Exam:</p> <p>How to efficiently load data into redshift from outside: <code>copy command</code></p> <p>How to optimize the usage of your actual storage on your cluster: <code>Automatic compression and analyzes data</code></p>"},{"location":"chap5/27Ana_Redshift/#6-3-redshift-copy-grants-for-cross-region-snapshot-copies","title":"6-3 Redshift copy grants for cross-region snapshot copies","text":"<ul> <li>Let's say you have a <code>KMS-encrypted</code> Redshift cluster and a snapshot of it </li> <li>You want to copy that snapshot to another region for backup</li> <li>In the destination AWS region: <ul> <li>Create a KMS key if you don't have one already </li> <li>Specify a unique name for your snapshot copy grant </li> <li>Specify the KMS key ID for which you're creating the copy grant </li> </ul> </li> <li>In the source AWS region: <ul> <li>Enable copying of snapshots to the copy grant you just created </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#6-4-dblink","title":"6-4 DBLINK","text":"<ul> <li>Connect Redshift to PostgreSQL (possibly in RDS) </li> <li>Good way to copy and sync data between PostgreSQL and Redshift </li> </ul> <ul> <li>launch Redshift cluster and PostgreSQL RDS in same AZ </li> <li>Configure VPC security group for Redshift cluster to allow incoming connection from PostgreSQL  </li> </ul> <pre><code>CREATE EXTENSION postgres_fdw; \nCREATE EXTENSION dblink; \nCREATE SERVER foreign_server \n    FOREIGN DATA WRAPPER postgres_fdw \n    OPTIONS (host '&lt;omazon_redshift eip,, port '&lt;port&gt;, dbnome '&lt;datobose_nome&gt;, sslmode 'require'); \n    CREATE USER MAPPING FOR &lt;rds_postgresql_username&gt; \n    SERVER foreign_server \n    OPTIONS (user '&lt;amazon_redshift_username&gt;, password '&lt;password&gt;'); \n</code></pre>"},{"location":"chap5/27Ana_Redshift/#7redshift-integration-wlm-vacuum-anti-patterns","title":"7\u3001Redshift Integration / WLM / Vacuum / Anti-Patterns","text":""},{"location":"chap5/27Ana_Redshift/#7-1-integration-with-other-services","title":"7-1 Integration with other services","text":"<ul> <li>S3</li> <li>DynamoDB </li> <li>EMR / EC2 </li> <li>Data Pipeline </li> <li>Database Migration Service </li> </ul> <ul> <li>S3: Parallel processing to export or import multiple data files from S3</li> <li>DynamoDB: Using Copy command to load a redshift table with data from a single Amazon dynamoDB table.</li> <li>EMR / EC2: Using Copy command to import from EMR and import data using SSH.</li> <li>Data Pipeline: Automate the data movement and transformation in and out of redshift tables using data pipeline.</li> <li>Database Migration Service: Migrate data from some existing data warehouse into Amazon Redshift</li> </ul>"},{"location":"chap5/27Ana_Redshift/#7-2-redshift-workload-management-wlm","title":"7-2 Redshift Workload Management (WLM)","text":"<ul> <li>Prioritize short, fast queries vs. long, slow queries </li> <li>Query queues </li> <li>Via console, CLI, or API </li> </ul>"},{"location":"chap5/27Ana_Redshift/#what-is-wlmprioritize","title":"What is WLM(Prioritize)?","text":"<p>WLM is a way to help users prioritize workloads so that short fast running queries are not stuck behind long running slow queries.The way it works is by creating query queues at runtime according to service classes and configuration parameters for various types of queues are defined by those service classes.</p>"},{"location":"chap5/27Ana_Redshift/#how-or-manage-wlmquery-queues","title":"How or manage WLM(Query queues)?","text":"<p>Modify the WLM configuration to create separate queues for long running queries and for short running queries thereby improving system performance and user experience.</p>"},{"location":"chap5/27Ana_Redshift/#how-or-set-this-upexam","title":"How or set this up(<code>Exam</code>)?","text":"<ul> <li>Amazon Redshift management console </li> <li>Amazon Redshift command line interface</li> <li>Amazon Redshift API </li> </ul>"},{"location":"chap5/27Ana_Redshift/#7-3-concurrency-scaling","title":"7-3 Concurrency Scaling","text":"<ul> <li>Automatically adds cluster capacity to handle increase in concurrent read queries </li> <li>Support virtually unlimited concurrent users &amp; queries</li> <li>WLM queues manage which queries are sent to the concurrency scaling cluster</li> <li>WLM queues is not free</li> </ul>"},{"location":"chap5/27Ana_Redshift/#workload-management-queuewlm-queues","title":"workload management queue(WLM queues)","text":"<p>It can help to manage queries are sent to the concurrency scaling cluster so you can manage:  </p> <ul> <li>What queue you assign your queries to </li> <li>Which ones can actually take advantage of concurrency scaling and which ones do not.</li> <li>Pick and choose which queries take advantage of concurrency scaling.<ul> <li>Segregate those read queries might be bursting or vary in time in their frequency and use that to automatically scale out the capacity for that specific query.</li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#7-3-automatic-workload-management","title":"7-3 Automatic Workload Management","text":"<ul> <li>Creates up to 8 queues </li> <li>Default 5 queues with even memory allocation </li> <li>Large queries (ie big hash joins -&gt; concurrency lowered) <ul> <li>Larger queries need more capacity so lower concurrency. </li> </ul> </li> <li>Small queries (ie inserts, scans, aggregations) -&gt; concurrency raised </li> <li>Configuring query queues <ul> <li>Priority:  Relative importance of queries within a workload.</li> <li>Concurrency scaling mode: Set particular queue to have access to concurrency scaling cluster </li> <li>User groups </li> <li>Query groups </li> <li>Query monitoring rules </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#3user-group","title":"3.User group","text":"<p>Set of user groups to a queue by specifying a user group name or by using wildcards.</p> <p>When a member of a listed user group runs a query that query will automatically run within the corresponding queue so you can assign queues to query queues based on users.</p>"},{"location":"chap5/27Ana_Redshift/#4query-group-set-by-label","title":"4.Query group - set by Label","text":"<p>Assign a query group label to a series of queries and that will define which queue that query goes into</p>"},{"location":"chap5/27Ana_Redshift/#5query-monitoring-rules","title":"5.Query monitoring rules","text":"<p>Define metric space performance boundaries for workflow management queue</p> <p>Specify what action to take when a query goes beyond those boundaries.</p> <p>Example:</p> <ul> <li>Queue for dedicated to short running queries and you might have a query monitoring role that aborts those queries if run for more than 60s</li> <li>Short query queue is handling short queries if something goes wrong with one of those queries it's not going to hold up all the other queries in that queue.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#7-4-manual-workload-management","title":"7-4 Manual Workload Management","text":"<ul> <li>One default queue with concurrency level of 5 (5 queries at once) </li> <li>Superuser queue with concurrency level 1<ul> <li>Intended for administrative queries</li> </ul> </li> <li>Define up to 8 queues, up to concurrency level 50 <ul> <li>Each can have defined concurrency scaling mode, concurrency level, user groups, query groups, memory, timeout, query monitoring rules </li> <li>Can also enable query queue hopping </li> <li>Timed out queries \"hop\" to next queue to try again </li> </ul> </li> </ul> <p>Concurrency levels define how many queries can I run at once within this queue.</p>"},{"location":"chap5/27Ana_Redshift/#query-queue-hopping","title":"Query queue hopping","text":"<p>So if you have a query that times out within a given queue you can configure things to have it hop to the next queue</p>"},{"location":"chap5/27Ana_Redshift/#7-5-short-query-acceleration-sqa","title":"7-5 Short Query Acceleration (SQA)","text":"<ul> <li>Prioritize short-running queries over longer-running ones </li> <li>Short queries run in a dedicated space, won't wait in queue behind long queries </li> <li>Can be used in place of WLM queues for short queries </li> <li>Works with: <ul> <li><code>CREATE TABLE AS</code> (CTAS) </li> <li><code>Read-only queries</code> (SELECT statements) </li> </ul> </li> <li>Uses machine learning to predict a query's execution time </li> <li>Can configure how many seconds is \"short\"</li> </ul>"},{"location":"chap5/27Ana_Redshift/#7-6-vacuum-command","title":"7-6 VACUUM command","text":"<p>Vacuum is the command used to <code>recover space from deleted rows</code> and to <code>restore the sort order</code>.</p> <ul> <li>Recovers space from deleted rows </li> <li>VACUUM FULL </li> <li>VACUUM DELETE ONLY </li> <li>VACUUM SORT ONLY </li> <li>VACUUM REINDEX </li> </ul>"},{"location":"chap5/27Ana_Redshift/#vacuum-fulldefault","title":"vacuum full(default)","text":"<p>Re-sort all of the rows and reclaim space from deleted rows.</p>"},{"location":"chap5/27Ana_Redshift/#vacuum-delete-only","title":"VACUUM DELETE ONLY","text":"<p>Just reclaiming deleted row space and not actually trying to record it and skips the sorting part.</p>"},{"location":"chap5/27Ana_Redshift/#vacuum-sort-only","title":"VACUUM SORT ONLY","text":"<p>Re-sort the table but not reclaim this space.</p>"},{"location":"chap5/27Ana_Redshift/#vacuum-reindex","title":"VACUUM REINDEX","text":"<p>Re-index will reanalyze the distribution of the values in the table sort.</p>"},{"location":"chap5/27Ana_Redshift/#redshift-anti-patterns","title":"Redshift anti-patterns","text":"<ul> <li>Small data sets<ul> <li>Use RDS instead </li> </ul> </li> <li>OLTP <ul> <li>Use RDS or DynamoDB instead </li> </ul> </li> <li>Unstructured data <ul> <li>ETL first with EMR etc.</li> <li>Redshift spectrum let you query unstructured data in S3 </li> </ul> </li> <li>BLOB data <ul> <li>Store references to large binary files in S3, not the files themselves. </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#8redshift-resizing-elastic-vs-classic-and-new-redshift-features-in-2020","title":"8\u3001Redshift Resizing (elastic vs. classic) and new Redshift features in 2020","text":""},{"location":"chap5/27Ana_Redshift/#8-1-resizing-redshift-clusters","title":"8-1 Resizing Redshift Clusters","text":"<ul> <li>Elastic resize <ul> <li>Quickly add or remove nodes of same type </li> <li>Cluster is down for a few minutes </li> <li>Tries to keep connections open across the downtime</li> <li>Limited to doubling or halving for some dc2 and ra3 node types. </li> </ul> </li> <li>Classic resize <ul> <li>Change node type and/or number of nodes </li> <li>Cluster is read-only for hours to days </li> </ul> </li> <li>Snapshot, restore, resize <ul> <li>Used to keep cluster available during a classic resize </li> <li>Copy cluster, resize new cluster </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#8-2-new-redshift-features-for-2020","title":"8-2 New Redshift features for 2020","text":"<ul> <li>RA3 nodes with managed storage <ul> <li>Enable independent scaling of compute and storage</li> </ul> </li> <li>Redshift data lake export <ul> <li>Unload Redshift query to S3 in Apache Parquet format </li> <li>Parquet is 2x faster to unload and consumes up to 6X less storage </li> <li>Compatible with Redshift Spectrum, Athena, EMR, SageMaker </li> <li>Automatically partitioned </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#9amazon-relational-database-servicerds-and-aurora","title":"9\u3001Amazon Relational Database Service(RDS) and Aurora","text":"<p>Relational Database</p> <p></p>"},{"location":"chap5/27Ana_Redshift/#9-1-what-is-rds","title":"9-1 What is RDS?","text":"<ul> <li>Hosted relational database <ul> <li>Amazon Aurora</li> <li>MySQL </li> <li>PostgreSQL </li> <li>MariaDB </li> <li>Oracle </li> <li>SQL Server </li> </ul> </li> <li>Not for \"big data\" <ul> <li>Might appear on exam as an example of what not to use </li> <li>Or in the context of migrating from RDS to Redshift etc. </li> </ul> </li> </ul>"},{"location":"chap5/27Ana_Redshift/#acid","title":"ACID","text":"<ul> <li> <p>RDS databases offer full ACID compliance </p> <ul> <li>Atomicity </li> <li>Consistency </li> <li>Isolation </li> <li>Durability </li> </ul> </li> <li> <p>Atomicity ensures that either the transaction as a whole is successfully executed or if part of a transaction fails then the entire transaction is invalidated.</p> </li> <li>Consistency ensures that the data written into the database as part of the transaction must adhere to all defined rules and restrictions including constraints cascades and trigger</li> <li>isolation ensures that each transaction is independent to itself. Critical in achieving concurrency control.</li> <li>durability ensures that all of the changes made to the database be permanent.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#9-2-amazon-aurora","title":"9-2 Amazon Aurora","text":"<ul> <li>MySQL and PostgreSQL \u2014 compatible </li> <li>Up to 5X faster than MySQL, 3X faster than PostgreSQL </li> <li>1/10 the cost of commercial databases </li> <li>Up to 64TB per database instance</li> <li>Up to 15 read replicas </li> <li>Continuous backup to S3</li> <li>Replication across availability zones </li> <li>Automatic scaling with Aurora Serverless </li> </ul>"},{"location":"chap5/27Ana_Redshift/#9-3-aurora-security","title":"9-3 Aurora Security","text":"<ul> <li>VPC network isolation </li> <li>At-rest with KMS <ul> <li>Data, backup, snapshots, and replicas can be encrypted </li> </ul> </li> <li>In-transit with SSL </li> </ul>"},{"location":"chap5/27Ana_Redshift/#10redshift-security-concerns","title":"10\u3001Redshift security concerns","text":""},{"location":"chap5/27Ana_Redshift/#10-1-using-a-hardware-security-module-hsm","title":"10-1 Using a Hardware Security Module (HSM)","text":"<ul> <li>Must use a client and server certificate to configure a trusted connection between Redshift and the HSM </li> <li>If migrating an unencrypted cluster to an HSM-encrypted cluster, you must create the new encrypted cluster and then move data to it.</li> </ul>"},{"location":"chap5/27Ana_Redshift/#10-2-defining-access-privileges-for-user-or-group","title":"10-2 Defining access privileges for user or group","text":"<ul> <li>Use the GRANT or REVOKE commands in SQL </li> <li>Example: grant select on table foo to bob; </li> </ul>"},{"location":"chap5/28Redshift_Spectrum_exer/","title":"L8 [Exercise] Redshift Spectrum","text":""},{"location":"chap5/28Redshift_Spectrum_exer/#make-sure","title":"Make sure","text":"<ul> <li>AWS Glue run successfully and generate glue database and table</li> <li>Redshift, glue and S3 located in same region like athena</li> </ul>"},{"location":"chap5/28Redshift_Spectrum_exer/#1create-redshift","title":"1\u3001Create Redshift","text":"<p>Rather than copy data from S3 to Redshift directly, we will set Redshift Spectrum on AWS glue, it can expose my S3 data to redshift spectrum</p> <ul> <li>Type: dc2.large</li> <li>Cluster identifier: cadabra</li> <li>Master user name: awsuser</li> <li>Master user password: password</li> </ul> <p></p> <p></p>"},{"location":"chap5/28Redshift_Spectrum_exer/#1-1-create-iam-role-for-redshift","title":"1-1 Create IAM role for Redshift","text":"<ul> <li>Name: RedshiftSpectrum</li> <li>Policy:<ul> <li>AmazonS3ReadOnlyAccess</li> <li>AWSGlueConsoleFullAccess</li> </ul> </li> </ul> <p>Copy ARN:<code>arn:aws:iam::...:role/RedshiftSpectrum</code></p> <p></p> <p></p>"},{"location":"chap5/28Redshift_Spectrum_exer/#1-2-enter-iam-arn","title":"1-2 Enter IAM ARN","text":""},{"location":"chap5/28Redshift_Spectrum_exer/#1-3-use-default-configuration-otherwise","title":"1-3 Use <code>default</code> configuration otherwise","text":"<ul> <li>Database name: dev</li> </ul> <p>Create Redshift</p>"},{"location":"chap5/28Redshift_Spectrum_exer/#2create-redshift-schema-from-glue","title":"2\u3001Create Redshift schema from glue","text":""},{"location":"chap5/28Redshift_Spectrum_exer/#2-1-connect-to-redshift","title":"2-1 Connect to Redshift","text":"<pre><code>create external schema orderlog_schema from data catalog\ndatabase 'orderlogs'\niam_role 'arn:aws:iam:...:role/RedshiftSpectrum'\nregion 'us-east-2'\n</code></pre> <ul> <li>glue database: orderlogs</li> </ul> <pre><code>SELECT description,\n         count(*)\nFROM orderlog_schema.glue_orderlogs\nWHERE country='France'\n        AND year='2020'\n        AND month='02'\n</code></pre>"},{"location":"chap6/30Vis_Qs/","title":"L1 Visualization","text":""},{"location":"chap6/30Vis_Qs/#1intro-to-amazon-quicksight","title":"1\u3001Intro to Amazon Quicksight","text":"<p>Business analytics and visualization in the cloud </p> <p></p>"},{"location":"chap6/30Vis_Qs/#1-1-what-is-quicksight","title":"1-1 What is QuickSight?","text":"<ul> <li>Fast, easy, cloud-powered business analytics service </li> <li>Allows all employees in an organization to: <ul> <li>Build visualizations o Perform ad-hoc analysis </li> <li>Quickly get business insights from data </li> <li>Anytime, on any device (browsers, mobile) </li> </ul> </li> <li>Serverless </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-2-quicksight-data-sources","title":"1-2 QuickSight Data Sources","text":"<ul> <li>Redshift </li> <li>Aurora / RDS </li> <li>Athena </li> <li>EC2-hosted databases (communicate through JDBC or ODBC) </li> <li>Files (S3 or on-premises) <ul> <li>Excel</li> <li>CSV, TSV </li> <li>Common or extended log format</li> </ul> </li> </ul> <p>Limited ETL Example</p> <ul> <li>Change column names for CSV file during the data preparation stage. </li> <li>Add calculated files issuing SQL queries to transform your data </li> <li>Change the data types that were imported before visualize it.  </li> </ul> <p>QuickSight is that it's not just sitting on top of data and analyzing it through some JDBC interface. It's actually importing your data sets into an engine that it calls </p>"},{"location":"chap6/30Vis_Qs/#1-3-spice-superfast-parallel-in-memory-calculation-engine","title":"1-3 SPICE (Superfast parallel in memory calculation engine)","text":"<ul> <li> <p>Data sets are imported into SPICE </p> <ul> <li>Super-fast, Parallel, In-memory Calculation Engine </li> <li>Uses columar storage, in-memory, machine code generation </li> <li>Accelerates interactive queries on large datasets </li> </ul> </li> <li> <p>Each user gets 10GB of SPICE </p> </li> <li>Highly available / durable</li> <li>Scales to hundreds of thousands of users </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-4-quicksight-use-cases","title":"1-4 QuickSight Use Cases","text":"<ul> <li>Interactive ad-hoc exploration Rtaa gallon of data </li> <li>Dashboards and KPI's </li> <li> <p>Stories </p> <ul> <li>Guided tours through specific vierws of an analysis</li> <li>Convey  key poinys, thought process, evolution of any analysis</li> </ul> </li> <li> <p>Analyze / visualize data from: </p> <ul> <li>Logs in S3 </li> <li>On-premise databases </li> <li>AWS (RDS, Redshift, Athena, S3) </li> <li>SaaS applications, such as Salesforce </li> <li>Any JDBC/ODBC </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-5-quicksight-anti-patterns","title":"1-5 QuickSight Anti-Patterns","text":"<ul> <li>Highly formatted canned reportsries, analysis, and visualization <ul> <li>QuickSight is for ad hoc que  </li> </ul> </li> <li>ETL <ul> <li>Use Glue instead, although QuickSight can do some transformations</li> <li>Apache Spark. </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-6-quicksight-security","title":"1-6 QuickSight Security","text":"<ul> <li>Multi-factor authentication(MFA) on your account </li> <li>VPC connectivity <ul> <li>Add Quic Sight's IP address ranee to your database securit groups \u2022</li> <li>Row-level security(RLS) </li> </ul> </li> <li>Private VPC access <ul> <li>Elastic Network Interface(ENI)AWS Enterprise Edition</li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-7-row-level-securityrls","title":"1-7 Row-level security(RLS)","text":"<ul> <li>QuickSight data set owners to control access to data at row granularity based on permissions associated with the user interacting with the data </li> <li>RLS or role level security QuickSight users only need to manage a single set of data and apply appropriate row level data set rules to it. </li> </ul>"},{"location":"chap6/30Vis_Qs/#1-8-quicksight-user-management","title":"1-8 QuickSight User Management","text":"<ul> <li>Users defined via IAM or email signup </li> <li>Active Directory integration with QuickSight Enterprise Edition </li> </ul>"},{"location":"chap6/30Vis_Qs/#2quicksight-pricing-and-dashboards-ml-insights","title":"2\u3001Quicksight Pricing and Dashboards; ML Insights","text":""},{"location":"chap6/30Vis_Qs/#2-1-quicksight-pricing","title":"2-1 QuickSight Pricing","text":"<ul> <li> <p>Annual subscription </p> <ul> <li>Standard: <code>$9 / user /month</code></li> <li>Enterprise: <code>$18 / user / month</code></li> </ul> </li> <li> <p>Extra SPICE capacity (beyond 10GB) </p> <ul> <li><code>$0.25 (standard) $0.38 (enterprise) / GB / month</code></li> </ul> </li> <li> <p>Month to month </p> <ul> <li>Standard: <code>$12 / GB / month</code> </li> <li>Enterprise: <code>$24 / GB / month</code> </li> </ul> </li> <li> <p>Enterprise edition </p> <ul> <li>Encryption at rest </li> <li>Microsoft Active Directory integration </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#2-2-quicksight-dashboard","title":"2-2 QuickSight Dashboard","text":""},{"location":"chap6/30Vis_Qs/#2-3-quicksight-machine-learning-insights","title":"2-3 Quicksight Machine Learning Insights","text":"<ul> <li> <p>ML-powered anomaly detection </p> <ul> <li>Uses Random Cut Forest </li> <li>Identify top contributors to significant changes in metrics automatcally</li> <li>Automatically find ourliers in dataset and identify what those are </li> </ul> </li> <li> <p>ML-powered forecasting </p> <ul> <li>Also uses Random Cut Forest</li> <li>Detects seasonality and trends </li> <li>Excludes outlier and imputes missing values</li> <li>Using machine learning it can take an incomplete or a messy data set and still forecast that while still preserving seasonal trends </li> </ul> </li> <li> <p>Autonarratives </p> <ul> <li>Adds \"story of your data\" to your dashboards </li> <li>Translate your data into plain English</li> </ul> </li> </ul> <p></p> <p></p> <ul> <li>Suggested Insights <ul> <li>\"Insights\" tab displays read-to-use suggested insights</li> <li>Tell you which of these machine learning features might be relevant to your dataset </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#3choosing-visualization-types","title":"3\u3001Choosing Visualization Types","text":""},{"location":"chap6/30Vis_Qs/#3-1-quicksight-visual-types","title":"3-1 QuickSight Visual Types","text":"<ul> <li>AutoGraph </li> <li> <p>Bar Charts </p> <ul> <li>For comparison and distribution (histograms) </li> <li>histograms </li> </ul> </li> <li> <p>Line graphs </p> <ul> <li>For changes over time </li> </ul> </li> <li> <p>Scatter plots, heat maps</p> <ul> <li>For correlation </li> </ul> </li> <li> <p>Pie graphs, tree maps </p> <ul> <li>For aggregation</li> </ul> </li> <li> <p>Pivot tables </p> <ul> <li>For tabular data </li> </ul> </li> <li> <p>Stories </p> <ul> <li>Stories create a narrative basically by presenting iterations of analysis </li> <li>Construct Stories by capturing and annotating specific states of your analysis. </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#3-2-additional-visual-types","title":"3-2 Additional Visual Types","text":"<ul> <li>KPIs (key performance indicators) </li> <li>Geospatial Charts (maps) </li> <li>Donut Charts </li> <li>Gauge Charts </li> <li>Word Clouds <ul> <li>Sum of Pop by State and State </li> </ul> </li> </ul>"},{"location":"chap6/30Vis_Qs/#3-3-bar-charts-comparison-and-distribution","title":"3-3 Bar Charts comparison and distribution","text":"<p>The idea of a histogram is that you bucket up your data into certain ranges. </p>"},{"location":"chap6/30Vis_Qs/#3-4-line-graphs-for-changes-over-time","title":"3-4 Line graphs: For changes over time","text":"<p>Trends over time </p> <p></p> <p>Area Charts </p> <p>Two dimensions of data there u cal yo can actually visualize that using colors underneath the line of your line chart as well that's led an area chart. </p>"},{"location":"chap6/30Vis_Qs/#3-5-scatter-plots-correlation","title":"3-5 Scatter plots: correlation","text":""},{"location":"chap6/30Vis_Qs/#3-6-heat-maps-correlation","title":"3-6 heat maps: correlation","text":"<p>The difference between Scatter plots and heat maps is that each cell is colored based on the value of the data in that cell. </p> <p></p>"},{"location":"chap6/30Vis_Qs/#3-7-pie-graphs-aggregation","title":"3-7 Pie graphs: aggregation","text":"<p>what different categories </p> <p></p>"},{"location":"chap6/30Vis_Qs/#3-8-additional-visual-types","title":"3-8 Additional Visual Types","text":"<ul> <li>KPIs </li> <li>Geospatial Charts (maps) </li> <li>Donut Charts </li> <li>Gauge Charts </li> <li>Word Clouds </li> </ul>"},{"location":"chap6/30Vis_Qs/#3-9-donut-charts-percentage-of-total-mount","title":"3-9 Donut Charts: Percentage of Total mount","text":"<p>Represent the percentage of a given thing to sum total amount. Similar to pie charts. </p>"},{"location":"chap6/30Vis_Qs/#3-10-gauge-charts-compare-values-in-a-measure","title":"3-10 Gauge Charts: Compare values in a measure","text":"<p>It displays how much there is of the thing you are measuring. </p> <p></p> <ul> <li>Fuel in a tank </li> <li>Bandwidth usage out of available bandwidth </li> </ul>"},{"location":"chap6/30Vis_Qs/#3-11-tree-maps-heirarchical-aggregation","title":"3-11 Tree Maps: Heirarchical Aggregation","text":"<ul> <li>Allows you to visualize data in a hierarchical way whereas you have this sort of top level view of different categories </li> <li>Different rectangles within that view reflecting how that is broken down further within subcategories within that category. </li> </ul> <p>This tree map we have these sort of colored blocks that correspond to broader </p> <p>categories of exports for this country and within each color </p>"},{"location":"chap6/30Vis_Qs/#3-12-pivot-tables-for-tabular-data","title":"3-12 Pivot tables For tabular data","text":""},{"location":"chap6/30Vis_Qs/#3-13-kpis-visualize-some-key-value-compared-to-its-target-value","title":"3-13 KPIs: Visualize some key value compared to its target value","text":""},{"location":"chap6/30Vis_Qs/#3-14-geospatial-charts-map","title":"3-14 Geospatial Charts (map)","text":""},{"location":"chap6/30Vis_Qs/#3-15-word-clouds-wordor-phase-frequency","title":"3-15 Word Clouds: wordor phase frequency","text":""},{"location":"chap6/30Vis_Qs/#4other-visualization-tools-highcharts-d3etc","title":"4\u3001Other Visualization Tools (HighCharts, D3,etc)","text":""},{"location":"chap6/30Vis_Qs/#4-1-alternative-visualization-tools","title":"4-1 Alternative Visualization Tools","text":"<ul> <li> <p>Web-based visualizations tools (deployed to the public and javascript libraries) </p> <ul> <li>D3.js </li> <li>Chart.js </li> <li>Highchartjs </li> </ul> </li> <li> <p>Business Intelligence Tools(integrate with any JDBC or ODBC database on the back end) </p> </li> <li> <p>Tableau </p> </li> <li>MicroStrategy </li> <li>Top of redshift alternative to QuickSight </li> </ul>"},{"location":"chap6/30Vis_Qs/#4-2-d3js","title":"4-2 D3.js","text":"<p>D3 stands for data driven documents <code>D3.js</code> is a javascript library which is used for manipulating documents based on data. Its a dynamic interactive and online data visualization framework. </p>"},{"location":"chap6/30Vis_Qs/#4-3-chartjs","title":"4-3 Chart.js","text":"<p>Community maintained open source library which helps easily visualize data using JavaScript. </p>"},{"location":"chap6/30Vis_Qs/#4-4-highchartjs","title":"4-4 Highchart.js","text":"<p>It is interactive and provides interactive charting capabilities to your web applications including line charts, spline charts, area charts, bar charts, pie charts </p> <ul> <li>Javascript libraries intended to be deployed to the public. </li> <li>QuickSight intended to be deployed to users of your organization or people within your organization. </li> </ul>"},{"location":"chap6/31Vis_Exer/","title":"L2 Amazon Quicksight Exercise","text":""},{"location":"chap6/31Vis_Exer/#1requirment-6-data-warehousing-visualization","title":"1\u3001Requirment 6: Data warehousing &amp; visualization","text":""},{"location":"chap6/31Vis_Exer/#2create-quicksight","title":"2\u3001Create Quicksight","text":""},{"location":"chap6/31Vis_Exer/#3add-datasets","title":"3\u3001Add datasets","text":""},{"location":"chap6/31Vis_Exer/#4spice-import","title":"4\u3001SPICE import","text":""},{"location":"chap7/32Secu_Encryption/","title":"L1 Security - Encryption","text":""},{"location":"chap7/32Secu_Encryption/#1aws-security-encryption","title":"1\u3001AWS Security &amp; Encryption","text":"<p>KMS, Encryption SDK, SSM Parameter Stogy </p>"},{"location":"chap7/32Secu_Encryption/#1-1-why-encryption-encryption-in-flight-ssl","title":"1-1 Why encryption? Encryption in flight (SSL)","text":"<ul> <li>Data is encrypted before sending and decrypted after receiving </li> <li>SSL certificates help with encryption (HTTPS) </li> <li>Encryption in flight ensures no MITM (man in the middle attack) can happen </li> </ul>"},{"location":"chap7/32Secu_Encryption/#1-2-why-encryption-server-side-encryption-at-rest","title":"1-2 Why encryption? Server side encryption at rest","text":"<ul> <li>Server side manages encryption and the decryption</li> <li>Data is encrypted after being received by the server </li> <li>Data is decrypted before being sent </li> <li>It is stored in an encrypted form thanks to a key (usually a data key)</li> <li>The encryption / decryption keys and object must be managed somewhere and the server must have access to it </li> </ul> <ul> <li>The encryption and the encryption keys must be managed somewhere usually called a KMS(Key Management Service)</li> <li>The server must have the right to talk to that KMS.</li> </ul>"},{"location":"chap7/32Secu_Encryption/#1-3-why-encryption-client-side-encryption","title":"1-3 Why encryption? Client side encryption","text":"<ul> <li>Data is encrypted by the client and never decrypted by the server</li> <li>Data will be decrypted by a receiving client </li> <li>The server should not be able to decrypt the data </li> <li>Could leverage Envelope Encryption </li> </ul> <p>Not using any KMS</p>"},{"location":"chap7/32Secu_Encryption/#2s3-encryption-reminder","title":"2\u3001S3 Encryption (Reminder)","text":""},{"location":"chap7/32Secu_Encryption/#2-1-s3-encryption-for-objects","title":"2-1 S3 Encryption for Objects","text":"<ul> <li>There are 4 methods of encrypting objects in S3 </li> <li><code>SSE-S3</code>: Encrypts S3 objects using keys handled &amp; managed by AWS </li> <li><code>SSE-KMS</code>: Leverage AWS Key Management Service to manage encryption keys </li> <li><code>SSE-C</code>: When you want to manage your own encryption keys </li> <li>Client Side Encryption </li> </ul> <p>It's important to understand which ones are adapted to which situation for the exam</p>"},{"location":"chap7/32Secu_Encryption/#2-2-sse-s3","title":"2-2 SSE-S3","text":"<ul> <li>SSE-S3: encryption using keys handled &amp; managed by AWS S3</li> <li>Object is encrypted server side </li> <li>AES-256 encryption type </li> <li>Must set header: <code>\"x-amz-server-side-encryption\": \"AES256\"</code> when you send your data to Amazon</li> </ul>"},{"location":"chap7/32Secu_Encryption/#2-3-sse-kms","title":"2-3 SSE-KMS","text":"<ul> <li>SSE-KMS: encryption using keys handled &amp; managed by KMS </li> <li>KMS Advantages: user control + audit trail </li> <li>Object is encrypted server side</li> <li>Must set header: <code>\"x-amz-servereside-encryption\":\"aws:kms\"</code></li> </ul> <p>The difference between SSE-S3 and SSE-KMS is that the key that is used is a KMS customer master key(CMK) that you can manage over time while SSE-S3 using keys handled &amp; managed by AWS S3</p>"},{"location":"chap7/32Secu_Encryption/#2-4-sse-c","title":"2-4 SSE-C","text":"<ul> <li>SSE-C: server-side encryption using data keys fully managed by the customer outside of AWS </li> <li>Amazon S3 does not store the encryption key you provide </li> <li>HTTPS must be used </li> <li>Encryption key must provided in HTTP headers, for every HTTP request made </li> </ul>"},{"location":"chap7/32Secu_Encryption/#2-5-client-side-encryption","title":"2-5 Client Side Encryption","text":"<ul> <li>Client library such as the Amazon S3 Encryption Client </li> <li>Clients must encrypt data themselves before sending to S3 </li> <li>Clients must decrypt data themselves when retrieving from S3 </li> <li>Customer fully manages the keys and encryption cycle </li> </ul>"},{"location":"chap7/32Secu_Encryption/#2-6-encryption-in-transit-ssl","title":"2-6 Encryption in transit (SSL)","text":"<ul> <li> <p>AWS S3 exposes: </p> <ul> <li>HTTP endpoint: non encrypted </li> <li>HTTPS endpoint: encryption in flight</li> </ul> </li> <li> <p>You're free to use the endpoint you want, but HTTPS is recommended </p> </li> <li>HTTPS is mandatory for SSE-C</li> <li>Encryption in flight is also called SSL /TLS </li> </ul>"},{"location":"chap7/32Secu_Encryption/#2-7-s3-encryption-example","title":"2-7 S3 encryption Example","text":""},{"location":"chap7/32Secu_Encryption/#3kms-overview","title":"3\u3001KMS Overview","text":""},{"location":"chap7/32Secu_Encryption/#3-1-aws-kms-key-management-service","title":"3-1 AWS KMS (Key Management Service)","text":"<ul> <li>Anytime you hear   \"encryption\" for an AWS service, it's most likely KMS </li> <li>Easy way to control access to your data, AWS manages keys for us </li> <li>Fully integrated with IAM for authorization <ul> <li>Seamlessly integrated into: <ul> <li>Amazon EBS: encrypt volumes </li> <li>Amazon S3: Server side encryption of objects </li> <li>Amazon Redshift: encryption of data </li> <li>Amazon RDS: encryption of data </li> <li>Amazon SSM: Parameter store </li> <li>Etc... </li> </ul> </li> </ul> </li> <li>But you can also use the CLI / SDK </li> </ul>"},{"location":"chap7/32Secu_Encryption/#3-2-aws-kms-101","title":"3-2 AWS KMS 101","text":"<ul> <li>Anytime you need to share sensitive information... use KMS <ul> <li>Database passwords </li> <li>Credentials to external service </li> <li>Private Key of SSL certificates </li> </ul> </li> <li>The value in KMS is that the CMK used to encrypt data can never be retrieved by the user, and the CMK can be rotated for extra security</li> <li>Never ever store your secrets in plaintext, especially in your code! </li> <li>Encrypted secrets can be stored in the code / environment variables </li> <li>KMS can only help in encrypting up to 4KB of data per call </li> <li>If <code>data &gt; 4 KB</code>, use envelope encryption</li> <li>To give access to KMS to someone: <ul> <li>Make sure the Key Policy allows the user </li> <li>Make sure the IAM Policy allows the API calls </li> </ul> </li> </ul> <p>Envelope Encryption:</p> <p>Basically will generate a new data key and that that key will be used to encrypt the big data sets.</p>"},{"location":"chap7/32Secu_Encryption/#3-3-aws-kms-key-management-service","title":"3-3 AWS KMS (Key Management Service)","text":"<ul> <li>Able to fully manage the keys &amp; policies: <ul> <li>Create </li> <li>Rotation policies </li> <li>Disable </li> <li>Enable </li> </ul> </li> <li>Able to audit key usage (using CloudTrail) </li> <li>Three types of Customer Master Keys (CMK):<ul> <li>AWS Managed Service Default CMK: free </li> <li>User Keys created in KMS: <code>$1 / month</code> </li> <li>User Keys imported (must be 256-bit symmetric key): <code>$1 / month</code> </li> </ul> </li> <li><code>+</code> pay for API call to KMS (<code>$0.03 / 10000 calls</code>) </li> </ul>"},{"location":"chap7/32Secu_Encryption/#3-4-how-does-kms-work-api-encrypt-and-decrypt","title":"3-4 How does KMS work? API - <code>Encrypt</code> and <code>Decrypt</code>","text":"<ol> <li>Encrypted API that within the KMS service check the CMK </li> <li>IAM permission check: User allowed to do this CMK encrypt call within IAM.</li> <li>Encryption happens by CMK and then KMS will send back the encrypted secrets. (never seen the CMK)</li> <li>use the CLI or the SDK again issue a decrypt API call and using the same CMK it again</li> <li>KMS will check the information for decrypt access and key policy.</li> <li>Decryption happen and send back the decrypted secrets in plaintext.</li> </ol>"},{"location":"chap7/32Secu_Encryption/#3-5-encryption-in-aws-services","title":"3-5 Encryption in AWS Services","text":"<ul> <li> <p>Requires migration (through Snapshot / Backup): </p> <ul> <li>EBS Volumes </li> <li>RDS databases </li> <li>ElastiCache </li> <li>EFS network file system </li> </ul> </li> <li> <p>In-place encryption(Only One): </p> <ul> <li>S3 </li> </ul> </li> </ul>"},{"location":"chap7/32Secu_Encryption/#3-6-cloud-hsm-hardware-security-module","title":"3-6 Cloud HSM (Hardware Security Module)","text":"<ul> <li>KMS =&gt; AWS manages the software for encryption </li> <li>CloudHSM =&gt; AWS provisions encryption hardware </li> <li>Dedicated Hardware (HSM = Hardware Security Module) </li> <li>You manage your own encryption keys entirely (not AWS) </li> <li>The CloudHSM hardware device is tamper resistant </li> <li>FIPS 140-2 Level 3 compliance </li> <li>CloudHSM clusters are spread across multi AZ (HA) </li> <li>Supports both symmetric and asymmetric encryption (SSL/TLS keys) </li> <li>No free tier available </li> <li>Must use the CloudHSM Client Software <ul> <li>Not as easy as the KMS API call with the CLI. </li> </ul> </li> </ul>"},{"location":"chap7/32Secu_Encryption/#3-7-cloudhsm-diagram","title":"3-7 CloudHSM Diagram","text":"<p>Exam</p> <ul> <li>Dedicated encryption hardware</li> <li>Control over the user keys but still be in AWS's cloud</li> <li>Have asymmetric type of encryption</li> </ul>"},{"location":"chap7/32Secu_Encryption/#3-8-cloudhsm-vs-kms","title":"3-8 CloudHSM VS KMS","text":""},{"location":"chap7/32Secu_Encryption/#4kms-key-rotation","title":"4\u3001KMS Key Rotation","text":""},{"location":"chap7/32Secu_Encryption/#4-1-kms-automatic-key-rotation","title":"4-1 KMS Automatic Key Rotation","text":"<ul> <li>For Customer-managed CMK (not AWS managed CMK) </li> <li>If enabled: automatic key rotation happens every 1 year </li> <li>Previous key is kept active so you can decrypt old data </li> <li>New Key has the same CMK ID(only the backing is changed) </li> </ul>"},{"location":"chap7/32Secu_Encryption/#4-2-kms-manual-key-rotation","title":"4-2 KMS Manual Key Rotation","text":"<ul> <li>When you want to rotate key every 90 days, 180 days, etc... </li> <li>New Key has a dilTerent, CMK ID </li> <li>Keep the previous key active so you can decrypt old data </li> <li>Better to use aliases in this case (to hide the change of key for the application) </li> <li>Good solution to rotate CMK that are not eligible for automatic rotation (like asymmetric CMK) </li> </ul>"},{"location":"chap7/32Secu_Encryption/#4-3-kms-alias-updating","title":"4-3 KMS Alias Updating","text":"<p>Better to use aliases in this case (to hide the change of key for application) </p> <p></p>"},{"location":"chap7/33Secu_bg_svc/","title":"L2 AWS Services Security Deep Dive","text":""},{"location":"chap7/33Secu_bg_svc/#1security-kinesis","title":"1\u3001Security Kinesis","text":""},{"location":"chap7/33Secu_bg_svc/#1-1-kinesis-data-streams","title":"1-1 Kinesis Data Streams","text":"<ul> <li>SSL endpoints using the HTTPS protocol to do encryption in flight </li> <li>AWS KMS provides server-side encryption [Encryption at rest] </li> <li>For client side-encryption, you must use your own encryption libraries <ul> <li>No support from AWS</li> <li>Use the KPL the producer library and own encryption libraries</li> </ul> </li> <li>Supported Interface VPC Endpoints / Private Link \u2014 access privately</li> <li>KCL \u2014 must get read / write access to DynamoDB table </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#1-2-kinesis-data-firehose","title":"1-2 Kinesis Data Firehose:","text":"<ul> <li>Attach IAM roles so it can deliver to S3 / ES / Redshift / Splunk </li> <li>Can encrypt the delivery stream with KMS [Server side encryption] </li> <li>Supported Interface VPC Endpoints / Private Link access privately </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#1-3-kinesis-data-analyics","title":"1-3 Kinesis Data Analyics","text":"<ul> <li>Attach IAM role so it can read from Kinesis Data Streams and reference sources and write to an output destination (example Kinesis Data Firehose) </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#2security-sqs","title":"2\u3001Security - SQS","text":"<ul> <li>Encryption in flight using the HTTPS endpoint </li> <li>Server Side Encryption using KMS </li> <li>IAM policy must allow usage of SQS</li> <li> <p>SQS queue access policy</p> </li> <li> <p>Client-side encryption must be implemented manually </p> </li> <li>VPC Endpoint is provided through an Interface </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#3security-aws-iot","title":"3\u3001Security \u2014AWS ioT","text":""},{"location":"chap7/33Secu_bg_svc/#3-1-aws-iot-policies","title":"3-1 AWS ioT policies:","text":"<ul> <li>Attached to X.509 certificates or Cognito Identities </li> <li>Able to revoke any device at any time  </li> <li>IoT Policies are JSON documents like IAM policy </li> <li>Can be attached to groups instead of individual Things. </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#3-2-iam-policies","title":"3-2 IAM Policies:","text":"<ul> <li>Attached to users, group or roles </li> <li>Used for controlling IoT AWS APIs </li> </ul> <p>Attach roles to Rules Engine so they can perform their actions </p>"},{"location":"chap7/33Secu_bg_svc/#4security-amazon-s3","title":"4\u3001Security \u2014Amazon S3","text":"<ul> <li>IAM policies </li> <li>S3 bucket policies </li> <li>Access Control Lists (ACLs) </li> <li>Encryption in flight using HTTPS </li> <li>Encryption at rest <ul> <li>Server-side encryption: SSE-S3, SSE-KMS, SSE-C </li> <li>Client-side encryption \u2014 such as Amazon S3 Encryption Client </li> </ul> </li> <li>Versioning + MFA Delete </li> <li>CORS for protecting websites<ul> <li>Only a few websites get access to S3 Buckets </li> </ul> </li> <li>VPC Endpoint is provided through a Gateway </li> <li>Glacier vault lock policies to prevent deletes (WORM) <ul> <li>Write once read many</li> </ul> </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#5security-dynamodb","title":"5\u3001Security DynamoDB","text":"<ul> <li>Data is encrypted in transit using TLS (HTTPS) </li> <li>DynamoDB can be encrypted at rest <ul> <li>KMS encryption for base tables and secondary indexes</li> <li>Only for new tables </li> <li>To migrate un-encrypted table, create new table and copy the data </li> <li>Encryption cannot be disabled once enabled </li> </ul> </li> <li>Access to tables / API / DAX using IAM </li> <li>DynamoDB Streams do not support encryption </li> <li>VPC Endpoint is provided through a Gateway </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#6security-rds","title":"6\u3001Security RDS","text":"<ul> <li>VPC provides network isolation </li> <li>Security Groups control network access to DB Instances </li> <li>KMS provides encryption at rest </li> <li>SSL provides encryption in-flight </li> <li>IAM policies provide protection for the RDS API </li> <li>IAM authentication is supported by PostgreSQL and MySQL </li> <li>Must manage user permissions within the database itself unlike  DynamoDB</li> <li>MSSQL Server and Oracle support TDE (Transparent Data Encryption)<ul> <li>Enabled on top of KMS and to provide more encryption  </li> </ul> </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#7security-aurora","title":"7\u3001Security Aurora","text":"<ul> <li>(very similar to RDS)</li> <li>VPC provides network isolation </li> <li>Security Groups control network access to DB Instances </li> <li>KMS provides encryption at rest </li> <li>SSL provides encryption in-flight </li> <li>IAM authentication is supported by PostgreSQL and MySQL</li> <li>Must manage user permissions within the database itself </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#8security-lambda","title":"8\u3001Security Lambda","text":"<ul> <li>IAM roles attached to each Lambda function </li> <li>Sources </li> <li>Targets </li> <li>KMS encryption for secrets </li> <li>SSM parameter store for configurations </li> <li>CloudWatch Logs </li> <li>Deploy in VPC to access private resources </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#9security-glue","title":"9\u3001Security Glue","text":"<ul> <li>IAM policies for the Glue service</li> <li>Configure Glue to only access JDBC through SSL</li> <li>Data Catalog: Encrypted by KMS </li> <li>Connection passwords: Encrypted by KMS </li> <li>Data written by AWS Glue \u2014 Security Configurations: <ul> <li>S3 encryption mode: SSE-S3 or SSE-KMS </li> <li>CloudWatch encryption mode</li> <li>job bookmark encryption mode </li> </ul> </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#10security-emr","title":"10\u3001Security - EMR","text":"<ul> <li>Using Amazon EC2 key pair for SSH credentials </li> <li>Attach IAM roles to EC2 instances for: <ul> <li>proper S3 access </li> <li>for EMRFS requests to S3 </li> <li>DynamoDB scans through Hive </li> </ul> </li> <li>EC2 Security Groups <ul> <li>One for master node </li> <li>Another one for cluster node (core node or task node) </li> </ul> </li> <li>Encrypts data at-rest for a Spark or a MapReduce job: <ul> <li>EBS encryption, </li> <li>Open Source HDFS Encryption, </li> <li>LUKS + EMRFS for S3 </li> </ul> </li> <li>In-transit encryption(using SSL certificates): node to node communication, EMRFS,TLS </li> <li>Data is encrypted before uploading to S3<ul> <li>EMR does not allow you to store unencrypted data into S3 </li> </ul> </li> <li>Kerberos authentication (provide authentication from Active Directory) </li> <li>Apache Ranger: Centralized Authorization (RBAC \u2014 Role Based Access) setup on external EC2 </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#11security-elasticsearch-service","title":"11\u3001Security \u2014 ElasticSearch Service","text":"<ul> <li>Amazon VPC provides network isolation </li> <li>ElasticSearch policy to manage security further </li> <li>Data security by encrypting data at-rest using KMS</li> <li> <p>Encryption in-transit using SSL </p> </li> <li> <p>IAM or Cognito based authentication </p> </li> <li>Amazon Cognito allow end-users to log-in to Kibana through enterprise identity providers such as Microsoft Active Directory using SAML </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#12security-redshift","title":"12\u3001Security Redshift","text":"<ul> <li>VPC provides network isolation </li> <li>Cluster security groups</li> <li>Encryption in flight using the JDBC driver enabled with SSL </li> <li>Encryption at rest using KMS or an HSM device (establish a connection with custom HSM device or hardware security module.)</li> <li>Supports S3 SSE using default managed key </li> <li>Use IAM Roles for Redshift </li> <li>To access other AWS Resources (example S3 or KMS) </li> <li>Must be referenced in the <code>COPY</code> or <code>UNLOAD</code> command (alternatively paste access key and secret key creds) </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#13security-athena","title":"13\u3001Security - Athena","text":"<ul> <li>IAM policies to control access to the service </li> <li>Data is in S3: IAM policies, bucket policies &amp; ACLs </li> <li>Encryption of data according to S3 standards: SSE-S3, SSE-KMS, CSE-KMS </li> <li>Encryption in transit using TLS between Athena and S3 and JDBC enabled by SSL</li> <li>Fine grained access using the AWS Glue Catalog </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#14security-quicksight","title":"14\u3001Security - Quicksight","text":""},{"location":"chap7/33Secu_bg_svc/#14-1-standard-edition","title":"14-1 Standard edition:","text":"<ul> <li>IAM users </li> <li>Email based accounts </li> </ul>"},{"location":"chap7/33Secu_bg_svc/#14-2-enterprise-edition","title":"14-2 Enterprise edition:","text":"<ul> <li>Active Directory </li> <li>Federated Login </li> <li>Supports MFA (Multi Factor Authentication) </li> <li>Encryption at rest and in SPICE </li> </ul> <p>Row Level Security to control which users can see which rows </p>"},{"location":"chap7/34Secu_account_fedration/","title":"L3 Account and Identity Federation","text":""},{"location":"chap7/34Secu_account_fedration/#1sts-and-cross-account-access","title":"1\u3001STS and Cross Account Access","text":""},{"location":"chap7/34Secu_account_fedration/#1-1-aws-stssecurity-token-service","title":"1-1 AWS STS(Security Token Service)","text":"<ul> <li>Allows to grant limited and temporary access to AWS resources </li> <li>Token is valid for up to one hour (must be refreshed) </li> <li>Cross Account Access <ul> <li>Allows users from one AWS account access resources in another </li> </ul> </li> <li>Federation (Active Directory) <ul> <li>Provides a non-AWS user with temporary AWS access by linking users Active Directory credentials </li> <li>Uses SAML (Security Assertion markup language) </li> <li>Allows Single Sign On (SSO) which enables users to log in to AWS console without assigning IAM credentials </li> </ul> </li> <li>Federation with third party providers / Cognito <ul> <li>Used mainly in web and mobile applications </li> <li>Makes use of Facebook/Google/Amazon etc to federate them </li> </ul> </li> </ul>"},{"location":"chap7/34Secu_account_fedration/#1-2-cross-account-access","title":"1-2 Cross Account Access","text":"<ul> <li>Define an IAM Role for another account to access </li> <li>Define which accounts can access this IAM Role </li> <li>Use AWS STS (Security Token Service) to retrieve credentials and impersonate the IAM Role you have access to (AssumeRole API) </li> <li>Temporary credentials can be valid between 15 minutes to 1 hour </li> </ul> <p>As a user access a role either in the same account or in another account.</p> <p></p> <ol> <li>Assume role API on STS.</li> <li>Check the IAM permissions </li> <li>Send back temporary security credentials</li> <li>These security credentials will basically allow to impersonate that role that you wanted to assume.</li> </ol>"},{"location":"chap7/34Secu_account_fedration/#2identity-federation","title":"2\u3001Identity Federation","text":""},{"location":"chap7/34Secu_account_fedration/#2-1-whats-identity-federation","title":"2-1 What's Identity Federation?","text":"<ul> <li>Federation lets users outside of AWS to assume temporary role for accessing AWS resources. </li> <li>These users assume identity provided access role. </li> <li>Federation assumes a form of 3rd party authentication <ul> <li>LDAP </li> <li>Microsoft Active Directory (~= SAML) </li> <li>Single Sign On </li> <li>Open ID </li> <li>Cognito </li> </ul> </li> <li>Using federation, you don't need to create IAM users (user management is outside of AWS) </li> </ul> <ol> <li>Company User or mobile app user without account in AWS</li> <li>Access to third party servers for login.</li> <li>The third party is trusted by AWS </li> <li>Third party  give back credentials with temporary to access AWS through the console or the API.</li> </ol>"},{"location":"chap7/34Secu_account_fedration/#2-2-saml-federation-for-enterprises","title":"2-2 SAML Federation For Enterprises","text":"<ul> <li>To integrate Active Directory / ADFS with AWS (or any SAML 2.0)</li> <li>Provides access to AWS Console or CLI (through temporary creds)</li> <li>No need to create an IAM user for each of your employees </li> </ul> <ol> <li>Client app within our organization make request to identity provider IDP which is SAML compliant(Microsoft active directory or user database)</li> <li>Authenticated to this IDP the IDP will send back a SAML assertion(SAML assertion is a token)</li> <li>Automatically call assume a role with SAML to STS which is special API on STS.</li> <li>STS recognizes this SAML assertion give us back temporary security credentials which  is traded from SAML assertion</li> <li>With the security credentials we can for example access AWS normally</li> </ol>"},{"location":"chap7/34Secu_account_fedration/#2-3-console-based-access","title":"2-3 Console based access","text":"<ol> <li>Access the portal of identity provider and get it authenticated.</li> <li>IDP will return a SAML assertion.</li> <li>Use that SAML assertion directly to sign it into the AWS SSL end points</li> <li>AWS SSL end points talks to STS.</li> <li>Get validated and SAML is traded for STS</li> <li>Get redirected to the AWS management console.</li> </ol>"},{"location":"chap7/34Secu_account_fedration/#2-4-custom-identity-broker-application-for-enterprises-dont-have-a-saml-20","title":"2-4 <code>Custom Identity Broker</code> Application For Enterprises  (Don't have a SAML 2.0)","text":"<ul> <li>Use only if identity provider is not compatible with SAML 2.0 </li> <li>The identity broker must determine the appropriate IAM policy </li> <li>Exact same principles as SAML but it's not SAML with more manual work </li> </ul> <ol> <li>Users browser or application will access our identity broker</li> <li>Identity broker is something that we have to program</li> <li>Identity broker will validate identity with maybe a corporate identity store authenticated </li> <li>Superuser can ask from STS any security credentials for any policy</li> <li>It's up to the identity broker to really test tailor a policy just for the user that was connected.</li> <li>It goes to STS makes a query request for separate for security credentials the security credentials come back they're given to our users</li> </ol>"},{"location":"chap7/34Secu_account_fedration/#2-5-aws-cognito-federated-identity-pools-for-public-applications","title":"2-5 AWS Cognito Federated Identity Pools For Public Applications","text":"<ul> <li> <p>Goal: </p> <ul> <li>Provide direct access to AWS Resources from the Client Side </li> </ul> </li> <li> <p>How: </p> <ul> <li>Log in to federated identity provider or remain anonymous </li> <li>Get temporary AWS credentials back from the Federated Identity Pool</li> <li>These credentials come with a pre-defined IAM policy stating their permissions </li> </ul> </li> <li> <p>Example: </p> <ul> <li>provide (temporary) access to write to S3 bucket using Facebook Login </li> </ul> </li> <li> <p>Note: </p> <ul> <li>Web Identity Federation is an alternative to using Cognito but AWS recommends against it</li> </ul> </li> </ul> <p>Example:</p> <p>Provide temporary access to write to S3 Buckets maybe using of a Facebook plugin</p> <p></p> <ol> <li>App is directly connected to our identity provider(User pool, Google, Facebook, Twitter, SAML, OpenID)</li> <li>App logs in to our identity provider and gets a token back</li> <li>App talk to the federated identity provider in Cognito trading that token.</li> <li>Verified by the identity provider and then the identity provider will get credentials from STS </li> <li>The identity the federated identity on Cognito will send us back a temporary AWS credentials.</li> <li>Using these credentials can directly talk to our S3 Buckets </li> </ol>"},{"location":"chap7/35Secu_others/","title":"L4 Polices, CloudTrail &amp; VPCe","text":""},{"location":"chap7/35Secu_others/#1policies-advanced","title":"1\u3001Policies - Advanced","text":""},{"location":"chap7/35Secu_others/#1-1-policies-leveraging-aws-variables","title":"1-1 Policies \u2014 leveraging AWS variables","text":"<p>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_variables.html</p> <ul> <li><code>${aws:usemame}</code> :to restrict users to tables / buckets  </li> <li><code>${aws:principattype}</code> : account user, federated, or assumed role </li> <li><code>${aws:PrincipalTag/department}</code> :to restrict using Tags </li> </ul> <p>https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_iam-condition-keys.html#condition-keys-wif</p> <ul> <li><code>${aws:FederatedProvider}</code> : which IdP was used for the user (Cognito, Amazon.) </li> <li><code>${www.amazon.com:user_id}</code> , <code>${cognito-identity.amazonaws.com:sub}</code> </li> <li><code>${saml:sub}</code>, <code>${sts:Externalld}</code> </li> </ul>"},{"location":"chap7/35Secu_others/#1-2-policies-advanced","title":"1-2 Policies - Advanced","text":"<p>For S3 - let's analyze the policies at</p> <p>https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html</p> <p>For DynamoDB \u2014 let's analyze the policies at: </p> <p>https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/specifying-conditions.html</p> <p>Note for RDS \u2014 IAM policies don't help with in-database security, as it's a proprietary technology and we are responsible for users &amp; authorization </p>"},{"location":"chap7/35Secu_others/#2cloudttrail","title":"2\u3001CloudtTrail","text":""},{"location":"chap7/35Secu_others/#2-1-aws-cloudtrail","title":"2-1 AWS CloudTrail","text":"<ul> <li>Provides governance, compliance and audit for your AWS Account \u2022</li> <li>CloudTrail is enabled by default! </li> <li> <p>Get an history of events / API calls made within your AWS Account by: </p> <ul> <li>Console </li> <li>SDK </li> <li>CLI </li> <li>AWS Services </li> </ul> </li> <li> <p>Can put logs from CloudTrail into CloudWatch Logs </p> </li> <li>If a resource is deleted in AWS, look into CloudTrail first! </li> <li>CloudTrail shows the past 90 days of activity</li> <li>The default UI only shows \"Create\",\"Modify\" or \"Delete\" events </li> <li> <p>CloudTrail Trail: </p> <ul> <li>Get a detailed list of all the events you choose </li> <li>Ability to store these events in S3 for further analysis </li> <li>Can be region specific or global </li> </ul> </li> <li> <p>CloudTrail Logs have SSE-S3 encryption when placed into S3 </p> </li> <li>Control access to S3 using IAM, Bucket Policy, etc... </li> </ul> <pre><code>data \"aws_caller_identity\" \"current\" {}\nresource \"aws_s3_bucket\" \"cloudtrail_bucket\" {\n  bucket = \"jam-${terraform.workspace}-cloudtrail-logs\"\n  region = var.region\n\n  lifecycle_rule {\n    enabled = true\n    id      = \"jam-awsorgcloudtrail-rule\"\n\n    tags = {\n      \"rule\"       = \"cloudtrail-rule\"\n      \"autoclean\"  = \"true\"\n      \"department\" = \"jam\"\n      \"team\"       = \"devops\"\n      \"purpose\"    = \"cloudtrail\"\n      \"env\"        = \"${terraform.workspace}\"\n    }\n\n    transition {\n      days          = 60\n      storage_class = \"STANDARD_IA\"\n    }\n\n    transition {\n      days          = 90\n      storage_class = \"GLACIER\"\n    }\n\n    expiration {\n      days = 180\n    }\n\n  }\n\n  tags = {\n    \"department\" = \"jam\"\n    \"team\"       = \"devops\"\n    \"purpose\"    = \"cloudtrail\"\n    \"env\"        = \"${terraform.workspace}\"\n  }\n\n  policy = &lt;&lt;POLICY\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSCloudTrailAclCheck20150319\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"Service\": \"cloudtrail.amazonaws.com\"},\n            \"Action\": \"s3:GetBucketAcl\",\n            \"Resource\": \"arn:aws:s3:::jam-${terraform.workspace}-cloudtrail-logs\"\n        },\n        {\n            \"Sid\": \"AWSCloudTrailWrite20150319\",\n            \"Effect\": \"Allow\",\n            \"Principal\": {\"Service\": \"cloudtrail.amazonaws.com\"},\n            \"Action\": \"s3:PutObject\",\n            \"Resource\": \"arn:aws:s3:::jam-${terraform.workspace}-cloudtrail-logs/AWSLogs/${data.aws_caller_identity.current.account_id}/*\",\n            \"Condition\": {\"StringEquals\": {\"s3:x-amz-acl\": \"bucket-owner-full-control\"}}\n        }\n    ]\n} \nPOLICY\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"cloudtrail_bucket\" {\n\n  bucket              = aws_s3_bucket.cloudtrail_bucket.id\n  block_public_acls   = true\n  block_public_policy = true\n\n}\n\nresource \"aws_cloudtrail\" \"jam_cloudtrail\" {\n  name                          = \"jam-${terraform.workspace}-cloudtrail\"\n  s3_bucket_name                = aws_s3_bucket.cloudtrail_bucket.id\n  include_global_service_events = true\n  is_multi_region_trail         = true\n  tags = {\n    \"department\" = \"jam\"\n    \"team\"       = \"devops\"\n    \"env\"        = \"${terraform.workspace}\"\n    \"owner\"      = \"jam-devops\"\n    \"region\"     = \"gloabl\"\n  }\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n    data_resource {\n      type   = \"AWS::S3::Object\"\n      values = [\"arn:aws:s3:::\"]\n    }\n  }\n}\n</code></pre>"},{"location":"chap7/35Secu_others/#3vpc-endpoints","title":"3\u3001VPC Endpoints","text":"<ul> <li>Endpoints allow you to connect to AWS Services using a private network instead of the public www network </li> <li>They scale horizontally and are redundant \u2022</li> <li>They remove the need of IGW, NAT, etc. to access AWS Services </li> <li> <p>Gateway provisions a target and must be used in a route table </p> <ul> <li>ONLY S3 and DynamoDB </li> </ul> </li> <li> <p>Interface: provisions an ENI (private IP a mss as an entry point must attach security group) \u2014 most AWS services Also called VPC PrivateLink </p> </li> </ul> <p></p> <p></p> <p></p>"},{"location":"chap8/36bg_integration/","title":"L1 AWS Bigdata Integration","text":""},{"location":"chap8/36bg_integration/#1iot","title":"1\u3001IoT","text":"<p>IoT rules actions have amount variety of destinations Kinesis, DynamoDB, SQS, SNS, S3, Lambda and so many others.</p>"},{"location":"chap8/36bg_integration/#2kinesis-data-stream","title":"2\u3001Kinesis Data Stream","text":""},{"location":"chap8/36bg_integration/#2-1-producer-side","title":"2-1 Producer side","text":"<ul> <li>SDK, Kinesis producer library, Kinesis agents</li> <li>Third party libraries<ul> <li>Apache Spark</li> <li>Apache Kafka</li> </ul> </li> </ul>"},{"location":"chap8/36bg_integration/#2-2-consumers","title":"2-2 Consumers","text":"<ul> <li>Kinesis consumer library</li> <li>SDK</li> <li>Firehose</li> <li>AWS lambda</li> <li>Kinesis connector library</li> <li>Apache Spark</li> </ul>"},{"location":"chap8/36bg_integration/#3kinesis-data-firehose","title":"3\u3001Kinesis Data Firehose","text":""},{"location":"chap8/36bg_integration/#3-1-source","title":"3-1 Source","text":"<ul> <li>SDK Kinesis producer library)</li> <li>Kinesis agent</li> <li>Kinesis Data Streams</li> <li>Cloudwatch logs and events</li> <li>IoT rules actions</li> </ul>"},{"location":"chap8/36bg_integration/#3-2-data-transformation","title":"3-2 Data transformation","text":"<p>AWS lambda functions do transformation on top of the data.</p>"},{"location":"chap8/36bg_integration/#3-3-destinations","title":"3-3 Destinations","text":"<ul> <li>Amazon S3</li> <li>Redshift</li> <li>Elasticsearch</li> <li>Splunk </li> </ul>"},{"location":"chap8/36bg_integration/#4kinesis-data-analytics","title":"4\u3001Kinesis Data Analytics","text":""},{"location":"chap8/36bg_integration/#4-1-data-sources","title":"4-1 Data sources","text":"<ul> <li>Real time Kinesis data streams </li> <li>Kinesis data firehose</li> <li>Reference data in JSON or CSV formats directly from S3.</li> </ul> <p>Pre-process the data with AWS lambda so transform the records before doing some analytics.</p>"},{"location":"chap8/36bg_integration/#4-1-result-of-the-continuous-running-analytic-queries-exp-sql-into","title":"4-1 Result of the continuous running analytic queries Exp. SQL into","text":"<ul> <li>Kinesis data streams</li> <li>Kinesis data firehose</li> <li>AWS lambda function<ul> <li>Exp. notification</li> </ul> </li> </ul>"},{"location":"chap8/36bg_integration/#5sqs","title":"5\u3001SQS","text":""},{"location":"chap8/36bg_integration/#5-1-sources","title":"5-1 sources","text":"<ul> <li>AWS SDK deploy onto a server or EC2, ECS</li> <li>Rules engine on IoT core</li> <li>S3 event, like new files to S3</li> </ul>"},{"location":"chap8/36bg_integration/#5-2-destinations","title":"5-2 Destinations","text":"<ul> <li>Application on the server such as EC2 or you can use AWS</li> <li>Lambda functions to directly process events from SQS.</li> </ul>"},{"location":"chap8/36bg_integration/#6s3","title":"6\u3001S3","text":""},{"location":"chap8/36bg_integration/#6-1-go-to-places-for-data","title":"6-1 Go to places for data","text":"<ul> <li>Snowball, snowball edge to transport data from your on premise environment</li> <li>Firehose deliver data into S3</li> <li>Redshift offload it data into S3</li> <li>Athena: queries from and writes data to S3</li> <li>Data pipeline:  Move data into S3</li> <li>IoT core is a direct rule that integrates with S3</li> <li>Database migration service: Source data from postgres and write it down to S3</li> <li>EMR will use S3 as its own backend if we use EMRFS</li> <li>Glue use S3 as a target</li> </ul>"},{"location":"chap8/36bg_integration/#6-2-s3-integrate-with","title":"6-2 S3 integrate with","text":"<ul> <li>to lambda function</li> <li>to an SQS queue</li> <li>to an SNS topic</li> </ul>"},{"location":"chap8/36bg_integration/#7dynamodb","title":"7\u3001DynamoDB","text":"<ul> <li>Client SDK to write data </li> <li>Database migration service(DMS) transfer data from MySQL into DynamoDB</li> <li>AWS data pipeline want to a batch running ETL</li> <li>DynamoDB streams: Chain of streams from DynamoDB <ul> <li>integrated directly with AWS Lambda functions.</li> <li>Kinesis client library with the DynamoDB adaptor </li> </ul> </li> <li>Glue:<ul> <li>Get all the tables metadata information directly into its data catalog</li> </ul> </li> <li>EMR can read from DynamoDB using hive <ul> <li>Hive can basically scan entire DynamoDB table before doing a query. </li> </ul> </li> </ul>"},{"location":"chap8/36bg_integration/#8glue","title":"8\u3001Glue","text":"<p>A metadata service collection as ETL</p> <p></p>"},{"location":"chap8/36bg_integration/#8-1-sources","title":"8-1 Sources","text":"<ul> <li>DynamoDB</li> <li>Amazon S3</li> <li>JDBC based.<ul> <li>RDS databases on premise database</li> <li>Database in the cloud</li> </ul> </li> </ul> <p>Glue crawlers to crawl these data sources retrieve the schema retrieve the table names all that stuff</p> <p>Glue data catalog can be used by different technologies to basically query data.</p> <ul> <li>Redshift spectrum to query data directly on S3</li> <li>Athena as well to create it on S3</li> <li>EMR plus hive know where it can store source data</li> </ul>"},{"location":"chap8/36bg_integration/#9emr","title":"9\u3001EMR","text":"<p>EMR is a lot of things, it's Hadoop, spark, hive, pig, presto, Apache HBase, Jupiter, Zeppelin, Flink.</p> <p></p> <ul> <li>Glue data catalog to know what to query</li> <li>Amazon S3 using EMRFS and maybe using the consistent view on S3.</li> <li>DynamoDB where hive can scan an entire DynamoDB table for its query.</li> <li>Apache ranger on EC2 for advanced model for controlling user access into our EMR cluster</li> </ul>"},{"location":"chap8/36bg_integration/#10amazon-machine-learning-ml-deprecated","title":"10\u3001Amazon Machine Learning (ML) (Deprecated)","text":""},{"location":"chap8/36bg_integration/#10-1-sources-data","title":"10-1 Sources data","text":"<ul> <li>Amazon S3 </li> <li>redshift</li> </ul>"},{"location":"chap8/36bg_integration/#exposes-the-output-model-as-a-prediction-and-explicit-prediction-api-so-we-can-basically-throw-some-data-at-amazon-ml","title":"Exposes the output model as a prediction and explicit prediction API so we can basically throw some data at Amazon ML","text":""},{"location":"chap8/36bg_integration/#11amazon-sagemaker","title":"11\u3001Amazon SageMaker","text":"<p>Newer shiny Amazon machine learning service </p> <p></p> <ul> <li>Source only from S3</li> <li>Tensorflow, pytorch, and mxnet or many other data machine learning framework for perform our data analysis or machine learning modelling.</li> </ul>"},{"location":"chap8/36bg_integration/#12aws-data-pipeline","title":"12\u3001AWS Data Pipeline","text":"<p>Moving data</p> <p></p> <ul> <li>Amazon S3</li> <li>JDBC for example RDS,</li> <li>EMR (hive)</li> <li>DynamoDB,</li> <li>basically or anything you want and can program</li> </ul>"},{"location":"chap8/36bg_integration/#13elasticsearch-service","title":"13\u3001ElasticSearch Service","text":"<ul> <li>Kinesis data firehose</li> <li>IoT core has a rule to send data</li> <li>CloudWatch logs</li> </ul> <p>Kibana</p> <ul> <li>IAM access integration </li> <li>Cognito integration</li> </ul>"},{"location":"chap8/36bg_integration/#14anthena","title":"14\u3001Anthena","text":"<ul> <li>Query data only in S3</li> <li>Get a metadata information from the glue data catalogue</li> <li>QuickSight can use Athena as a database engine</li> </ul>"},{"location":"chap8/36bg_integration/#15redshift","title":"15\u3001Redshift","text":"<ul> <li>Copy load or unload data from and to through S3</li> <li>Redshift spectrum to basically query the data in S3(Dont touch data from S3)</li> <li>QuickSight query data warehouse in redshift</li> <li>Integration with PostgreSQL to replicate some data called DBlink</li> </ul>"},{"location":"chap8/36bg_integration/#16quicksight","title":"16\u3001QuickSight","text":"<ul> <li>RDS or JDBC to connect to any database</li> <li>Redshift</li> <li>Amazon S3</li> <li>Salesforce, Teradata, Excel flat files, or JSON or CSV, Jira</li> </ul>"},{"location":"chap8/37bg_instances/","title":"L2 AWS Big Data Instances","text":""},{"location":"chap8/37bg_instances/#1instance-types-for-big-data-d-b-g-r","title":"1\u3001Instance Types for Big Data (D, B, G, R)","text":""},{"location":"chap8/37bg_instances/#1-1-general-purpose-t2t3-m4-m5","title":"1-1 General Purpose: T2,T3, M4, M5","text":""},{"location":"chap8/37bg_instances/#1-2-compute-optimized-c4-c5","title":"1-2 Compute Optimized:  C4, C5","text":"<p>Batch processing, Distributed analytics, Machine / Deep Learning Inference </p>"},{"location":"chap8/37bg_instances/#1-3-memory-optimized-r4-r5-x1-z1d","title":"1-3 Memory Optimized: R4, R5, X1 , Z1d","text":"<p>High performance database, In memory database, Real time big data analytics </p>"},{"location":"chap8/37bg_instances/#1-4-accelerated-computing-p2-p3-g3-f1","title":"1-4 Accelerated Computing: P2, P3, G3, F1","text":"<p>GPU instances, Machine or Deep Learning, High Performance Computing </p>"},{"location":"chap8/37bg_instances/#1-5-storage-optimized-h1-13-d2","title":"1-5 Storage Optimized: H1 , 13, D2","text":"<p>Distributed File System (HDFS), NFS, Map Reduce, Apache Kafka, Redshift </p> <p>Tensorflow for machine learning and MXNet for accelerated computing:  P2, P3, G3</p> <p>Batch processing for compute optimized</p>"},{"location":"chap8/37bg_instances/#2ec2-in-big-data","title":"2\u3001EC2 in Big Data","text":""},{"location":"chap8/37bg_instances/#2-1-on-demand-spot-reserved-instances","title":"2-1 On demand, Spot &amp; Reserved instances:","text":"<ul> <li>Spot can tolerate loss, low cost =&gt; checkpointing feature (ML, etc) </li> <li>Reserved: long running clusters, databases (over a year) </li> <li>On demand: remaining workloads </li> </ul>"},{"location":"chap8/37bg_instances/#2-2-auto-scaling","title":"2-2 Auto Scaling:","text":"<ul> <li>Leverage for EMR, etc </li> <li>Automated for DynamoDB, Auto Sca ing Groups, etc... </li> </ul>"},{"location":"chap8/37bg_instances/#2-3-ec2-is-behind-emr","title":"2-3 EC2 is behind EMR","text":"<ul> <li>Master Nodes </li> <li>Compute Nodes (contain data) + Tasks Nodes (do not contain data) </li> </ul>"},{"location":"chap9/18Process_ML/","title":"AWS Machine Learning \uff08Amazon ML Service/Amazon SageMaker)","text":""},{"location":"chap9/18Process_ML/#1machine-learning-101","title":"1\u3001Machine Learning 101","text":"<p>Amazon Machine Learning ML with linear and logistic regression </p>"},{"location":"chap9/18Process_ML/#1-1-machine-learning-101","title":"1-1 Machine Learning 101","text":"<ul> <li>Machine learning systems predict some unknown property of an item, given its other properties </li> </ul> <p>Examples: </p> <ul> <li>How much will this house sell for? </li> <li>What is this a picture of? </li> <li>Is this biopsy result malignant or benign? </li> <li>Is this financial transaction fraudulent? </li> </ul>"},{"location":"chap9/18Process_ML/#1-2-supervised-learning","title":"1-2 Supervised Learning","text":"<p>Supervised machine learning systems are trained </p> <ul> <li>The property we want to predict is called a label </li> <li>Our training data set contains labels known to be correct, together with the other attributes of the data (i.e., known house sale price given its location, # of bedrooms, square feet, etc.) </li> <li>This training data is used to build a model that can then make predictions of unknown labels </li> </ul>"},{"location":"chap9/18Process_ML/#1-3-train-test","title":"1-3 Train / Test","text":"<ul> <li>Your training data can be randomly split into a training set and a test set </li> <li>Only the training set is used to train the model </li> <li>The model is then used on the test set </li> <li>We can then measure the accuracy of the predicted labels vs. their actual labels </li> </ul> <p>A popular one for example is RMSE or root means squared error.</p>"},{"location":"chap9/18Process_ML/#2classification-models","title":"2\u3001Classification Models","text":""},{"location":"chap9/18Process_ML/#2-1-types-of-models-in-amazon-ml","title":"2-1 Types of models in Amazon ML","text":"<ul> <li>Regression means that trying to predict some numerical value based on past trends. Trying to predict a specific number and that number has some sort of numeric meaning.<ul> <li>Linear regression for predicting numbers</li> <li>Logistic regression for predicting categories. </li> </ul> </li> <li>Multi class classification trying to classify something into one of many different buckets.</li> <li>Binary classification binary referring to the fact that you just have two choices to choose from </li> </ul>"},{"location":"chap9/18Process_ML/#2-2-confusion-matrix","title":"2-2 Confusion Matrix","text":"<p>A way to visualize the accuracy of multiclass classification predictive models </p> <p> </p> <p>So the way to interpret a confusion matrix by just looking at it is that a really perfect classifier will just have dark blue all the way down the diagonal here.</p>"},{"location":"chap9/18Process_ML/#2-2-hyperparameters","title":"2-2 Hyperparameters","text":"<ul> <li> <p>Machine learning models often depend on tuning the parameters of the model itself </p> <ul> <li>This is called hyperparameter tuning </li> </ul> </li> <li> <p>Parameters in Amazon ML include: </p> <ul> <li>Learning rate </li> <li>Model size </li> <li>Number of passes </li> <li>Data shuffling </li> <li>Regularization </li> </ul> </li> </ul> <p>Learning rate which is basically how quickly it moves from one iteration to the other.</p> <p>Whether or not the input data is shuffled or not to sort of randomize things and try to eliminate any patterns that might be inherent in the order of the data you're feeding it </p> <p>Regularization means scaling the data to a common range as it goes in</p>"},{"location":"chap9/18Process_ML/#3amazon-ml-service","title":"3\u3001Amazon ML Service","text":""},{"location":"chap9/18Process_ML/#3-1-amazon-machine-learning-ml","title":"3-1 Amazon Machine Learning (ML)","text":"<ul> <li>Provides visualization tools &amp; wizards to make creating a model easy </li> <li>You point it to training data in S3, Redshift, or RDS </li> <li>It builds a model than can make predictions using batches or a low-latency API </li> <li>Can do train/test and evaluate your model </li> <li>Fully managed </li> <li>Honestly it's a bit outdated now</li> </ul>"},{"location":"chap9/18Process_ML/#3-2-ideal-usage-patterns","title":"3-2 \"Ideal Usage Patterns\"","text":"<ul> <li>Flag suspicious transactions (fraud detection) </li> <li>Forecasting product demand </li> <li>Personalization \u2014 predict items a user will be interested in </li> <li>Predict user activity (we'll do this) </li> <li>Classify social media (does this Tweet require my attention?) </li> </ul>"},{"location":"chap9/18Process_ML/#3-3-amazon-ml-cost-model","title":"3-3 Amazon ML: Cost Model","text":"<ul> <li>\"Pay for what you use\" </li> <li>Charged for compute time </li> <li>Number of predictions </li> <li>Memory used to run your model </li> <li>Compute-hours for training </li> </ul>"},{"location":"chap9/18Process_ML/#3-5-amazon-ml-promises-limitations","title":"3-5 Amazon ML: Promises &amp; Limitations","text":"<ul> <li>No downtime </li> <li>Up to 100GB training data (more via support ticket) </li> <li>Up to 5 simultaneous jobs (more via support ticket) </li> </ul>"},{"location":"chap9/18Process_ML/#3-6-amazon-ml-anti-patterns","title":"3-6 Amazon ML: Anti-Patterns","text":"<ul> <li>Terabyte-scale data </li> <li>Unsupported learning tasks<ul> <li>Sequence prediction </li> <li>Unsupervised clustering </li> <li>Deep learning </li> </ul> </li> <li>EMR / Spark is an (unmanaged) alternative. </li> </ul> <p>Exam</p> <p>Provide a machine learning solution that has terabytes or petabytes of training data Amazon ML is not going to be the right answer for that. </p>"},{"location":"chap9/18Process_ML/#4amazon-sagemaker","title":"4\u3001Amazon SageMaker","text":"<p>SageMaker is a component of Amazon Web Services and allows you to create notebooks hosted on AWS that can train large scale models in the cloud and then eent predictions from that model from the cloud as well.</p> <ul> <li>serious computing horsepower behind your machine learning system</li> <li>Scales better than Amazon's ML service</li> <li>More flexibility and more advanced and modern algorithms</li> <li>fully managed, SageMaker will manage your production compute infrastructure on your behalf to perform health check supply security patches and apply all the other routine maintenance</li> </ul> <p>The way to use is to write Python code in what's called a Jupiter notebook in order to use SageMaker.</p>"},{"location":"chap9/18Process_ML/#4-1-sagemaker-modules","title":"4-1 SageMaker Modules","text":""},{"location":"chap9/18Process_ML/#4-1-1-build-module","title":"4-1-1 Build Module","text":"<p>Build module provides a hosted environment for working with your data. Experimenting with algorithms and visualizing your output.</p> <p>This is where you're going to be working with fully managed instances running Jupiter notebooks for training data exploration and pre processing.</p> <ul> <li>These Jupiter notebooks that gonna be writing python code into build your model are preloaded with some pretty cool stuff such as CUDA and CUDNN drivers for deep learning. These drivers that allow to use the GPU on the computers in your cluster to accelerate your neural networks.</li> <li>Also includes a wide variety of Anaconda packages which are data science related to machine learning related packages for python and it also has libraries available for tensorflow, Apache MX net, pi torch, and chain.</li> <li>SageMaker in the build stage also has available built in fully managed reinforcement learning algorithms in the academic literature. Offers broad framework support so you can actually test and prototype</li> <li>Download docker container to your local environment and work with that to actually develop your modules for SageMaker as well using the SageMaker Python sdk without actually being online. </li> </ul>"},{"location":"chap9/18Process_ML/#4-1-2-train-module","title":"4-1-2 Train Module","text":"<p>SageMaker Search which allows you to quickly find and evaluate the most relevant model training runs from potentially hundreds and thousands of your Amazon SageMaker model training job.</p>"},{"location":"chap9/18Process_ML/#4-1-3-deploy-module","title":"4-1-3 deploy module","text":"<p>Deploy module provides a managed environment for you to easily host and test your models that will make predictions securely and with low latency.</p> <ul> <li>There's a batch transform mode that allows you to run predictions on large or small batch data.</li> <li>SageMaker enables you to deploy inference pipelines so you can pass raw input data and execute pre processing predictions and post-processing on real time and batch inference requests as well.</li> </ul>"},{"location":"chap9/18Process_ML/#4-1-4-sagemaker-neo","title":"4-1-4 SageMaker Neo","text":"<p>SageMaker Neo that allows machine learning models to be trained once and run anywhere in the cloud and at the edge so you can actually push out your prediction models out to edge nodes</p>"},{"location":"chap9/18Process_ML/#4-2-sagemaker-is-powerful","title":"4-2 SageMaker is powerful","text":"<ul> <li>Tensorflow </li> <li>Apache MXNet </li> <li>GPU accelerated deep learning </li> <li>Scaling effectively unlimited </li> <li>Flyperparameter tuning jobs </li> </ul>"},{"location":"chap9/18Process_ML/#4-3-sagemaker-security","title":"4-3 SageMaker Security","text":"<ul> <li>Code stored in \"ML storage volumes\" <ul> <li>Controlled by security groups </li> <li>Optionally encrypted at rest </li> </ul> </li> <li>All artifacts encrypted in transit and at rest</li> <li>API &amp; console secured by SSL </li> <li>IAM roles </li> <li>Encrypted S3 buckets for data </li> <li>KMS integration for SageMaker notebooks, training jobs, endpoints </li> </ul>"},{"location":"chap9/18Process_ML/#4-4-sagemaker-operations","title":"4-4 SageMaker Operations","text":"<ul> <li>CloudWatch is used to monitor Amazon SageMaker which collects all the raw data and processes it into readable near real time metrics.</li> <li>CloudTrail records the history of your Amazon SageMaker API calls that were made on your account.</li> </ul>"}]}